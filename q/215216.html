<!DOCTYPE html>
<html>
<head>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6EBTM9J4LK"></script>
<script src="../g.js"></script>
    <title>cg::215216</title>
    <link rel="stylesheet" href="../c.css">
</head>
<body>
    <br><br>
    <div id = "content">
    <div id="container">
    <div id="mf">
        <a href="#" class="nonewtab" d-g="g">g</a> | 
        <a href="#" class="nonewtab" d-g="x">x</a> | 
        <a href="#" class="nonewtab" d-g="w">w</a> | 
        <a href="#" class="nonewtab" d-g="">all</a>
    </div>
    <input type="text" id="mi" placeholder="/">
    </div>

<table id="mt">
  <tr class="header">
    <th class="tbytes">Bytes</th>
    <th class="tlang">Lang</th>
    <th class="ttime">Time</th>
    <th class="tlink">Link</th>
  </tr>
<tr d-ix="0"><td>nan</td><td></td><td>241225T025334Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/277386#277386">RARE Kpo</a></td></tr>
<tr d-ix="1"><td>nan</td><td></td><td>240204T174429Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/269772#269772">David Fr</a></td></tr>
<tr d-ix="2"><td>nan</td><td></td><td>231229T031609Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/268828#268828">Dmitry</a></td></tr>
<tr d-ix="3"><td>nan</td><td></td><td>221228T151639Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/256115#256115">Timo Klu</a></td></tr>
<tr d-ix="4"><td>nan</td><td></td><td>230708T083358Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/262521#262521">technusm</a></td></tr>
<tr d-ix="5"><td>003</td><td>Python</td><td>230715T234220Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/262893#262893">Antoine </a></td></tr>
<tr d-ix="6"><td>nan</td><td></td><td>221018T081916Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/253380#253380">Kokizzu</a></td></tr>
<tr d-ix="7"><td>nan</td><td></td><td>230703T085401Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/262388#262388">janfrode</a></td></tr>
<tr d-ix="8"><td>nan</td><td></td><td>230704T090912Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/262405#262405">0xDEADFE</a></td></tr>
<tr d-ix="9"><td>nan</td><td></td><td>230703T111114Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/262390#262390">Automati</a></td></tr>
<tr d-ix="10"><td>017</td><td>Java</td><td>211202T230454Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/237990#237990">Olivier </a></td></tr>
<tr d-ix="11"><td>nan</td><td>Updated code This code no more strings gets me to 4.8GiB/s. Can't break the 5 GiB/s barrier on the M1 with the naive implementation . Also</td><td>211208T230330Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/238254#238254">Ioan Tan</a></td></tr>
<tr d-ix="12"><td>nan</td><td></td><td>220623T172840Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248992#248992">anbcodes</a></td></tr>
<tr d-ix="13"><td>nan</td><td></td><td>220623T155811Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248988#248988">user1635</a></td></tr>
<tr d-ix="14"><td>nan</td><td></td><td>220620T153500Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248837#248837">psaikko</a></td></tr>
<tr d-ix="15"><td>nan</td><td></td><td>220617T163918Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248740#248740">LianShen</a></td></tr>
<tr d-ix="16"><td>nan</td><td></td><td>220604T180336Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248216#248216">no_gravi</a></td></tr>
<tr d-ix="17"><td>nan</td><td></td><td>220604T060156Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248198#248198">Phan Tha</a></td></tr>
<tr d-ix="18"><td>nan</td><td></td><td>211219T223917Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/239848#239848">xiver77</a></td></tr>
<tr d-ix="19"><td>nan</td><td>Did answer with Go</td><td>220606T181631Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/248295#248295">Bysmyyr</a></td></tr>
<tr d-ix="20"><td>nan</td><td>x8664+AVX2 assembly language Linux</td><td>211026T010328Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">ais523 -</a></td></tr>
<tr d-ix="21"><td>nan</td><td></td><td>211218T025114Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/239729#239729">Qaziquza</a></td></tr>
<tr d-ix="22"><td>nan</td><td></td><td>211202T203422Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/237980#237980">michalsi</a></td></tr>
<tr d-ix="23"><td>nan</td><td></td><td>201115T213534Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/215236#215236">Kamila S</a></td></tr>
<tr d-ix="24"><td>nan</td><td></td><td>220415T002813Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/246246#246246">arrmansa</a></td></tr>
<tr d-ix="25"><td>nan</td><td></td><td>211205T133202Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/238090#238090">Xavier B</a></td></tr>
<tr d-ix="26"><td>nan</td><td></td><td>211202T230032Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/237989#237989">RandyRan</a></td></tr>
<tr d-ix="27"><td>nan</td><td></td><td>211208T235452Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/238256#238256">lonelyel</a></td></tr>
<tr d-ix="28"><td>nan</td><td></td><td>211206T161649Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/238144#238144">MarcMush</a></td></tr>
<tr d-ix="29"><td>nan</td><td>Adding a bit upon ksousa's answer</td><td>211203T123736Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/238027#238027">bconstan</a></td></tr>
<tr d-ix="30"><td>nan</td><td></td><td>211203T045315Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/238011#238011">user1086</a></td></tr>
<tr d-ix="31"><td>nan</td><td>Just tried the following Kotlin</td><td>211202T135248Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/237956#237956">Arthur</a></td></tr>
<tr d-ix="32"><td>nan</td><td></td><td>211111T203930Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/237190#237190">ksousa</a></td></tr>
<tr d-ix="33"><td>nan</td><td></td><td>211108T193428Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/237012#237012">DBADon</a></td></tr>
<tr d-ix="34"><td>nan</td><td>Here is my attempt at using justintime compilation to emit fast FizzBuzz assembly that is specialized for every digit length.  It's basically the same idea as Neil's answer</td><td>211029T164903Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236737#236737">Paolo Bo</a></td></tr>
<tr d-ix="35"><td>nan</td><td>This probably won't be the fastest</td><td>211029T215616Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236744#236744">Random83</a></td></tr>
<tr d-ix="36"><td>nan</td><td></td><td>211008T141100Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236154#236154">jdt</a></td></tr>
<tr d-ix="37"><td>nan</td><td>A C++ program for Linux.  I use the same method of arithmetic as in my C answer</td><td>210122T105318Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/217887#217887">Toby Spe</a></td></tr>
<tr d-ix="38"><td>nan</td><td></td><td>210119T212119Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/217771#217771">Toby Spe</a></td></tr>
<tr d-ix="39"><td>nan</td><td>Coded in rust modern languages can be fast too. Build with cargo build release* and run with ./target/release/fizz_buzz. The count goes up by 15 every iteration of the loop. The itoap crate is used to quickly write integers to the buffer. Adds 15 line chunks to an array unless there isn't enough space left in the buffer for a maxsized chunk</td><td>210108T171419Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/217455#217455">Aiden4</a></td></tr>
<tr d-ix="40"><td>nan</td><td></td><td>201115T140423Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/215231#215231">Neil</a></td></tr>
<tr d-ix="41"><td>nan</td><td></td><td>201117T140455Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/215304#215304">anatolyg</a></td></tr>
<tr d-ix="42"><td>nan</td><td>After much trial and error</td><td>201114T182307Z</td><td><a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/215218#215218">Isaac G.</a></td></tr>
</table>
<div id="pu0" class="pu"><h2><code>awk</code></h2>
<p>If modulo (<code>%</code>) ops are considered high cost, then here's one way to do handle all output scenarios with just 1 modulo, and 1 single copy of combined string.</p>
<pre><code>jot 36 | 
awk 'function ____(__,_,___){return(_^=_&lt;_)-(__=int(___=__?__:$_)^++_^_++%(_++*++_))\
                  ?substr(&quot;Fizz Buzz&quot;,++_^(_--&lt;__),_*!__+--_):___}$NF=____()' ORS=', '
</code></pre>
<hr />
<pre><code>1, 2, Fizz, 4, Buzz, Fizz, 7, 8, Fizz, Buzz, 11, Fizz, 
13, 14, Fizz Buzz, 16, 17, Fizz, 19, Buzz, Fizz, 22, 23, Fizz,
Buzz, 26, Fizz, 28, 29, Fizz Buzz, 31, 32, Fizz, 34, Buzz, Fizz, 
</code></pre>
<p>But if I stupidly hard-encode every scenario into an array,</p>
<pre><code>( time ( mawk2 ' BEGIN {

    ______ = 16

    $1 = ($4 = $7 = $10 = $13 = &quot;Fizz&quot;)&quot; &quot;($6 = $11 = &quot;Buzz&quot;)

    for (_____ ^= _ = (ORS = &quot;, &quot;)*(___ = (_+=++_)^++_^_); _++ &lt; ___;)

          $(_____ ^= ++_____ &lt; ______) ? $_____ : _

    printf(&quot;%d\n&quot;, ___)  }' ) ) 
</code></pre>
<hr />
<pre><code>( mawk2 ; )  7.07s user 0.03s system 99% cpu 7.102 total

 1  134217728

 echo '1148700297/7.102/32^4' | bc -l          

 154.25034785935389293948
</code></pre>
<p>Cycling through <code>2^0</code> - <code>2^27</code>, <code>mawk2</code> had an internal throughput rate of <strong>154.25 MiB/sec</strong>, which is quite insane for a single-threaded shell scripting language invented 47 years ago. In this variant, all the thresholds appear to be upshifted by one, and that's by design, since I'm using exponentiation to handle <code>mod 15</code>.</p>
</div>
<div id="pu1" class="pu"><p><strong>283 GB/s</strong> output on AMD Ryzen 9 7700X.</p>
<p>To build (tested with GCC 13):</p>
<pre><code>g++ fizzbuzz.cc -march=native -o fizzbuzz -O3 -Wall -std=c++20 -fno-tree-vectorize -fno-exceptions
</code></pre>
<p>The build takes a few minutes to complete. Compiling with or without <code>-fno-tree-vectorize</code>
may yield better runtime performance depending on the CPU.</p>
<p>To benchmark:</p>
<ol>
<li>Install pv (ensure you have <a href="https://github.com/icetee/pv" rel="noreferrer">1.6.6</a>, later versions have an issue which makes the throughput lower when specifying <code>-B</code>)</li>
<li>Run</li>
</ol>
<pre><code>taskset -c 0-6 ./fizzbuzz | taskset -c 7 pv -B 2M &gt; /dev/null
</code></pre>
<p>Requires Linux 2.6.17 or later.</p>
<h3>Performance tuning</h3>
<ol>
<li>The value of the <code>kParallelism</code> constant in <code>fizzbuzz.cc</code> should be set to
available CPU cores or less.</li>
<li>The program uses <code>kParallelism</code> threads. It's worth trying different cpu
affinities to see what gives the best performance. The number of cores assigned
by <code>taskset</code> should be equal to <code>kParallelism</code></li>
<li>For maximum performance, <a href="https://jcvassort.open-web.fr/how-to-disable-cpu-mitigations/#how-to-disable-these-mitigations-to-make-linux-fast-again" rel="noreferrer">turn off mitigations</a>
(it's recommended to reenable mitigations after benchmarking since they protect
against CPU vulnerabilities).</li>
</ol>
<p><code>/proc/sys/fs/pipe-max-size</code> must be at least <code>14680064</code> (14MB) or alternatively
the program must be run as root (<code>sudo ...</code>)</p>
<hr />
<h2>The code</h2>
<pre class="lang-cpp prettyprint-override"><code>#include &lt;array&gt;
#include &lt;charconv&gt;
#include &lt;cstddef&gt;
#include &lt;cstdint&gt;
#include &lt;cstdlib&gt;
#include &lt;cstring&gt;
#include &lt;fcntl.h&gt;
#include &lt;iostream&gt;
#include &lt;optional&gt;
#include &lt;thread&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/mman.h&gt;

namespace {

// Constexpr helper for calculating 10^X since std::pow is not constexpr.
constexpr int64_t PowTen(int x) {
  int64_t result = 1;
  for (int i = 0; i &lt; x; ++i) {
    result *= 10;
  }
  return result;
}

// We process each batch in parallel from |kParallelism| threads. This number
// should be set to the available CPU cores or less. Note that higher number
// doesn't necessarily mean better performance due to the synchronization
// overhead between threads.
constexpr int64_t kParallelism = 7;
// The last kSuffixDigits digits of each number line are untouched when
// iterating.
constexpr int64_t kSuffixDigits = 6;
// Increment the first right-most touched digit by this much in one step. Must
// be divisible by 3. The code currently only handles when this is single-digit.
constexpr int64_t kIncrementBy = 3;
// One batch contains maximum this many lines.
constexpr int64_t kMaxLinesInBatch = PowTen(kSuffixDigits) * kIncrementBy / 3;

constexpr int kFizzLength = 4;
constexpr int kBuzzLength = 4;
constexpr int kNewlineLength = 1;

// A barrier that busy waits until all other threads reach the barrier.
template &lt;typename Completion&gt;
class SpinningBarrier {
 public:
  // Constructs a spinning barrier with |count| participating threads and
  // completion callback |completion_cb|.
  // After all threads reach the barrier, the last thread executes the
  // completion callback. The other threads are blocked until the completion
  // callback returns.
  SpinningBarrier(int64_t count, Completion completion_cb) :
      count_(count), spaces_(count), generation_(0),
      completion_cb_(completion_cb) {}

  void Wait() {
      int64_t my_generation = generation_;
      if (!--spaces_) {
          spaces_ = count_;
          completion_cb_();
          ++generation_;
      } else {
          while(generation_ == my_generation);
      }
  }

 private:
  int64_t count_;
  std::atomic&lt;int64_t&gt; spaces_;
  std::atomic&lt;int64_t&gt; generation_;
  Completion completion_cb_;
};

// Owns the output buffers and maintains which buffer was used last.
class OutputHandler {
 static constexpr size_t kBufferSize = 14 * 1024 * 1024;

 public:
  OutputHandler() {
    for (int i = 0; i &lt; 3; ++i) {
      buffers_[i].reset(static_cast&lt;char*&gt;(
        std::aligned_alloc(2 * 1024 * 1024, kBufferSize)));
      madvise(buffers_[i].get(), kBufferSize, MADV_HUGEPAGE);
    }
  }

  void Output(int buffer_id, size_t bytes) {
    // We use three buffers. We have to ensure that while a buffer (or its
    // part) is in the pipe, it won't get modified. There is no API to know
    // when a downstream process is finished reading some data from the pipe,
    // so we choose the size of the pipe smartly.
    // As long as the pipe cannot fit more than two full buffers, we can ensure
    // that after after outputting buffer 0, 1, 2 in this order, the pipe no
    // longer contains data from buffer 0. However, if we make the pipe too
    // small, the program will be slower. The optimal pipe size is calculated by
    // TargetPipeSize. Since there is a minimum pipe size which we
    // cannot go below (4kb on Linux), this approach won't work when the
    // buffer size is too small. In these cases we fall back to write() which
    // copies the content into the pipe, therefore there is no risk of
    // overwriting memory that is still being read from the downstream process.
    // However, if in the subsequent call to Output(), a smaller size were
    // passed (and therefore the else branch were executed), the pipe could
    // still end up containing some data from the current iteration and the
    // entire data from the next iteration. We assume that Output() will be
    // invoked with monotonically increasing sizes (which is true in practice
    // but it'd be better not to depend on this assumption).
    SetPipeSize(TargetPipeSize(bytes));
    if (2 * bytes &gt;= pipe_size_) {
      OutputWithVmSplice(buffers_[buffer_id].get(), bytes);
    } else {
      if (write(STDOUT_FILENO, buffers_[buffer_id].get(), bytes) &lt; 0) {
        std::cerr &lt;&lt; &quot;write error: &quot; &lt;&lt; errno;
        std::abort();
      }
    }
  }

  char* GetBuffer(int buffer_id) {
    return buffers_[buffer_id].get();
  }

  // Returns the next buffer id that can be filled up and outputted.
  // Callers are responsible to actually output the buffer after requesting it
  // with this method.
  int NextBufferId() {
    buffer_id_ = (buffer_id_ + 1) % 3;
    return buffer_id_;
  }

  static constexpr int64_t BufferSize() {
    return kBufferSize;
  }

 private:
  // Calculates the optimal pipe size for outputting |out_bytes|.
  size_t TargetPipeSize(size_t out_bytes) const {
    // Pipe sizes must be powers of 2 and &gt;= 4kb on Linux.
    // We want that the pipe is not bigger than twice the output (but still
    // maximize the pipe size), so we round |out_bytes| up to the nearest power
    // of two.
    return std::max(4ul * 1024, std::bit_ceil(out_bytes));
  }

  void OutputWithVmSplice(char* buffer, size_t bytes) const {
    iovec iov;
    iov.iov_base = buffer;
    iov.iov_len = bytes;
    while (true) {
      int64_t ret = vmsplice(STDOUT_FILENO, &amp;iov, 1, SPLICE_F_NONBLOCK);
      if (ret &gt;= 0) {
        iov.iov_len -= ret;
        iov.iov_base = reinterpret_cast&lt;char*&gt;(iov.iov_base) + ret;
        if (iov.iov_len == 0) {
          break;
        }
      } else {
        if (errno != EAGAIN) {
          std::cerr &lt;&lt; &quot;vmsplice error: &quot; &lt;&lt; errno;
          std::abort();
        }
      }
    }
  }

  void SetPipeSize(size_t size) {
    if (pipe_size_ == size) {
      return;
    }
    size_t new_pipe_size = fcntl(STDOUT_FILENO, F_SETPIPE_SZ, size);
    if (new_pipe_size &lt; 0) {
      std::cerr &lt;&lt; &quot;Error while calling fcntl F_SETPIPE_SZ &quot; &lt;&lt; errno
      &lt;&lt; &quot;\nPerhaps you need to update /proc/sys/fs/pipe-max-size or &quot;
         &quot;run the program as sudo&quot;;
      std::abort();
    }

    pipe_size_ = new_pipe_size;
  }

  std::array&lt;std::unique_ptr&lt;char[], decltype([](char* x) {std::free(x);})&gt;, 3&gt;
    buffers_;
  int buffer_id_ = 0;
  size_t pipe_size_;
};

// Inserts the fizzbuzz line for line number |line| and a newline character
// into |out|.
// Returns the pointer pointing to the character after the newline.
char* InsertFizzBuzzLine(char* out, int64_t line) {
  if (line % 15 == 0) {
    std::memcpy(out, &quot;FizzBuzz\n&quot;, 9);
    return out + 9;
  } else if (line % 3 == 0) {
    std::memcpy(out, &quot;Fizz\n&quot;, 5);
    return out + 5;
  } else if (line % 5 == 0) {
    std::memcpy(out, &quot;Buzz\n&quot;, 5);
    return out + 5;
  } else {
    // We support numbers up to 10^20.
    char* next = std::to_chars(out, out + 20, line).ptr;
    *next = '\n';
    return next + 1;
  }
}

// A run refers to all lines where the line numbers have |DIGITS| digits.
// Run&lt;1&gt;: [1,9]
// Run&lt;2&gt;: [10,99]
// ...
template&lt;int DIGITS&gt;
class Run {

  static_assert(DIGITS &gt;= 1);

  static constexpr int FizzBuzzLineLength(int64_t number_mod_15) {
    if (number_mod_15 % 15 == 0) {
      return 9;
    } else if (number_mod_15 % 3 == 0) {
      return 5;
    } else if (number_mod_15 % 5 == 0) {
      return 5;
    } else {
      return DIGITS + 1;
    }
  }

  // Returns the size of one fifteener in bytes.
  static constexpr size_t FifteenerBytes() {
    size_t size = 0;
    for (int i = 0; i &lt; 15; ++i) {
      size += FizzBuzzLineLength(i);
    }
    return size;
  }

  // Returns the number of lines in this run.
  static constexpr int64_t LinesInRun() {
    return PowTen(DIGITS) - PowTen(DIGITS - 1);
  }

  // The entire fizz-buzz output for this run takes this many bytes.
  static constexpr size_t RunBytes() {
    if constexpr(DIGITS == 1) {
      return 5 + 3 * kFizzLength + 1 * kBuzzLength + 9 * kNewlineLength;
    } else {
      return LinesInRun() / 15 * FifteenerBytes();
    }
  }

  // Returns the number of batches in this run.
  static constexpr int64_t BatchesInRun() {
    if constexpr (DIGITS &gt; kSuffixDigits) {
      return PowTen(DIGITS - kSuffixDigits - 1) * 9;
    } else {
      return 1;
    }
  }

 public:
  // Outputs all lines for this run by using the buffers from |output_handler|.
  static void Execute(OutputHandler&amp; output_handler) {
    Batch&lt;0&gt; batch0(&amp;output_handler);
    Batch&lt;1&gt; batch1(&amp;output_handler);
    Batch&lt;2&gt; batch2(&amp;output_handler);
    // We fill up each batch with the initial values. This is a relatively slow
    // process so we only do it once per run. In subsequent iterations, we
    // only increment the numbers (see below) which is much faster.
    batch0.Init();
    batch0.Output();
    if constexpr (BatchesInRun() &gt; 1) {
      batch1.Init();
      batch1.Output();
    }
    if constexpr (BatchesInRun() &gt; 2) {
      batch2.Init();
      batch2.Output();
    }

    if constexpr (BatchesInRun() &gt; 3) {
      int64_t prefix = PowTen(DIGITS - kSuffixDigits - 1);
      // We update the batch from |kParallelism| threads
      // We use a spinning barrier for synchronizing between the threads.
      // After all threads reach the barrier, the completion function is
      // executed and the output is written out. Then the next batch is
      // processed.
      SpinningBarrier barrier(kParallelism, [&amp;] {
        switch (prefix % 3) {
          // In the beginning
          //   batch0 corresponds to prefix 10..00 ( ≡ 1 mod 3),
          //   batch1 corresponds to prefix 10..01 ( ≡ 2 mod 3),
          //   batch2 corresponds to prefix 10..02 ( ≡ 0 mod 3).
          // After all 3 batches are processed, the prefix is incremented by 3,
          // hence the mods don't change.
          case 0: batch2.Output(); break;
          case 1: batch0.Output(); break;
          case 2: batch1.Output(); break;
        }
        prefix++;
      });

      [&amp;]&lt;size_t... THREAD_ID&gt;(std::index_sequence&lt;THREAD_ID...&gt;) {
        // Launch |kParallelism| number of threads. We could also use a thread
        // pool, but one run takes long enough that launching new threads is
        // negligible.
        (std::jthread([&amp;] {
          for (int64_t batch = 3; batch &lt; BatchesInRun();
               batch += 3) {
            // Each thread processes their corresponding chunk in the batch.
            Chunk&lt;0, THREAD_ID&gt;(batch0).IncrementNumbers(prefix);
            // At this point, all threads wait until every other thread reaches
            // the barrier, the last thread to finish will invoke batch.Output()
            // (see above at the definition of |barrier|).
            barrier.Wait();
            Chunk&lt;1, THREAD_ID&gt;(batch1).IncrementNumbers(prefix);
            barrier.Wait();
            Chunk&lt;2, THREAD_ID&gt;(batch2).IncrementNumbers(prefix);
            barrier.Wait();
          }
        }) , ...);
      }(std::make_index_sequence&lt;kParallelism&gt;());
    }
  }

  // A batch represents 10^|kSuffixDigits| lines of the output.
  // This is useful because the last |kSuffixDigits| digits don't need to be
  // updated. Furthermore, line numbers in one batch share the same prefix.
  // BATCH_ID ∈ [0, 1, 2]
  template&lt;int BATCH_ID&gt;
  class Batch {
    static_assert(BATCH_ID &lt; 3);
    using PreviousBatch = Batch&lt;BATCH_ID - 1&gt;;

    public:
    Batch(OutputHandler* output_handler) : output_handler_(output_handler) {
      static_assert(OutputHandler::BufferSize() &gt;= BytesInBatch());
    }

    // Initializes this batch by taking the next available buffer from
    // the output handler and filling it with the initial values.
    void Init() {
      buffer_id_ = output_handler_-&gt;NextBufferId();
      char* out = GetBuffer();
      int64_t start = PowTen(DIGITS - 1) + BATCH_ID * LinesInBatch();
      int64_t end = std::min(PowTen(DIGITS), start + LinesInBatch());
      for (int64_t line = start; line &lt; end; ++line) {
        out = InsertFizzBuzzLine(out, line);
      }
    }

    // Returns the first line number of this chunk mod 15.
    static constexpr int64_t FirstLineNumberMod15() {
      if constexpr (BATCH_ID == 0) {
        return DIGITS &gt; 1 ? 10 : 1;
      } else {
        return (PreviousBatch::FirstLineNumberMod15() +
          PreviousBatch::LinesInBatch()) % 15;
      }
    }

    // Returns the number of lines in this batch.
    static constexpr int64_t LinesInBatch() {
      return std::min(kMaxLinesInBatch, LinesInRun());
    }

    // Returns the size of this batch in bytes.
    static constexpr int64_t BytesInBatch() {
      if constexpr (LinesInBatch() &lt; kMaxLinesInBatch) {
        return RunBytes();
      } else {
        size_t size = LinesInBatch() / 15 * FifteenerBytes();
        for (int64_t i = FirstLineNumberMod15() + LinesInBatch() / 15 * 15;
             i &lt; FirstLineNumberMod15() + LinesInBatch(); ++i) {
          size += FizzBuzzLineLength(i);
        }
        return size;
      }
    }

    void Output() {
      output_handler_-&gt;Output(buffer_id_, BytesInBatch());
    }

    char* GetBuffer() {
      return output_handler_-&gt;GetBuffer(buffer_id_);
    }

    OutputHandler* output_handler_;
    // The buffer id that this batch should use in |output_handler_|.
    int buffer_id_;
  };

  // Represents a chunk, a part of batch processed by thread with id
  // |THREAD_ID|. THREAD_ID ∈ [0, kParallelism)
  // Since numbers in each chunk need to be incremented at different indexes,
  // we specialize this class for each BATCH_ID and THREAD_ID so the indexes can
  // be precomputed at compile time.
  template&lt;int BATCH_ID, int THREAD_ID&gt;
  class Chunk {
    using PreviousChunk = Chunk&lt;BATCH_ID, THREAD_ID - 1&gt;;

    public:
    // Initializes a chunk that resides in |batch|.
    Chunk(Batch&lt;BATCH_ID&gt; batch) : batch_(batch) {}

    // Returns the first line number of this chunk mod 15.
    static constexpr int64_t FirstLineNumberMod15() {
      if constexpr (THREAD_ID == 0) {
        return Batch&lt;BATCH_ID&gt;::FirstLineNumberMod15();
      } else {
        return (PreviousChunk::FirstLineNumberMod15() +
          PreviousChunk::LinesInChunk()) % 15;
      }
    }

    // Returns the index of the start byte of this chunk in the batch.
    static constexpr int64_t StartIndexInBatch() {
      if constexpr (THREAD_ID == 0) {
        return 0;
      } else {
        return PreviousChunk::StartIndexInBatch() +
          PreviousChunk::BytesInChunk();
      }
    }

    // Returns the number of lines in this chunk.
    static constexpr int64_t LinesInChunk() {
      int64_t done = THREAD_ID == 0 ? 0 :
        PreviousChunk::CumulativeLinesUpToChunk();
      int64_t remaining_lines = Batch&lt;BATCH_ID&gt;::LinesInBatch() - done;
      int64_t remaining_threads = kParallelism - THREAD_ID;
      // equivalent to ceil(remaining_lines / remaining_threads)
      return (remaining_lines - 1) / remaining_threads + 1;
    }

    // Returns the number of lines in this and all previous chunks in the batch.
    static constexpr int64_t CumulativeLinesUpToChunk() {
      if constexpr (THREAD_ID &lt; 0) {
        return 0;
      } else {
        return PreviousChunk::CumulativeLinesUpToChunk() + LinesInChunk();
      }
    }

    // Returns the length of this chunk in bytes.
    static constexpr int64_t BytesInChunk() {
      size_t size = LinesInChunk() / 15 * FifteenerBytes();
      for (int64_t i = FirstLineNumberMod15() + LinesInChunk() / 15 * 15;
           i &lt; FirstLineNumberMod15() + LinesInChunk(); ++i) {
        size += FizzBuzzLineLength(i);
      }
      return size;
    }

    // Increments all the numbers in the chunk.
    // This function wraps IncrementNumbersImpl for efficiently dispatching to
    // specialized versions based on |prefix|.
    void IncrementNumbers(int64_t prefix) {
      // If DIGITS &lt; kSuffixDigits, it means that all the numbers within a run
      // will fit into a single batch, so we should not use IncrementNumbers().
      // The below implementation would not even work.
      static_assert(DIGITS &gt;= kSuffixDigits);
      constexpr int64_t max_overflow_digits = DIGITS - kSuffixDigits;
      // Contains an IncrementChunkImpl() specialization for each value in
      // 0..max_overflow_digits. We use it to jump to the right specialization.
      constexpr auto increment_chunk_impls = []() {
        std::array&lt;void (*)(char*), max_overflow_digits + 1&gt; res{};
        [&amp;]&lt;size_t... OVERFLOW_DIGITS&gt;(std::index_sequence&lt;OVERFLOW_DIGITS...&gt;) {
          ((res[OVERFLOW_DIGITS] = &amp;IncrementNumbersImpl&lt;OVERFLOW_DIGITS&gt;), ...);
        }(std::make_index_sequence&lt;max_overflow_digits + 1&gt;());
        return res;
      }();

      increment_chunk_impls[OverflowDigits(prefix)](batch_.GetBuffer());
    }

    private:
    // Increments this chunk in |batch|.
    //
    // Each number line is incremented by |kIncrementBy| * 10^kSuffixDigits.
    // If OVERFLOW_DIGITS &gt; 0, we assume that the operation will overflow,
    // therefore, we need to increment this many digits beforehand. It's the
    // caller's responsibility to calculate the number of digits that will need
    // to be updated in this chunk.

    // For example, the chunk if kIncrementBy = 3 and kSuffixDigits = 6, the
    // chunk [100000000, 100999999] can be incremented to [103000000; 103999999]
    // with OVERFLOW_DIGITS = 0 (no overflow).
    // When incrementing [108000000, 108999999] to [111000000; 111999999],
    // OVERFLOW_DIGITS = 1 (one-digit overflow).
    // When incrementing [198000000, 198999999] to [201000000, 201999999],
    // OVERFLOW_DIGITS = 2 (two-digit overflow)
    template&lt;int OVERFLOW_DIGITS&gt;
    static void IncrementNumbersImpl(char* batch) {
      char* out = batch;
      constexpr int64_t start_index = StartIndexInBatch();
      constexpr int first_line_number_mod_15 = FirstLineNumberMod15();

      // Increments the |num_lines| starting from |out|.
      // |num_lines| must be divisible by 120 (except in the last iteration).
      auto increment = [&amp;] (int num_lines) __attribute__((always_inline)) {
        int line_start = 0;
        #pragma GCC unroll 120
        for (int64_t line = 0; line &lt; num_lines; ++line) {
          if (IsFizzBuzzNumber(first_line_number_mod_15 + line)) {
            // In order for the compiler to generate efficient code, the
            // second and third params should be deducible to constants.
            // Since the loop is unrolled, the value of |line_start| is
            // known in every iteration. |start_index| is constexpr, so
            // its value is also known.
            IncrementNumber(out, line_start + start_index, OVERFLOW_DIGITS);
          }
          line_start +=
              FizzBuzzLineLength((first_line_number_mod_15 + line) % 15);
        }
        // Since num_lines is a multiply of 120, the right hand side is a
        // multiply of 8 which ensures that |out| is aligned to 8 bytes
        // afterwards.
        out += FifteenerBytes() * num_lines / 15;
      };

      for (int64_t i = 0; i &lt; LinesInChunk() / 120; ++i) {
        increment(120);
      }
      increment(LinesInChunk() % 120);
    }

    // Returns whether this number is printed as-is ie. it's not a multiply of 3
    // or 5.
    static constexpr bool IsFizzBuzzNumber(int64_t number) {
      return number % 3 != 0 &amp;&amp; number % 5 != 0;
    }

    // Increments the number starting at base[line_start].
    // |base| must be aligned to 8 bytes. The caller must guarantee that the
    // number of overflows that occur is |overflow_digits|.
    // For maximum performance, |line_start| should be deducible at compile
    // time.
    __attribute__((always_inline))
    static inline void IncrementNumber(char* base,
                                       int64_t line_start,
                                       int overflow_digits) {
      int64_t right_most_digit_to_update_index =
          line_start + DIGITS - 1 - kSuffixDigits;
      // When overflow_digits is known at compile time, all the IncrementAt
      // calls that affect the same 8-byte integer are combined into 1
      // instruction by the compiler.
      IncrementAt(base, right_most_digit_to_update_index, kIncrementBy);
      #pragma GCC unroll 100
      for (int i = 0; i &lt; overflow_digits; ++i) {
        IncrementAt(base, right_most_digit_to_update_index, -10);
        IncrementAt(base, right_most_digit_to_update_index - 1, 1);
        right_most_digit_to_update_index--;
      }
    }

    // Increments the byte at |index| in |base| by |by|.
    // |base| must by aligned to 8 bytes.
    // For maximum performance, |index| and |by| should be deducible by the
    // compiler to constants.
    __attribute__((always_inline))
    static inline void IncrementAt(char* base, int64_t index, char by) {
      union char_array_int64 {
        char ch[8];
        int64_t int64;
      };
      auto base_as_union = reinterpret_cast&lt;char_array_int64*&gt;(base);
      // The code below only works on little endian systems.
      static_assert(std::endian::native == std::endian::little);
      // Increment the character at index |index| by |by|. This works because
      // we can guarantee that the character won't overflow.
      base_as_union[index / 8].int64 +=
        static_cast&lt;int64_t&gt;(by) &lt;&lt; ((index % 8) * 8);
    }

    // Returns the number of digits that will overflow when incrementing
    // |prefix| by |kIncrementBy|.
    // Eg. if kIncrementBy = 3:
    // OverflowDigits(100) = 0 (no digits overflow)
    // OverflowDigits(108) = 1 (8 overflows and 0 is incremented by 1)
    // OverflowDigits(198) = 2 (8 overflows and 9 overflows)
    static int OverflowDigits(int64_t prefix) {
      int incremented = prefix + kIncrementBy;
      #pragma GCC unroll 2
      for (int i = 0; i &lt; 20; ++i) {
        incremented /= 10;
        prefix /= 10;
        if (incremented == prefix) {
          return i;
        }
      }
      return 20;
    }

    Batch&lt;BATCH_ID&gt; batch_;
  };
};

} // namespace

int main() {
  OutputHandler output_handler;

  [&amp;]&lt;std::size_t... I&gt;(std::index_sequence&lt;I...&gt;){
    (Run&lt;I + 1&gt;::Execute(output_handler), ...);
  }(std::make_index_sequence&lt;18&gt;());

  return 0;
}
</code></pre>
<h2>The algorithm</h2>
<p>I reuse some of the ideas from <a href="https://codegolf.stackexchange.com/a/236630/7251">ais523's answer</a>, namely:</p>
<ul>
<li>using vmsplice for zero-copy output into the pipe</li>
<li>aligning the output buffers to 2MB and using huge pages</li>
</ul>
<h3>Definitions</h3>
<ul>
<li>line number: the id of each line starting with 1, 2, ...</li>
<li>mod: the line number mod 15</li>
<li>fizzbuzz line: one line of output</li>
<li>fizzbuzz function: a function that translates the line number to a fizzbuzz line according to the fizzbuzz logic</li>
<li>number line: a line of output which is a number (and not fizz, buzz or fizzbuzz)</li>
<li>fifteener: 15 lines of consecutive output</li>
<li>batch: 1,000,000 lines of consecutive output</li>
<li>run: consecutive output where the line numbers have the same number of digits in base 10, eg. run(6) is the output for line numbers: 100000 ... 999999</li>
</ul>
<h3>A few observations</h3>
<p><strong>Observation 1:</strong> within each fifteener, the number lines are always at the same indices, namely at indices 1, 2, 4, 7, 8, 11, 13 and 14</p>
<p><strong>Observation 2:</strong> each run with 2+ digits contains a whole number of fifteeners</p>
<p><strong>Observation 3:</strong> each run with 2+ digits starts with mod = 10 because 10^N ≡ 10 (mod 15) for N &gt; 0</p>
<p><strong>Observation 4:</strong> if we have 3 batches (3,000,000 lines) of output in a buffer,
we can get the next 3 batches by incrementing the 6th digit (0-indexed) from the
right of each number line by 3 in each batch. We can keep other digits untouched. We'll call
the last 6 digits of the number <em>suffix digits</em>, since these will never change in a run.
The fizz/buzz/fizzbuzz lines are also untouched.</p>
<p>For example the first batch of run(9) looks like this:</p>
<pre><code>BUZZ
100000001
FIZZ
100000003
100000004
FIZZBUZZ
...
FIZZ
100999999
</code></pre>
<p>Second batch of run(9):</p>
<pre><code>BUZZ
FIZZ
101000002
101000003
...
101999998
101999999
</code></pre>
<p>Third batch of run(9):</p>
<pre><code>FIZZBUZZ
102000001
102000002
FIZZ
...
102999998
FIZZ
</code></pre>
<p>We can get the fourth batch by incrementing the first batch by 3,000,000:</p>
<pre><code>BUZZ
103000001
FIZZ
103000003
103000004
FIZZBUZZ
...
FIZZ
105999999
</code></pre>
<p>Incrementing single digits is much faster than recomputing the numbers every time.</p>
<p>We only need to maintain three buffers for the three batches and keep incrementing numbers by 3,000,000.</p>
<p>It's important to note that the number lines in the buffer contain the string
representation of the numbers, eg. 103000003 is actually <code>['1','0','3','0','0','0','0','0','3']</code> = <code>[49, 48, 51, 48, 48, 48, 48, 48, 51]</code>.
Incrementing by 3,000,000 means incrementing the 6th digit (0-indexed) from the right by 3.</p>
<p>Using three buffers also has an addition benefit: we can put up to two buffers
into the pipe for the downstream process to read from (see vmsplice and
<a href="https://mazzo.li/posts/fast-pipes.html" rel="noreferrer">this article</a>) and update the third buffer in the meantime.</p>
<p>The basic algorithm is as follows:</p>
<pre><code>for run in 1..19:
  initialize batch0 with fizz buzz lines between 10^(run-1) and 10^(run-1) + 999,999
  output batch0
  initialize batch1 with fizz buzz lines between 10^(run-1) + 1,000,000 and 10^(run-1) + 1,999,999
  output batch1
  initialize batch2 with fizz buzz lines between 10^(run-1) + 2,000,000 and 10^(run-1) + 2,999,999
  output batch2
  for batch in 3..(number of batches in run):
    increment batch0
    output batch0
    increment batch1
    output batch1
    increment batch2
    output batch2
</code></pre>
<p>The algorithm is fast because the increment operation (which is where most of
the time is spent) can be optimized really well.</p>
<h3>Overflows and carry</h3>
<p>A major complication in the above algorithm is when a digit overflows.
For example, if we increment the digit '8' in 108399977 by 3, the result is not a
digit, so we have to take care of the overflow.
We do this by first incrementing '8' by 3, then subtracting 10 and adding 1 to
the '0' before the '8' (which is pretty much the process how we'd do it on paper).
Furthermore, it can happen that more than even the digit before overflows, e.g. if the number is 198399977. In this case, we:</p>
<ul>
<li>add 3 to '8'</li>
<li>subtract 10 from '8' + 3</li>
<li>add 1 to '9'</li>
<li>subtract 10 from '9' + 1</li>
<li>add 1 to '1'</li>
</ul>
<p>The final result is 201399977.</p>
<p>However, checking in each iteration whether an overflow has occurred is pretty slow.
This is where batches are useful once again. Since a batch is 1,000,000 lines of output,
all numbers in a batch share a common prefix.</p>
<pre><code>122|531269
    ------  suffix (last 6 digits)
---         prefix (all previous digits)
</code></pre>
<p>As mentioned above, the suffixes are never touched after the initialization.
We only increment the prefix.</p>
<p>The nice property of a batch is that all numbers in
a batch overflow the same way, therefore we only have to check once per chunk, how many digits
will need to be updated for each number. We call this the overflow count.</p>
<p>We get extra performance gains by incrementing each batch from multiple threads.
One section of a batch updated by a thread is called a <strong>chunk</strong>.</p>
<h2>C++ tricks</h2>
<p>After discussing the algorithm, here are a few ideas that make this algorithm particularly fast:</p>
<h3>8 is better than 1</h3>
<p>Previously we talked about incrementing single characters in the buffer but CPUs can work with 8-byte integers faster than with 1-byte integers. Furthermore, if we have to update multiple digits because of overflow, updating 8 bytes at once will reduce the number of instructions.</p>
<p>For this to work, a requirement is that the integers must be aligned at 8 bytes, so we need to know where the 8-byte boundaries are.</p>
<p>Consider the number 12019839977 where we want to add 6 to the digit '8' (and handle overflow). Let's assume that the (one-byte) indexes mod 8 are as follows:</p>
<pre><code>output:        X Y 1 2 0 1 9 8 3 9 9 7 7
index mod 8:   0 1 2 3 4 5 6 7 0 1 2 3 4
</code></pre>
<p><code>X Y</code> is the last two bytes before this number. Let's call the address of <code>X</code> <code>base</code>. This address is aligned to 8 bytes. Instead of updating the single bytes at (<code>base + 7</code>), (<code>base + 6</code>) and (<code>base + 5</code>), we can update the 8 bytes in a single operation using bit shifts.</p>
<p>On little endian systems (like x86) where the least significant byte is at the lowest address, this translates to:</p>
<pre class="lang-cpp prettyprint-override"><code>base[index \ 8] += 1 &lt;&lt; (5 * 8)  |  (1 - 10) &lt;&lt; (6 * 8)  |  (6 - 10) &lt;&lt; (7 * 8)
                         ^             ^
                  index mod 8 = 5    increment by 1 - 10 (add carry and handle overflow)
</code></pre>
<p>Each update we want to do to the numbers is OR-d together. What's even better is that even if we write individual instructions, the compiler is smart enough to compile it to a single expression as long as the right handsides are compile-time constants:</p>
<pre class="lang-cpp prettyprint-override"><code>base[index \ 8] += 1 &lt;&lt; (5 * 8);
base[index \ 8] += (1 - 10) &lt;&lt; (6 * 8);
base[index \ 8] += (6 - 10) &lt;&lt; (7 * 8);
</code></pre>
<p>Doing all these bit manipulations at runtime would be slower than just incrementing the numbers one byte at a time, so we'll be ...</p>
<h3>Using the compiler for maximum gains</h3>
<p>All the calculation needed for the previous step to work fast is done at compile time. A few more observations:</p>
<ul>
<li>The first batch starts with mod 10, the second batch starts with mod 5, the batch chunk starts with mod 0.</li>
<li>The first batch is aligned at 8 bytes. We can calculate the length of each batch and chunk at compile time.</li>
</ul>
<p>Using C++ templates, we generate specialized code for each <code>(run digits, batch id, chunk id, overflows)</code> tuple.</p>
<ul>
<li>run digits: the number of digits of each number line in this run</li>
<li>batch id: 0, 1 or 2 (see the Observation 4 above)</li>
<li>chunk id: to distinguish the chunk in the batch, [0, kParallelism)</li>
<li>overflow count: the number of digits that will overflow after incrementing the last digit of the prefix</li>
</ul>
<p>In order to support the compiler in generating branchless code, we aggressively
unroll loops so conditions and calculations can be done at compile time. The
price is a long compile time.</p>
<p>If we inspect the generated assembly, we can see that the compiler generates
specialized code which only contains add/sub instructions without any branches.</p>
<pre><code>add QWORD PTR 8[rax], rdx
sub QWORD PTR 40[rax], 1033
add QWORD PTR 32[rax], rdx
add QWORD PTR 56[rax], r8
sub QWORD PTR 88[rax], 4
add QWORD PTR 80[rax], rsi
sub QWORD PTR 104[rax], 67698432
sub QWORD PTR 128[rax], 67698432
sub QWORD PTR 160[rax], 4
[many more add/sub]
</code></pre>
<p>Most of the time, we only need 8 instructions for each fifteener.</p>
<p><strong>Feedback / ideas for improvement welcome!</strong></p>
</div>
<div id="pu2" class="pu"><h1>Ruby</h1>
<p>Here's some refinements based on the initial solution by @lonelyelk. Tested using the now latest Ruby 3.3. <a href="https://codegolf.stackexchange.com/a/238256">His original five-liner</a> gives ~70 MiB/s on my machine.</p>
<p>Step 1: Drop the <code>each_slice</code> iteration, using a simple loop:</p>
<pre class="lang-rb prettyprint-override"><code># frozen_string_literal: true
FMT = &quot;%d\n%d\nFizz\n%d\nBuzz\nFizz\n%d\n%d\nFizz\nBuzz\n%d\nFizz\n%d\n%d\nFizzBuzz\n&quot;
i = 1

loop do
  printf(FMT, i, i + 1, i + 3, i + 6, i + 7, i + 10, i + 12, i + 13)
  i += 15
end
</code></pre>
<p>The result runs at 135 MiB/s, almost twice as fast.</p>
<p>Step 2: Create much longer (by x400) strings each iteration step, using some runtime-generated code.</p>
<pre class="lang-rb prettyprint-override"><code># frozen_string_literal: true
MULT = 400
FMT = &quot;%d\n%d\nFizz\n%d\nBuzz\nFizz\n%d\n%d\nFizz\nBuzz\n%d\nFizz\n%d\n%d\nFizzBuzz\n&quot; * MULT

idxs = (0..MULT).flat_map do |i|
  [0, 1, 3, 6, 7, 10, 12, 13].map { |j| j + i * 15 }
end

eval &lt;&lt;EOS
  def run_loop
    i = 1
    loop do
      printf(FMT, #{idxs.map { |n| &quot;i + #{n}&quot; }.join(', ') })
      i += 15 * MULT
    end
  end
EOS

run_loop
</code></pre>
<p>This gets up to 180-200 MiB/s, overtaking the &quot;naive C&quot;.</p>
<p>Finally, parallelize the computation using ractors (16 seems like the sweet spot on my 6-core machine). This chunk of work is big enough that message-passing overhead is not a problem.</p>
<pre class="lang-rb prettyprint-override"><code># frozen_string_literal: true
MULT = 400
FMT = (&quot;%d\n%d\nFizz\n%d\nBuzz\nFizz\n%d\n%d\nFizz\nBuzz\n%d\nFizz\n%d\n%d\nFizzBuzz\n&quot; * MULT).freeze
WORKERS = 16

idxs = (0..MULT).flat_map do |i|
  [0, 1, 3, 6, 7, 10, 12, 13].map { |j| j + i * 15 }
end

eval &lt;&lt;EOS
  def spawn_worker
    Ractor.new do
      loop do
        i = Ractor.receive
        Ractor.yield format(FMT, #{idxs.map { |n| &quot;i + #{n}&quot; }.join(', ') }).freeze
      end
    end
  end
EOS

workers = (1...WORKERS).map { spawn_worker }

ii = 1

loop do
  workers.each do |worker|
    worker.send(ii)
    ii += 15 * MULT
  end
  workers.each { |worker| puts worker.take }
end
</code></pre>
<p>This gives ~400 MiB/s, with fluctuations 380-420.</p>
</div>
<div id="pu3" class="pu"><h1>Julia (v1.10)</h1>
<p>Run with <code>julia fizzbuzz.jl | pv &gt; /dev/null</code>.</p>
<p>I'm getting 8-10 GiB/s throughput.</p>
<p>Notes:</p>
<ul>
<li>This supports at most 16 digits for the line number, which on my machine theoretically takes a day to reach.</li>
<li>This uses <code>vmsplice()</code> as popularized by ais523.</li>
<li>The buffer and page size count are hardcoded for my own machine, a Dell XPS with a 4 core / 8 threads Core i7-10510U CPU @ 1.80GHz.</li>
</ul>
<pre><code>const PAGESIZE = 4096
const L2_CACHE_SIZE = 256 * PAGESIZE
const BUFSIZE = L2_CACHE_SIZE ÷ 2

&quot;&quot;&quot;
    ShortString(&quot;foo&quot;)

Represents a string that's short enough to fit entirely in a UInt128.
We take advantage of that by doing arithmetic on the UInt128 for
enumerating the decimal representation of the line numbers.
&quot;&quot;&quot;
struct ShortString
  val :: UInt128
  len :: Int
end

ShortString(s::String) = begin
  @assert length(s) &lt;= sizeof(UInt128)
  s_padded = s * &quot;\0&quot; ^ sizeof(UInt128)
  val = unsafe_load(Ptr{UInt128}(pointer(s_padded)))
  ShortString(val, length(s))
end

Base.length(s::ShortString) = s.len

Base.:+(s::ShortString, x::Integer) = ShortString(s.val + x, s.len)
Base.:-(a::ShortString, b::ShortString) = begin
  @assert length(a) == length(b)
  a.val - b.val
end

concat(s::ShortString, a::Char) = begin
  newval = (s.val &lt;&lt; 8) | UInt8(a)
  ShortString(newval, s.len + 1)
end

&quot;&quot;&quot;
    StaticBuffer(size)

Represents a simple byte array together with its next index.

This struct is non-mutable, and instead of updating `ptr` in place, we
replace it with a new StaticBuffer (see the `put` implementation).
This has experimentally been much faster; I think the compiler can apply
more optimizations when it keeps the struct on the stack.
&quot;&quot;&quot;
struct StaticBuffer
  buf :: Vector{UInt8}
  ptr :: Ptr{UInt128}
end

StaticBuffer(size) = begin
  buf = Vector{UInt8}(undef, size)
  ptr = pointer(buf)
  StaticBuffer(buf, ptr)
end

Base.length(buffer::StaticBuffer) = buffer.ptr - pointer(buffer.buf)
Base.pointer(buffer::StaticBuffer) = buffer.ptr
Base.truncate(buffer::StaticBuffer) = StaticBuffer(buffer.buf, pointer(buffer.buf))

put(buffer::StaticBuffer, s::ShortString) = begin
  unsafe_store!(buffer.ptr, s.val)
  StaticBuffer(buffer.buf, buffer.ptr + s.len)
end

almostfull(buffer::StaticBuffer) = begin
  length(buffer.buf) - (buffer.ptr - pointer(buffer.buf)) &lt; PAGESIZE
end

&quot;&quot;&quot;
    withpipefd(f, io::IO, args...; kwds...)

Run `f` with a file descriptor (`::RawFD`) that is known to be a pipe; if `io`
isn't a pipe already, we insert a dummy `cat` process. This allows us to use
`vmsplice` which is much faster in the benchmark setup than `write`.
&quot;&quot;&quot;
withpipefd(f, io::Base.PipeEndpoint, args...; kwds...) = f(Base._fd(io), args...; kwds...)
withpipefd(f, io::Base.IOContext, args...; kwds...) = withpipefd(f, io.io, args...; kwds...)
withpipefd(f, io, args...; kwds...) = begin
  process = open(pipeline(`cat`, stdout=io), write=true)
  withpipefd(f, process.in, args...; kwds...)
  close(process)
end

&quot;&quot;&quot;
    vmsplice(fdesc, buffer)

Splice the data in `buffer` to the pipe in `fdesc`.
&quot;&quot;&quot;
vmsplice(fdesc::RawFD, buffer::StaticBuffer) = begin
  ptr = pointer(buffer.buf)
  while ptr &lt; buffer.ptr
    written = @ccall vmsplice(
      fdesc :: Cint,
      (ptr, buffer.ptr - ptr) :: Ref{Tuple{Ref{UInt8}, Csize_t}},
      1 :: Csize_t,
      0 :: Cuint) :: Cssize_t
    if written &lt; 0
      error(&quot;Couldn't write to pipe&quot;)
    end
    ptr += written
  end
end

&quot;&quot;&quot;
    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)

Move asciidigits and intdigits to the next line, i.e. add 1
to the ascii and decimal representations.
&quot;&quot;&quot;
@inline nextline(asciidigits, intdigits, plusone) = begin
  asciidigits += plusone
  intdigits = Base.setindex(intdigits, intdigits[1] + 1, 1)
  asciidigits, intdigits
end

const CARRY = ShortString(&quot;20&quot;) - ShortString(&quot;1:&quot;)

&quot;&quot;&quot;
    asciidigits, plusone, pluscarry = carry(position, asciidigits, plusone, pluscarry)

Perform a carry operation on asciidigits in the `position`th decimal place.
&quot;&quot;&quot;
@inline carry(position, asciidigits, plusone, pluscarry) = begin
  if position + 1 == length(asciidigits)
    asciidigits = concat(asciidigits, '0')

    plusone &lt;&lt;= 8
    pluscarry = pluscarry .&lt;&lt; 8
    pluscarry = Base.setindex(pluscarry, CARRY, position)
  end
  asciidigits += pluscarry[position]
  asciidigits, plusone, pluscarry
end

&quot;&quot;&quot;
    @compiletime for a in b
      &lt;statements&gt;
    end

Unroll the loop.
&quot;&quot;&quot;
macro compiletime(forloop)
  @assert forloop.head == :for
  it, body = forloop.args
  @assert it.head == :(=)
  lhs, rhs = it.args

  expressions = gensym(:expressions)

  body = quote
    push!($expressions, $(Expr(:quote, body)))
  end

  expressions = Core.eval(__module__, quote
    let $expressions = []
      for $lhs in $rhs
        $body
      end
      $expressions
    end
  end)

  return esc(quote
    $(expressions...)
  end)
end

&quot;&quot;&quot;
    asciidigits, intdigits, plusone, pluscarry = maybecarry(asciidigits, intdigits, plusone, pluscarry)

If necessary, perform a carry operation on asciidigits and intdigits.
&quot;&quot;&quot;
@inline maybecarry(asciidigits, intdigits, plusone, pluscarry) = begin
  asciidigits += plusone

  @compiletime for d in 1:16
    intdigits = Base.setindex(intdigits, intdigits[$d] + 1, $d)
    intdigits[$d] != 10 &amp;&amp; @goto carried
    intdigits = Base.setindex(intdigits, 0, $d)
    asciidigits, plusone, pluscarry = carry($d, asciidigits, plusone, pluscarry)
  end

  intdigits = Base.setindex(intdigits, intdigits[17] + 1, 17)
  intdigits[17] &gt;= 10 &amp;&amp; error(&quot;too big!&quot;)

  @label carried
  asciidigits, intdigits, plusone, pluscarry
end

const FIZZ = ShortString(&quot;Fizz\n&quot;)
const BUZZ = ShortString(&quot;Buzz\n&quot;)
const FIZZBUZZ = ShortString(&quot;FizzBuzz\n&quot;)

initialstate() = (
  intdigits = (1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
  asciidigits = ShortString(&quot;1\n&quot;),
  plusone = UInt128(1),
  pluscarry = ntuple(_ -&gt; zero(UInt128), Val(sizeof(UInt128)))
)

fizzbuzz(buffer::StaticBuffer, state) = begin
  (;intdigits, asciidigits, plusone, pluscarry) = state

  while !almostfull(buffer)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, FIZZ)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits, plusone, pluscarry = maybecarry(asciidigits, intdigits, plusone, pluscarry)
    buffer = put(buffer, BUZZ)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, FIZZ)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, FIZZ)

    asciidigits, intdigits, plusone, pluscarry = maybecarry(asciidigits, intdigits, plusone, pluscarry)
    buffer = put(buffer, BUZZ)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, FIZZ)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
    buffer = put(buffer, asciidigits)

    asciidigits, intdigits, plusone, pluscarry = maybecarry(asciidigits, intdigits, plusone, pluscarry)
    buffer = put(buffer, FIZZBUZZ)

    asciidigits, intdigits = nextline(asciidigits, intdigits, plusone)
  end
  buffer, (;intdigits,asciidigits,plusone,pluscarry)
end

fizzbuzz(fdesc::RawFD, cutoff=typemax(Int)) = begin
  pipesize = @ccall fcntl(fdesc::Cint, 1031::Cint, BUFSIZE::Cint)::Cint
  @assert pipesize == BUFSIZE

  buf1, buf2 = StaticBuffer(BUFSIZE), StaticBuffer(BUFSIZE)

  state = initialstate()
  n = 0

  @GC.preserve buf1 buf2 while n &lt;= cutoff

    buf1, state = fizzbuzz(truncate(buf1), state)
    vmsplice(fdesc, buf1)
    n += length(buf1)


    buf2, state = fizzbuzz(truncate(buf2), state)
    vmsplice(fdesc, buf2)
    n += length(buf2)
  end
end

&quot;&quot;&quot;
  fizzbuzz(io::IO, cutoff=typemax(Int))

Write the fizzbuzz output to `io`.

The `cutoff` parameter is approximate; depending on buffering, more bytes
may be written to `io`.
&quot;&quot;&quot;
fizzbuzz(io::IO, cutoff=typemax(Int)) = withpipefd(fizzbuzz, io, cutoff)

if abspath(PROGRAM_FILE) == @__FILE__
  fizzbuzz(stdout)
end
</code></pre>
</div>
<div id="pu4" class="pu"><p>Here's my answer in <em>Elixir</em>: <a href="https://github.com/technusm1/fizzbuzz" rel="nofollow noreferrer">https://github.com/technusm1/fizzbuzz</a></p>
<p>Its a full-fledged mix project, so I hosted it on GitHub. On my system MacBook Pro 16-inch 2019 (2.6 GHz 6-Core Intel Core i7), I get the following throughput:</p>
<ul>
<li>OP's naive C implementation: 68 MiB/s</li>
<li>My naive elixir implementation: 2 MiB/s</li>
<li>My concurrent elixir implementation: 225 MiB/s (breached 200 MiB/s, yay!)</li>
</ul>
<p>My latest optimization:</p>
<ul>
<li>Using a binary as my GenServer state instead of iolist in <code>Fizzbuzz.Worker</code>. This reduces message passing overhead when calling <code>IO.binwrite</code> while issuing <code>print</code> command.
Here's the code:</li>
</ul>
<pre><code>defmodule Fizzbuzz do
  def fizzbuzz_no_io(enumerable) do
    Stream.map(enumerable, &amp;reply/1)
    |&gt; Stream.chunk_every(5000)
    |&gt; Enum.into([])
  end

  def reply(n) when rem(n, 15) == 0, do: &lt;&lt;70, 105, 122, 122, 66, 117, 122, 122, 10&gt;&gt;
  def reply(n) when rem(n, 3) == 0, do: &lt;&lt;70, 105, 122, 122, 10&gt;&gt;
  def reply(n) when rem(n, 5) == 0, do: &lt;&lt;66, 117, 122, 122, 10&gt;&gt;
  def reply(n), do: [Integer.to_string(n), &lt;&lt;10&gt;&gt;]
end

defmodule Fizzbuzz.Cli do
  def main([lower, upper]) do
    {lower, upper} = {String.to_integer(lower), String.to_integer(upper)}
    chunk_size = min(div(upper - lower, System.schedulers_online()), 6000)

    if chunk_size == 6000 do
      # We'll divide the input range into 3 parts: beginning, 6k ranges and ending
      # beginning and ending will be processed before and after stream.run respectively.
      input_lower =
        case rem(lower, 15) do
          1 -&gt;
            lower

          0 -&gt;
            IO.binwrite(&quot;FizzBuzz\n&quot;)
            lower + 1

          remainder -&gt;
            IO.binwrite(Fizzbuzz.fizzbuzz_no_io(lower..(15 - remainder + lower)))
            15 - remainder + lower + 1
        end

      input_upper =
        case rem(upper - input_lower + 1, 6000) do
          0 -&gt; upper
          remainder -&gt; upper - remainder
        end

      input_enumerable = Chunk6kStream.create(input_lower..input_upper)

      Task.async_stream(
        input_enumerable,
        fn input -&gt; elem(GenServer.start_link(Fizzbuzz.Worker, [input]), 1) end,
        timeout: :infinity
      )
      |&gt; Stream.map(fn {:ok, res} -&gt; res end)
      |&gt; Stream.each(fn pid -&gt;
        GenServer.call(pid, :print)
        Process.exit(pid, :kill)
      end)
      |&gt; Stream.run()

      if input_upper &lt; upper do
        IO.binwrite(Fizzbuzz.fizzbuzz_no_io(input_upper+1..upper))
      end
    else
      input_enumerable = get_input_ranges2(lower, upper, chunk_size)

      Task.async_stream(
        input_enumerable,
        fn input -&gt; elem(GenServer.start_link(Fizzbuzz.Worker, [input]), 1) end,
        timeout: :infinity
      )
      |&gt; Stream.map(fn {:ok, res} -&gt; res end)
      |&gt; Stream.each(fn pid -&gt;
        GenServer.call(pid, :print)
        Process.exit(pid, :kill)
      end)
      |&gt; Stream.run()
    end
  end

  def main(_), do: IO.puts(&quot;Usage: fizzbuzz 1 10000&quot;)

  defp get_input_ranges2(lower, upper, chunk_size) do
    # Need to make this streamable
    if chunk_size &gt;= 10 do
      ChunkRangeStream.create(lower..upper, chunk_size)
    else
      [lower..upper]
    end
  end
end

defmodule Chunk6kStream do
  # Make sure that range has size of multiples of 6000 and range.first is divisible by 15
  def create(range) do
    Stream.resource(fn -&gt; initialize(range) end, &amp;generate_next_value/1, &amp;done/1)
  end

  defp initialize(range) do
    {range, range.first, range.last}
  end

  defp generate_next_value({range, lower, upper}) when lower == upper + 1 do
    {:halt, {range, upper, upper}}
  end

  defp generate_next_value({range, lower, upper}) do
    {[lower..(lower + 5999)], {range, lower + 6000, upper}}
  end

  defp done(_) do
    nil
  end
end

defmodule ChunkRangeStream do
  def create(range, chunk_size) do
    Stream.resource(fn -&gt; initialize(range, chunk_size) end, &amp;generate_next_value/1, &amp;done/1)
  end

  defp initialize(range, chunk_size) do
    {range, chunk_size, range.first}
  end

  defp generate_next_value({range, chunk_size, lower}) do
    if lower &lt; range.last do
      {[lower..min(lower + chunk_size, range.last)],
       {range, chunk_size, min(range.last, lower + chunk_size + 1)}}
    else
      {:halt, {range, chunk_size, lower}}
    end
  end

  defp done(_) do
    nil
  end
end

defmodule Fizzbuzz.Worker do
  use GenServer

  def init([range]) do
    send(self(), {:calculate, range})
    {:ok, []}
  end

  def handle_info({:calculate, range}, _state) do
    res = if Range.size(range) == 6000 do
      i = range.first - 1
      0..(400-1)
      |&gt; Stream.map(fn j -&gt;
        [[Integer.to_string(15 * j + 1 + i), &quot;\n&quot;], [Integer.to_string(15 * j + 2 + i), &quot;\n&quot;], &quot;Fizz\n&quot;, [Integer.to_string(15 * j + 4 + i), &quot;\n&quot;], &quot;Buzz\nFizz\n&quot;, [Integer.to_string(15 * j + 7 + i), &quot;\n&quot;], [Integer.to_string(15 * j + 8 + i), &quot;\n&quot;], &quot;Fizz\nBuzz\n&quot;, [Integer.to_string(15 * j + 11 + i), &quot;\n&quot;], &quot;Fizz\n&quot;, [Integer.to_string(15 * j + 13 + i), &quot;\n&quot;], [Integer.to_string(15 * j + 14 + i), &quot;\n&quot;], &quot;FizzBuzz\n&quot;]
      end)
      |&gt; Stream.chunk_every(400)
      |&gt; Enum.into([])
    else
      Fizzbuzz.fizzbuzz_no_io(range)
    end

    {:noreply, res |&gt; :erlang.iolist_to_binary}
  end

  def handle_call(:print, _from, results) do
    IO.binwrite(results)
    {:reply, :ok, []}
  end
end
<span class="math-container">```</span>
</code></pre>
</div>
<div id="pu5" class="pu"><h1>Python 3</h1>
<p>We use fstrings to create blocks of 300 lines, and reduce the number of conversions from int to str by counting by 100.</p>
<pre><code>def fizz_buzz(write):
    write(
        &quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n11\nFizz\n13\n14\nFiz&quot;
        &quot;zBuzz\n16\n17\nFizz\n19\nBuzz\nFizz\n22\n23\nFizz\nBuzz\n26\nFizz&quot;
        &quot;\n28\n29\nFizzBuzz\n31\n32\nFizz\n34\nBuzz\nFizz\n37\n38\nFizz\nBu&quot;
        &quot;zz\n41\nFizz\n43\n44\nFizzBuzz\n46\n47\nFizz\n49\nBuzz\nFizz\n52\n&quot;
        &quot;53\nFizz\nBuzz\n56\nFizz\n58\n59\nFizzBuzz\n61\n62\nFizz\n64\nBuzz&quot;
        &quot;\nFizz\n67\n68\nFizz\nBuzz\n71\nFizz\n73\n74\nFizzBuzz\n76\n77\nFi&quot;
        &quot;zz\n79\nBuzz\nFizz\n82\n83\nFizz\nBuzz\n86\nFizz\n88\n89\nFizzBuzz&quot;
        &quot;\n91\n92\nFizz\n94\nBuzz\nFizz\n97\n98\nFizz\nBuzz\n&quot;
    )
    h = 0
    while True:
        h += 1
        c1 = str(h)
        h += 1
        c2 = str(h)
        h += 1
        c3 = str(h)
        write(
            f&quot;{c1}01\nFizz\n{c1}03\n{c1}04\nFizzBuzz\n{c1}06\n{c1}07\nFizz\n{c1}09\nBuzz\n&quot;
            f&quot;Fizz\n{c1}12\n{c1}13\nFizz\nBuzz\n{c1}16\nFizz\n{c1}18\n{c1}19\nFizzBuzz\n&quot;
            f&quot;{c1}21\n{c1}22\nFizz\n{c1}24\nBuzz\nFizz\n{c1}27\n{c1}28\nFizz\nBuzz\n&quot;
            f&quot;{c1}31\nFizz\n{c1}33\n{c1}34\nFizzBuzz\n{c1}36\n{c1}37\nFizz\n{c1}39\nBuzz\n&quot;
            f&quot;Fizz\n{c1}42\n{c1}43\nFizz\nBuzz\n{c1}46\nFizz\n{c1}48\n{c1}49\nFizzBuzz\n&quot;
            f&quot;{c1}51\n{c1}52\nFizz\n{c1}54\nBuzz\nFizz\n{c1}57\n{c1}58\nFizz\nBuzz\n&quot;
            f&quot;{c1}61\nFizz\n{c1}63\n{c1}64\nFizzBuzz\n{c1}66\n{c1}67\nFizz\n{c1}69\nBuzz\n&quot;
            f&quot;Fizz\n{c1}72\n{c1}73\nFizz\nBuzz\n{c1}76\nFizz\n{c1}78\n{c1}79\nFizzBuzz\n&quot;
            f&quot;{c1}81\n{c1}82\nFizz\n{c1}84\nBuzz\nFizz\n{c1}87\n{c1}88\nFizz\nBuzz\n&quot;
            f&quot;{c1}91\nFizz\n{c1}93\n{c1}94\nFizzBuzz\n{c1}96\n{c1}97\nFizz\n{c1}99\nBuzz\n&quot;
            f&quot;Fizz\n{c2}02\n{c2}03\nFizz\nBuzz\n{c2}06\nFizz\n{c2}08\n{c2}09\nFizzBuzz\n&quot;
            f&quot;{c2}11\n{c2}12\nFizz\n{c2}14\nBuzz\nFizz\n{c2}17\n{c2}18\nFizz\nBuzz\n&quot;
            f&quot;{c2}21\nFizz\n{c2}23\n{c2}24\nFizzBuzz\n{c2}26\n{c2}27\nFizz\n{c2}29\nBuzz\n&quot;
            f&quot;Fizz\n{c2}32\n{c2}33\nFizz\nBuzz\n{c2}36\nFizz\n{c2}38\n{c2}39\nFizzBuzz\n&quot;
            f&quot;{c2}41\n{c2}42\nFizz\n{c2}44\nBuzz\nFizz\n{c2}47\n{c2}48\nFizz\nBuzz\n&quot;
            f&quot;{c2}51\nFizz\n{c2}53\n{c2}54\nFizzBuzz\n{c2}56\n{c2}57\nFizz\n{c2}59\nBuzz\n&quot;
            f&quot;Fizz\n{c2}62\n{c2}63\nFizz\nBuzz\n{c2}66\nFizz\n{c2}68\n{c2}69\nFizzBuzz\n&quot;
            f&quot;{c2}71\n{c2}72\nFizz\n{c2}74\nBuzz\nFizz\n{c2}77\n{c2}78\nFizz\nBuzz\n&quot;
            f&quot;{c2}81\nFizz\n{c2}83\n{c2}84\nFizzBuzz\n{c2}86\n{c2}87\nFizz\n{c2}89\nBuzz\n&quot;
            f&quot;Fizz\n{c2}92\n{c2}93\nFizz\nBuzz\n{c2}96\nFizz\n{c2}98\n{c2}99\nFizzBuzz\n&quot;
            f&quot;{c3}01\n{c3}02\nFizz\n{c3}04\nBuzz\nFizz\n{c3}07\n{c3}08\nFizz\nBuzz\n&quot;
            f&quot;{c3}11\nFizz\n{c3}13\n{c3}14\nFizzBuzz\n{c3}16\n{c3}17\nFizz\n{c3}19\nBuzz\n&quot;
            f&quot;Fizz\n{c3}22\n{c3}23\nFizz\nBuzz\n{c3}26\nFizz\n{c3}28\n{c3}29\nFizzBuzz\n&quot;
            f&quot;{c3}31\n{c3}32\nFizz\n{c3}34\nBuzz\nFizz\n{c3}37\n{c3}38\nFizz\nBuzz\n&quot;
            f&quot;{c3}41\nFizz\n{c3}43\n{c3}44\nFizzBuzz\n{c3}46\n{c3}47\nFizz\n{c3}49\nBuzz\n&quot;
            f&quot;Fizz\n{c3}52\n{c3}53\nFizz\nBuzz\n{c3}56\nFizz\n{c3}58\n{c3}59\nFizzBuzz\n&quot;
            f&quot;{c3}61\n{c3}62\nFizz\n{c3}64\nBuzz\nFizz\n{c3}67\n{c3}68\nFizz\nBuzz\n&quot;
            f&quot;{c3}71\nFizz\n{c3}73\n{c3}74\nFizzBuzz\n{c3}76\n{c3}77\nFizz\n{c3}79\nBuzz\n&quot;
            f&quot;Fizz\n{c3}82\n{c3}83\nFizz\nBuzz\n{c3}86\nFizz\n{c3}88\n{c3}89\nFizzBuzz\n&quot;
            f&quot;{c3}91\n{c3}92\nFizz\n{c3}94\nBuzz\nFizz\n{c3}97\n{c3}98\nFizz\nBuzz\n&quot;
        )

if __name__ == &quot;__main__&quot;:
    import sys
    fizz_buzz(sys.stdout.write)
</code></pre>
<p>On my laptop (i7-1165G7):</p>
<ul>
<li>python (3.11.3): 0.6 GiB/s</li>
<li>pypy3 (7.3.12):  1.3 GiB/s</li>
</ul>
</div>
<div id="pu6" class="pu"><p>Just normal Go</p>
<pre class="lang-go prettyprint-override"><code>package main
import (
  &quot;bufio&quot;
  &quot;fmt&quot;
  &quot;os&quot;
)
var writer *bufio.Writer = bufio.NewWriter(os.Stdout)
func printf(f string, a ...interface{}) { fmt.Fprintf(writer, f, a...) }

func main() {
    defer writer.Flush()
    for i := 1; i &lt; 1000000000; i++ {
        if (i % 3 == 0) &amp;&amp; (i % 5 == 0) {
            printf(&quot;FizzBuzz\n&quot;)
        } else if i % 3 == 0 {
            printf(&quot;Fizz\n&quot;)
        } else if i % 5 == 0 {
            printf(&quot;Buzz\n&quot;)
        } else {
            printf(&quot;%d\n&quot;,i)
        }
    }
}
</code></pre>
<p>Unrolled output version:</p>
<pre class="lang-go prettyprint-override"><code>package main
import (
    &quot;bufio&quot;
    &quot;fmt&quot;
    &quot;os&quot;
)
var writer *bufio.Writer = bufio.NewWriter(os.Stdout)
// or: bufio.NewWriterSize(os.Stdout, 400 * 1024 * 1024)
func printf(f string, a ...interface{}) { fmt.Fprintf(writer, f, a...) }
func main() {
    const FMT = &quot;%d\n%d\nFizz\n%d\nBuzz\nFizz\n%d\n%d\nFizz\nBuzz\n%d\nFizz\n%d\n%d\nFizzBuzz&quot;
    defer writer.Flush()
    for i := 1; i &lt; 1000000000; i += 15 {
        printf(FMT, i, i+1, i+3, i+6, i+7, i+10, i+12, i+13)
    }
}
</code></pre>
<p>Unbuffered output version:</p>
<pre class="lang-go prettyprint-override"><code>package main
import &quot;fmt&quot;
func main() {
    for i := 1; i &lt; 1000000000; i++ {
        if (i % 3 == 0) &amp;&amp; (i % 5 == 0) {
            fmt.Println(&quot;FizzBuzz&quot;)
        } else if i % 3 == 0 {
            fmt.Println(&quot;Fizz&quot;)
        } else if i % 5 == 0 {
            fmt.Println(&quot;Buzz&quot;)
        } else {
            fmt.Printf(&quot;%d\n&quot;,i)
        }
    }
}
</code></pre>
<p>On my machine:</p>
<pre><code>gcc version 11.3.0 (Ubuntu 11.3.0-1ubuntu1~22.04.1)
gcc a.c &amp;&amp; ./a.out | pv &gt; /dev/null

go version go1.20.5 linux/amd64
go build a.go &amp;&amp; ./a | pv &gt; /dev/null
</code></pre>
<ul>
<li>C example: <code>7.33GiB 0:00:26 [ 282MiB/s]</code></li>
<li>Go: <code>7.33GiB 0:00:56 [ 133MiB/s]</code></li>
<li>Go (400MB buffer): <code>7.33GiB 0:00:49 [ 151MiB/s]</code></li>
<li>Unrolled Go: <code>7.27GiB 0:00:32 [ 229MiB/s]</code></li>
<li>Unrolled Go (400MB buffer): <code>7.27GiB 0:00:25 [ 291MiB/s]</code></li>
<li>unbuffered Go: <code>7.33GiB 0:05:50 [21.4MiB/s]</code></li>
</ul>
</div>
<div id="pu7" class="pu"><p>This python two-liner (!) is getting &gt;500 MiB/s with pypy on MacBook Pro M1 Max:</p>
<pre><code>$ cat fizzbuzz.py
for i in range (0,1000000000000,15):
   print(&quot;%d\n%d\nfizz\n%d\nbuzz\nfizz\n%d\n%d\nfizz\nbuzz\n%d\nfizz\n%d\n%d\nfizzbuzz\n&quot; 
      % (1+i, 2+i, 4+i, 7+i, 8+i, 11+i, 13+i, 14+i))

$ python3 fizzbuzz.py|pv &gt; /dev/null
3.73GiB 0:00:27 [ 143MiB/s] [                                                                                 

$ pypy fizzbuzz.py|pv &gt; /dev/null
70.3GiB 0:02:17 [ 525MiB/s] [
</code></pre>
<p>Pypy throughput is very stable at around 522-525 MiB/s.</p>
<p>I can get additional 100 MiB/s by working on 30 values at the time.. so there's more to achieve by further output chunking.</p>
<p>A bit boring solution, but by stepping 60 at the time, this achieves 740 MiB/s with pypy, and 180 MiB/s with python3:</p>
<pre><code>import sys
for i in range (0,100000000000,60):
    sys.stdout.write(&quot;%d\n%d\nfizz\n%d\nbuzz\nfizz\n%d\n%d\nfizz\nbuzz\n%d\nfizz\n%d\n%d\nfizzbuzz\n%d\n%d\nfizz\n%d\nbuzz\nfizz\n%d\n%d\nfizz\nbuzz\n%d\nfizz\n%d\n%d\nfizzbuzz\n%d\n%d\nfizz\n%d\nbuzz\nfizz\n%d\n%d\nfizz\nbuzz\n%d\nfizz\n%d\n%d\nfizzbuzz\n%d\n%d\nfizz\n%d\nbuzz\nfizz\n%d\n%d\nfizz\nbuzz\n%d\nfizz\n%d\n%d\nfizzbuzz\n&quot;
        % ( 1+i,  2+i,  4+i,  7+i,  8+i, 11+i, 13+i, 14+i,
           16+i, 17+i, 19+i, 22+i, 23+i, 26+i, 28+i, 29+i,
           31+i, 32+i, 34+i, 37+i, 38+i, 41+i, 43+i, 44+i,
           46+i, 47+i, 49+i, 52+i, 53+i, 56+i, 58+i, 59+i ))


$ python3  fizzbuzz.py|pv &gt; /dev/null
18.1GiB 0:01:40 [ 185MiB/s] 

$ pypy  fizzbuzz.py|pv &gt; /dev/null
30.1GiB 0:00:42 [ 739MiB/s] [
</code></pre>
</div>
<div id="pu8" class="pu"><p>this is inspired by the previous Rust entry by aiden4 at <a href="https://codegolf.stackexchange.com/a/217455/118590">https://codegolf.stackexchange.com/a/217455/118590</a></p>
<p>it's a threaded version of aiden4's code, with the macros replaced by inline functions, because i haven't learned macros yet =)</p>
<p>this will utilize all logical CPUs up to MAX_THREADS, and uses one thread to handle synchronization.</p>
<p>build with <code>cargo build --release</code> and run with <code>./target/release/fizz_buzz_threaded</code></p>
<p>/.cargo/config.toml (please adjust as necessary):</p>
<pre><code>[target.x86_64-unknown-linux-gnu]
rustflags = [&quot;-Ctarget-cpu=native&quot;]

[target.x86_64-pc-windows-msvc]
rustflags = [&quot;-Ctarget-cpu=native&quot;]

[target.x86_64-pc-windows-gnu]
rustflags = [&quot;-Ctarget-cpu=native&quot;]
</code></pre>
<p>main.rs:</p>
<pre><code>use std::io::*;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::thread;
extern crate num_cpus;
const FIZZ: *const u8 = &quot;Fizz\n&quot;.as_ptr();
const BUZZ: *const u8 = &quot;Buzz\n&quot;.as_ptr();
const FIZZBUZZ: *const u8 = &quot;FizzBuzz\n&quot;.as_ptr();
const MAX_NUM: usize = 90_000; // results to cache before writing output
const MAX_THREADS: usize = 256;
const BUF_SIZE: usize = MAX_NUM * 207; // i think max size for one round of fizz buzz ANSI is 206 bytes?
const UATOMIC: AtomicUsize = AtomicUsize::new(0);
static mut BUFS: [[u8; BUF_SIZE]; MAX_THREADS] = [[0u8; BUF_SIZE]; MAX_THREADS];
static mut BUF_COUNTS: [usize; MAX_THREADS] = [0usize; MAX_THREADS];
static mut LOCKS: [AtomicUsize; MAX_THREADS] = [UATOMIC; MAX_THREADS];

unsafe fn sync_threads(threads: usize) {
    let mut synced = false;
    let mut val: usize;
    let mut out = stdout();
    loop {
        for x in 0..threads {
            val = LOCKS[x].load(Ordering::SeqCst);
            if val == 1 {
                synced = true;
            } else {
                synced = false;
                break;
            }
        }
        if synced {
            for x in 0..threads {
                let res = out.write_all(BUFS[x].get_unchecked(..BUF_COUNTS[x]));
                if res.is_err() {
                    println!(&quot;{:?}&quot;, res.err());
                }
                LOCKS[x].store(0, Ordering::SeqCst);
            }
        }
    }
}

unsafe fn thread(id: usize, mut num: usize, worker_threads: usize) {
    // alas, i haven't learned macros yet
    unsafe fn itoap_write(id: usize, buf_count: &amp;mut usize, num: usize) {
        *buf_count +=
            itoap::write_to_ptr(BUFS[id].get_unchecked_mut(*buf_count..).as_mut_ptr(), num);
        BUFS[id].as_mut_ptr().add(*buf_count).write(b'\n');
        *buf_count += 1;
    }
    unsafe fn str_write(id: usize, buf_count: &amp;mut usize, string: *const u8, len: usize) {
        let ptr = BUFS[id].get_unchecked_mut(*buf_count..).as_mut_ptr();
        ptr.copy_from_nonoverlapping(string, len);
        *buf_count += len;
    }
    let mut val: usize;
    let mut count: usize = 0;
    num += 1;
    let number_skip = (worker_threads - 1) * MAX_NUM;
    loop {
        val = LOCKS[id].load(Ordering::SeqCst);
        if val == 0 {
            if count &gt; MAX_NUM - 15 {
                count = 0;
                LOCKS[id].store(1, Ordering::SeqCst);
                loop {
                    val = LOCKS[id].load(Ordering::SeqCst);
                    if val == 0 {
                        BUF_COUNTS[id] = 0;
                        num += number_skip;
                        break;
                    }
                }
                continue;
            }
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            num += 1;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            str_write(id, &amp;mut BUF_COUNTS[id], FIZZ, 5);
            num += 2;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            str_write(id, &amp;mut BUF_COUNTS[id], BUZZ, 5);
            str_write(id, &amp;mut BUF_COUNTS[id], FIZZ, 5);
            num += 3;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            num += 1;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            str_write(id, &amp;mut BUF_COUNTS[id], FIZZ, 5);
            str_write(id, &amp;mut BUF_COUNTS[id], BUZZ, 5);
            num += 3;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            str_write(id, &amp;mut BUF_COUNTS[id], FIZZ, 5);
            num += 2;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            num += 1;
            itoap_write(id, &amp;mut BUF_COUNTS[id], num);
            str_write(id, &amp;mut BUF_COUNTS[id], FIZZBUZZ, 9);
            num += 2;
            count += 15;
        }
    }
}

fn main() {
    let max_threads = num_cpus::get();
    if max_threads &lt; 2 {
        panic!(&quot;multi-cpu only!&quot;)
    }
    let mut thread_ids: Vec&lt;usize&gt; = Vec::with_capacity(max_threads);
    for x in 0..max_threads {
        thread_ids.push(x);
    }
    thread::scope(|s| {
        for x in thread_ids.iter_mut() {
            if *x == max_threads - 1 {
                let builder = thread::Builder::new();
                let res = builder.spawn_scoped(s, || unsafe { sync_threads(max_threads - 1) });
                if res.is_err() {
                    println!(&quot;Error spinning up sync thread: {}&quot;, res.err().unwrap());
                }
            } else {
                let builder = thread::Builder::new();
                let res = builder
                    .spawn_scoped(s, || unsafe { thread(*x, *x * MAX_NUM, max_threads - 1) });
                if res.is_err() {
                    println!(&quot;Error spinning up worker thread: {}&quot;, res.err().unwrap());
                }
            }
        }
    });
}
</code></pre>
<p>Cargo.toml:</p>
<pre><code>[package]
name = &quot;fizz_buzz_threaded&quot;
version = &quot;0.1.0&quot;
authors = [&quot;0xDEADFED5&quot;,&quot;aiden4&quot;]
edition = &quot;2021&quot;

[dependencies]
num_cpus = &quot;1.15.0&quot;
itoap = &quot;0.1&quot;

[profile.release]
lto = &quot;fat&quot;
</code></pre>
<p>also available at <a href="https://github.com/0xDEADFED5/fizz_buzz_threaded" rel="nofollow noreferrer">https://github.com/0xDEADFED5/fizz_buzz_threaded</a></p>
</div>
<div id="pu9" class="pu"><h1>Python</h1>
<p>Here is my humble attempt. It seems to out-perform the other python alternatives on my machine. I'm getting a sustained ~=330-367 MiB/s.</p>
<p>Run with python3, and tested with pypy3 (which seems to be little bit slower 320-360 MiB/s).</p>
<pre class="lang-py prettyprint-override"><code>from sys import stdout
from io import StringIO


fz = &quot;Fizz&quot;
bz = &quot;Buzz&quot;
nl = &quot;\n&quot;
def fizzbuzz():
    num = 1
    while True:
        nf = True
        if num % 3 == 0:
            nf = False
            yield fz
        if num % 5 == 0:
            nf = False
            yield bz
        if nf:
            yield str(num)
        yield nl
        num += 1

output = StringIO()
for a in fizzbuzz():
    output.write(a)
    stdout.write(output.getvalue())
    output.truncate(0)
</code></pre>
<p>It uses a StringIO object which, as far as I understand, is implemented in a more efficient way, together with <code>stdout.write</code>, which again, seems to perform better than <code>print</code> and <code>os.write</code>.</p>
<p>I'm also storing the string-parts as variables. It seems to perform better, but that might be just placebo.</p>
<p>I have made a few variations on this with bulking, and writing more numbers/fizzbuzz to the <code>output</code>-parameter before writing to <code>stdout</code>, but it only seems to slow it down. I'm not sure why that is, but perhaps I get more lucky with L1/L2 cache with the current approach.</p>
</div>
<div id="pu10" class="pu"><h1>Java 17</h1>
<p>Compile and run with <code>java FizzBuzz.java</code>.</p>
<p>The algorithm is correct for numbers up to 2^63-1.</p>
<pre class="lang-java prettyprint-override"><code>import java.io.FileDescriptor;
import java.io.FileOutputStream;
import java.nio.ByteBuffer;
import java.util.concurrent.Callable;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;

import static java.nio.charset.StandardCharsets.US_ASCII;

public final class FizzBuzz {

  private static final int BUFFER_SIZE = 1 &lt;&lt; 16;
  private static final long STARTING_NUMBER = 10L;
  private static final long SIZE_FOR_30 = 2 * (17 * 8 + 47);
  private static final long FULL_INCREMENT = BUFFER_SIZE / SIZE_FOR_30 * 30;
  private static final long LIGHT_INCREMENT = FULL_INCREMENT - 30;
  private static final int[] BASE_IDX = {-1, 6, 8, 19, 21, 28, 40, 42, 54, 61, 63, 74, 76, 83, 95, 97};
  private static final int[][] IDX = new int[19][16];

  static {
    IDX[1] = BASE_IDX;
    for (var i = 2; i &lt; IDX.length; i++) {
      for (var j = 0; j &lt; 16; ) {
        IDX[i][j] = IDX[i - 1][j] + ++j;
      }
    }
  }


  public static void main(String[] args) {
    var threads = Runtime.getRuntime().availableProcessors();
    var queue = new LinkedBlockingQueue&lt;Future&lt;ByteBuffer&gt;&gt;(threads);
    var executor = Executors.newFixedThreadPool(threads);
    try (var outputStream = new FileOutputStream(FileDescriptor.out);
         var channel = outputStream.getChannel()) {

      var counter = STARTING_NUMBER;
      for (var i = 0; i &lt; threads; i++) {
        var buffer = ByteBuffer.allocateDirect(BUFFER_SIZE);
        queue.offer(executor.submit(new Task(counter, buffer)));
        counter += FULL_INCREMENT;
      }
      channel.write(ByteBuffer.wrap(&quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n&quot;.getBytes(US_ASCII)));
      while (true) {
        var buffer = queue.poll().get();
        channel.write(buffer);
        queue.offer(executor.submit(new Task(counter, buffer)));
        counter += FULL_INCREMENT;
      }
    } catch (Exception e) {
      e.printStackTrace(System.err);
    } finally {
      executor.shutdown();
    }
  }

  record Task(long startingNumber, ByteBuffer buffer) implements Callable&lt;ByteBuffer&gt; {

    @Override
    public ByteBuffer call() {
      buffer.clear();
      var n = startingNumber;
      var nextPowerOf10 = 10L;
      var digitCount = 1;
      for (; nextPowerOf10 &lt;= n; nextPowerOf10 *= 10L) {
        digitCount++;
      }
      var idx = IDX[digitCount];
      var t = n / 10L;
      var s = Long.toString(t);
      var template = (s + &quot;1\nFizz\n&quot; +
        s + &quot;3\n&quot; +
        s + &quot;4\nFizzBuzz\n&quot; +
        s + &quot;6\n&quot; +
        s + &quot;7\nFizz\n&quot; +
        s + &quot;9\nBuzz\nFizz\n&quot; +
        (s = Long.toString(++t)) + &quot;2\n&quot; +
        s + &quot;3\nFizz\nBuzz\n&quot; +
        s + &quot;6\nFizz\n&quot; +
        s + &quot;8\n&quot; +
        s + &quot;9\nFizzBuzz\n&quot; +
        (s = Long.toString(++t)) + &quot;1\n&quot; +
        s + &quot;2\nFizz\n&quot; +
        s + &quot;4\nBuzz\nFizz\n&quot; +
        s + &quot;7\n&quot; +
        s + &quot;8\nFizz\nBuzz\n&quot;).getBytes(US_ASCII);
      n += 30;
      buffer.put(template);

      for (var limit = n + LIGHT_INCREMENT; n &lt; limit; n += 30L) {
        if (n == nextPowerOf10) {
          nextPowerOf10 *= 10;
          digitCount++;
          idx = IDX[digitCount];
          t = n / 10L;
          s = Long.toString(t);
          template = (s + &quot;1\nFizz\n&quot; +
            s + &quot;3\n&quot; +
            s + &quot;4\nFizzBuzz\n&quot; +
            s + &quot;6\n&quot; +
            s + &quot;7\nFizz\n&quot; +
            s + &quot;9\nBuzz\nFizz\n&quot; +
            (s = Long.toString(++t)) + &quot;2\n&quot; +
            s + &quot;3\nFizz\nBuzz\n&quot; +
            s + &quot;6\nFizz\n&quot; +
            s + &quot;8\n&quot; +
            s + &quot;9\nFizzBuzz\n&quot; +
            (s = Long.toString(++t)) + &quot;1\n&quot; +
            s + &quot;2\nFizz\n&quot; +
            s + &quot;4\nBuzz\nFizz\n&quot; +
            s + &quot;7\n&quot; +
            s + &quot;8\nFizz\nBuzz\n&quot;).getBytes(US_ASCII);
        } else {
          for (var i = 0; i &lt; idx.length; ) {
            var pos = idx[i++];
            template[pos] += 3;
            while (template[pos] &gt; '9') {
              template[pos] -= 10;
              template[--pos]++;
            }
          }
        }
        buffer.put(template);
      }
      return buffer.flip();
    }
  }

}

/*
 * Speed references:
 *   - 270 GiB / min ± 3.95 / min on Macbook Pro 2021
 */

</code></pre>
</div>
<div id="pu11" class="pu"><p>Updated code: This code (no more strings) gets me to 4.8GiB/s. Can't break the 5 GiB/s barrier on the M1 with the naive implementation :-(. Also, larger segments, even more memory. However, this has better throughput than just writing empty arrays to the stdout (even with draining to the direct byte buffer).</p>
<pre class="lang-java prettyprint-override"><code>import java.io.FileDescriptor;
import java.io.FileOutputStream;
import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;
import java.util.LinkedList;
import java.util.Optional;
import java.util.Queue;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ForkJoinPool;
import java.util.function.Consumer;
import java.util.function.Supplier;
import java.util.stream.IntStream;

public class FizzBuzz {

    static final String NEWLINE = String.format(&quot;%n&quot;);

    static byte[] fizzbuzz = &quot;fizzbuzz\n&quot;.getBytes(StandardCharsets.ISO_8859_1);
    static byte[] fizz = &quot;fizz\n&quot;.getBytes(StandardCharsets.ISO_8859_1);
    static byte[] buzz = &quot;buzz\n&quot;.getBytes(StandardCharsets.ISO_8859_1);
    static byte newline = &quot;\n&quot;.getBytes(StandardCharsets.ISO_8859_1)[0];
    static byte zero = (byte) '0';

    static int fizzBuzz(long src, byte[] destination, int destinationPos, byte[] digitsHelper, int digitsHelperLast) {
        if (src % 15 == 0) {
            System.arraycopy(fizzbuzz, 0, destination, destinationPos, fizzbuzz.length);
            return destinationPos + fizzbuzz.length;
        } else if (src % 5 == 0) {
            System.arraycopy(fizz, 0, destination, destinationPos, fizz.length);
            return destinationPos + fizz.length;
        } else if (src % 3 == 0) {
            System.arraycopy(buzz, 0, destination, destinationPos, buzz.length);
            return destinationPos + buzz.length;
        } else {
            do {
                digitsHelper[digitsHelperLast--] = (byte) (zero + src % 10);
                src /= 10;
            } while (src != 0);
            int len = digitsHelper.length - digitsHelperLast;
            System.arraycopy(digitsHelper, digitsHelperLast, destination, destinationPos, len);
            return destinationPos + len;
        }

    }

    record Pair(byte[] item1, ByteBuffer item2) {
    }


    public static void main(String[] argv) throws Exception {

        final var channel = new FileOutputStream(FileDescriptor.out).getChannel();

        final Consumer&lt;ByteBuffer&gt; writeToChannel = bb -&gt; {
            try {
                while (bb.hasRemaining()) {
                    channel.write(bb);
                }
            } catch (Exception ex) {
                ex.printStackTrace();
                System.exit(1);
            }
        };

        final var segment = 10_000_000;
        final var arralloc = 20 * segment;

        final Queue&lt;CompletableFuture&lt;Pair&gt;&gt; queue =
                new LinkedList&lt;&gt;
                        (IntStream.range(0, Optional.of(ForkJoinPool.getCommonPoolParallelism() - 1).filter(i -&gt; i &gt; 0).orElse(1))
                                .mapToObj(i -&gt;
                                        CompletableFuture.completedFuture(new Pair(new byte[arralloc], ByteBuffer.allocateDirect(arralloc)))).toList());

        CompletableFuture&lt;?&gt; last = CompletableFuture.completedFuture(null);

        final Supplier&lt;Pair&gt; supplier = () -&gt; {
            try {
                return queue.poll().get();
            } catch (Exception ex) {
                ex.printStackTrace();
                System.exit(1);
                return null;
            }
        };


        var nr = 0L;


        while (true) {
            final var start = nr;
            final var end = nr + segment;


            final var finalLast = last;

            var cf = CompletableFuture.completedFuture(supplier.get())
                    .thenApplyAsync(p -&gt; {
                        var arr = p.item1();
                        var bb = p.item2();
                        var pos = 0;
                        var digitsHelper = new byte[20];
                        digitsHelper[19] = newline;

                        for (long l = start; l &lt; end; l++) {
                            pos = fizzBuzz(l, arr, pos, digitsHelper, 18);
                        }
                        bb.clear();
                        bb.put(arr, 0, pos);
                        bb.flip();
                        return p;
                    })
                    .thenCombineAsync(finalLast, (p, v) -&gt; {
                        try {
                            channel.write(p.item2());
                        } catch (Exception ex) {
                            ex.printStackTrace();
                            System.exit(1);
                        }
                        return p;
                    });

            queue.add(cf);
            last = cf;

            nr = end;


        }

    }

}
</code></pre>
<p>Regular Java, no tricks on fizzbuzz, needs quite a bit of memory and benefits from multiple threads. On my M1 Pro w/ Java 17 I am at 4.3GiB/s (9 threads + 1 main). ByteBuffer writes max out the channel at ~ 5GiB/s piped via pv (without fizzbuzz).</p>
<pre class="lang-java prettyprint-override"><code>import java.io.FileDescriptor;
import java.io.FileOutputStream;
import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;
import java.util.LinkedList;
import java.util.Optional;
import java.util.Queue;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ForkJoinPool;
import java.util.function.Consumer;
import java.util.function.Supplier;
import java.util.stream.IntStream;

public class FizzBuzz {

    static final String NEWLINE = String.format(&quot;%n&quot;);

    static StringBuilder fizzBuzz(long src, StringBuilder destination) {
        if (src % 15 == 0) {
            destination.append(&quot;fizzbuzz&quot;);
        } else if (src % 5 == 0) {
            destination.append(&quot;fizz&quot;);
        } else if (src % 3 == 0) {
            destination.append(&quot;buzz&quot;);
        } else {
            destination.append(src);
        }
        return destination.append(NEWLINE);
    }

    record Pair&lt;T1, T2&gt;(T1 item1, T2 item2) {
    }

    public static void main(String[] argv) throws Exception {

        final var channel = new FileOutputStream(FileDescriptor.out).getChannel();

        final Consumer&lt;ByteBuffer&gt; writeToChannel = bb -&gt; {
            try {
                while (bb.hasRemaining()) {
                    channel.write(bb);
                }
            } catch (Exception ex) {
                ex.printStackTrace();
                System.exit(1);
            }
        };

        final Queue&lt;CompletableFuture&lt;Pair&lt;StringBuilder, ByteBuffer&gt;&gt;&gt; queue =
                new LinkedList&lt;&gt;
                        (IntStream.range(0, Optional.of(ForkJoinPool.getCommonPoolParallelism() - 1).filter(i -&gt; i &gt; 0).orElse(1))
                                .mapToObj(i -&gt;
                                        CompletableFuture.completedFuture(new Pair&lt;&gt;(new StringBuilder(20 * 1024 * 1024), ByteBuffer.allocateDirect(41 * 1024 * 1024)))).toList());

        CompletableFuture&lt;?&gt; last = CompletableFuture.completedFuture(null);

        final Supplier&lt;Pair&lt;StringBuilder, ByteBuffer&gt;&gt; supplier = () -&gt; {
            try {
                return queue.poll().get();
            } catch (Exception ex) {
                ex.printStackTrace();
                System.exit(1);
                return null;
            }
        };


        var nr = 0L;
        var segment = 1_000_000L;

        while (true) {
            final var start = nr;
            final var end = nr + segment;


            final var finalLast = last;

            var cf = CompletableFuture.completedFuture(supplier.get())
                    .thenApplyAsync(p -&gt; {
                        var sb = p.item1();
                        var bb = p.item2();
                        sb.delete(0, sb.length());
                        for (long l = start; l &lt; end; l++) {
                            fizzBuzz(l, sb);
                        }
                        bb.clear();
                        bb.put(sb.toString().getBytes(StandardCharsets.UTF_8));
                        return p;
                    })
                    .thenCombineAsync(finalLast, (p, v) -&gt; {
                        try {
                            channel.write(p.item2().flip());
                        } catch (Exception ex) {
                            ex.printStackTrace();
                            System.exit(1);
                        }
                        return p;
                    });

            queue.add(cf);
            last = cf;

            nr = end;


        }

    }

}
</code></pre>
</div>
<div id="pu12" class="pu"><h1>Node JS (v18.1.0)</h1>
<pre class="lang-js prettyprint-override"><code>let i = 1;
let str = '';

const resume = () =&gt; {
  while (true) {
    if (i % (2 &lt;&lt; 11) === 0) {
      const success = process.stdout.write(str);
      str = '';
      if (!success) {
        process.stdout.once('drain', resume);
        break;
      }
    }
    if (i % 3 === 0 &amp;&amp; i % 5 === 0) {
      str += 'FizzBuzz\n'
    } else if (i % 3 === 0) {
      str += 'Fizz\n'
    } else if (i % 5 === 0) {
      str += 'Buzz\n'
    } else {
      str += i + '\n';
    }
    i++;
  }
}

resume();
</code></pre>
<p>The command <code>node main.js | pv &gt; /dev/null</code> gave me about <code>150MiB/s</code> (for comparison the example shown in the OP ran at about <code>200 MiB/s</code> on my machine, an Intel i7-9700K)</p>
</div>
<div id="pu13" class="pu"><p>Here's my attempt with Node.js 18.4</p>
<h1>Initial solution</h1>
<pre class="lang-js prettyprint-override"><code>const MAX = Number.MAX_SAFE_INTEGER
const BUFFER_SIZE = 32 * 1024

function fizzbuzz() {
    let buffer = ''

    for (let i = 0; i &lt; MAX; i += 15) {
        buffer += `${i + 1}\n${i + 2}\nFizz\n${i + 4}\nBuzz\nFizz\n${i + 7}\n${i + 8}\nFizz\nBuzz\n${i + 11}\nFizz\n${i + 13}\n${i + 14}\nFizzBuzz\n`

        if (buffer.length &gt; BUFFER_SIZE) {
            process.stdout.write(buffer)
            buffer = ''
        }
    }
}

fizzbuzz()
</code></pre>
<p>This runs at ~110MB/s</p>
<p>Sadly this doesn't satisfy the requirement for large values as the largest safe int in JavaScript is <code>2^53-1</code>. It also quickly hits OOM errors because for whatever reason the garbage collector doesn't free up the temporary strings.</p>
<h1>Single threaded</h1>
<pre class="lang-js prettyprint-override"><code>const MAX = 0x7FFFFFFFFFFFFFFFn
const BUFFER_SIZE = 64 * 1024

const MAX_DECIMALS = 19 // 19 max bytes (decimal places) for 2^63-1
const BASE10 = [...Array(MAX_DECIMALS + 1).keys()].map((i) =&gt; 10n ** BigInt(i))

const FIZZ_BUZZ_PER_CYCLE = (15 / 3) + (15 / 5)
const INT_PER_CYCLE = 15 - FIZZ_BUZZ_PER_CYCLE
const BYTES_PER_CYCLE = (FIZZ_BUZZ_PER_CYCLE * 4) + (INT_PER_CYCLE * MAX_DECIMALS) // 4 bytes for 'fizz' and 'buzz'', 
const CYCLES = Math.floor(BUFFER_SIZE / BYTES_PER_CYCLE)

function fizzbuzz() {
    const buffer = Buffer.alloc(BYTES_PER_CYCLE * CYCLES)
    let offset = 0

    const writeFizz = () =&gt; {
        buffer.writeUInt32BE(0x46697a7a, offset)
        offset += 4
        buffer.writeUint8(0x0a, offset)
        offset += 1
    }

    const writeBuzz = () =&gt; {
        buffer.writeUInt32BE(0x42757a7a, offset)
        offset += 4
        buffer.writeUint8(0x0a, offset)
        offset += 1
    }

    const writeFizzBuzz = () =&gt; {
        buffer.writeUInt32BE(0x46697a7a, offset)
        offset += 4
        buffer.writeUInt32BE(0x42757a7a, offset)
        offset += 4
        buffer.writeUint8(0x0a, offset)
        offset += 1
    }

    // Works between 1 to 2^63-1
    const writeBigInt = (n) =&gt; {
        let hasLeading = false

        for (let exp = MAX_DECIMALS; exp &gt;= 0; exp--) {
            const divisor = BASE10[exp]

            if (n &gt;= divisor) {
                const digit = n / divisor
                n = n % divisor

                buffer.writeUint8(0x30 + Number(digit), offset)
                offset += 1
                hasLeading = true
            } else if (hasLeading) {
                buffer.writeUint8(0x30, offset)
                offset += 1
            }
        }

        buffer.writeUint8(0x0a, offset)
        offset += 1
    }

    const printAndResetBuffer = () =&gt; {
        process.stdout.write(buffer.subarray(0, offset), 'ascii')
        offset = 0
    }

    for (let i = 0n, cycles = 0; i &lt; MAX; i += 15n, cycles += 1) {
        writeBigInt(i + 1n)
        writeBigInt(i + 2n)
        writeFizz()
        writeBigInt(i + 4n)
        writeBuzz()
        writeFizz()
        writeBigInt(i + 7n)
        writeBigInt(i + 8n)
        writeFizz()
        writeBuzz()
        writeBigInt(i + 11n)
        writeFizz()
        writeBigInt(i + 13n)
        writeBigInt(i + 14n)
        writeFizzBuzz()

        if (cycles &gt;= CYCLES) {
            printAndResetBuffer()
            cycles = 0
        }
    }

    printAndResetBuffer()
}

fizzbuzz()
</code></pre>
<p>This runs at an astonishing ~8MB/s. Replacing all the <code>BigInt</code>s with native numbers runs at ~50MB/s.</p>
<p>I can't believe this was the fastest solution that I can come up with that doesn't eventually hit OOM errors.</p>
<h1>Worker threads</h1>
<pre class="lang-js prettyprint-override"><code>const { Worker, isMainThread, parentPort, workerData } = require('worker_threads')

const MAX = 0x7FFFFFFFFFFFFFFFn
const BUFFER_SIZE = 64 * 1024

const MAX_DECIMALS = 19 // 19 max bytes (decimal places) for 2^63-1
const BASE10 = [...Array(MAX_DECIMALS + 1).keys()].map((i) =&gt; 10n ** BigInt(i))

const FIZZ_BUZZ_PER_CYCLE = (15 / 3) + (15 / 5)
const INT_PER_CYCLE = 15 - FIZZ_BUZZ_PER_CYCLE
const BYTES_PER_CYCLE = (FIZZ_BUZZ_PER_CYCLE * 4) + (INT_PER_CYCLE * MAX_DECIMALS) // 4 bytes for 'fizz' and 'buzz'',
const CYCLES = Math.floor(BUFFER_SIZE / BYTES_PER_CYCLE)
const INTS_PER_CYCLE = BigInt(CYCLES) * 15n

const THREADS = 12

async function fizzbuzz() {
    if (isMainThread) {
        const sharedStrBuffer = new SharedArrayBuffer(THREADS * BUFFER_SIZE)
        const sharedCanConsumeBuffer = new SharedArrayBuffer(THREADS * Int32Array.BYTES_PER_ELEMENT)
        const sharedCanProduceBuffer = new SharedArrayBuffer(THREADS * Int32Array.BYTES_PER_ELEMENT)

        const strBuffer = new Uint8Array(sharedStrBuffer)
        const canConsume = new Int32Array(sharedCanConsumeBuffer) // when non-zero, it stores the position of the last character
        const canProduce = new Int32Array(sharedCanProduceBuffer) // when non-zero, worker thread can work

        const workers = []
        for (let threadId = 0; threadId &lt; THREADS; threadId++) {
            canConsume[threadId] = 0
            canProduce[threadId] = 1

            const worker = new Worker(__filename, {
                workerData: {
                    threadId,
                    sharedStrBuffer,
                    sharedCanConsumeBuffer,
                    sharedCanProduceBuffer,
                }
            })

            workers.push(worker)
        }

        const step = INTS_PER_CYCLE * BigInt(THREADS)
        for (let i = 0n; i &lt; MAX; i += step) {
            for (let threadId = 0; threadId &lt; THREADS; threadId++) {
                Atomics.wait(canConsume, threadId, 0)

                const offsetStart = threadId * BUFFER_SIZE
                const offsetEnd = Atomics.load(canConsume, threadId)
                process.stdout.write(strBuffer.subarray(offsetStart, offsetEnd), 'ascii')

                Atomics.store(canProduce, threadId, 1)
                Atomics.notify(canProduce, threadId)
            }
        }
    } else {
        const { threadId } = workerData

        const strBuffer = new Uint8Array(workerData.sharedStrBuffer)
        const canConsume = new Int32Array(workerData.sharedCanConsumeBuffer)
        const canProduce = new Int32Array(workerData.sharedCanProduceBuffer)

        const initOffset = threadId * BUFFER_SIZE
        let offset = initOffset

        const writeFizz = () =&gt; {
            strBuffer[offset + 0] = 0x46
            strBuffer[offset + 1] = 0x69
            strBuffer[offset + 2] = 0x7a
            strBuffer[offset + 3] = 0x7a

            strBuffer[offset + 4] = 0x0a
            offset += 5
        }

        const writeBuzz = () =&gt; {
            strBuffer[offset + 0] = 0x42
            strBuffer[offset + 1] = 0x75
            strBuffer[offset + 2] = 0x7a
            strBuffer[offset + 3] = 0x7a

            strBuffer[offset + 4] = 0x0a
            offset += 5
        }

        const writeFizzBuzz = () =&gt; {
            strBuffer[offset + 0] = 0x46
            strBuffer[offset + 1] = 0x69
            strBuffer[offset + 2] = 0x7a
            strBuffer[offset + 3] = 0x7a

            strBuffer[offset + 4] = 0x42
            strBuffer[offset + 5] = 0x75
            strBuffer[offset + 6] = 0x7a
            strBuffer[offset + 7] = 0x7a

            strBuffer[offset + 8] = 0x0a
            offset += 9
        }

        // Works between 1 to 2^63-1
        const writeBigInt = (n) =&gt; {
            let hasLeading = false

            for (let exp = MAX_DECIMALS; exp &gt;= 0; exp--) {
                const divisor = BASE10[exp]

                if (n &gt;= divisor) {
                    const digit = n / divisor
                    n = n % divisor

                    strBuffer[offset] = 0x30 + Number(digit)
                    offset += 1
                    hasLeading = true
                } else if (hasLeading) {
                    strBuffer[offset] = 0x30
                    offset += 1
                }
            }

            strBuffer[offset] = 0x0a
            offset += 1
        }

        const intsPerGlobalCycle = INTS_PER_CYCLE * BigInt(THREADS)
        const totalCycles = (MAX / intsPerGlobalCycle) + 1n

        for (let c = 0n; c &lt; totalCycles; c++) {
            Atomics.wait(canProduce, threadId, 0)
    
            const startInt = (c * intsPerGlobalCycle) + (BigInt(threadId) * INTS_PER_CYCLE)
            const endInt = (startInt + INTS_PER_CYCLE &gt; MAX)
                ? MAX
                : startInt + INTS_PER_CYCLE

            for (let i = startInt; i &lt; endInt; i += 15n) {
                writeBigInt(i + 1n)
                writeBigInt(i + 2n)
                writeFizz()
                writeBigInt(i + 4n)
                writeBuzz()
                writeFizz()
                writeBigInt(i + 7n)
                writeBigInt(i + 8n)
                writeFizz()
                writeBuzz()
                writeBigInt(i + 11n)
                writeFizz()
                writeBigInt(i + 13n)
                writeBigInt(i + 14n)
                writeFizzBuzz()
            }

            Atomics.store(canConsume, threadId, offset)
            Atomics.notify(canConsume, threadId)
            offset = initOffset

            Atomics.store(canProduce, threadId, 0)
        }
    }
}

fizzbuzz()
</code></pre>
<p>After running a profiler on my single threaded solution, the biggest slowdown was these 2 lines:</p>
<pre><code>const digit = n / divisor
n = n % divisor
</code></pre>
<p>Which makes sense considering that it's division operation on <code>BigInt</code>. I've also thought of using WebAssembly or some C module to access native 64-bit ints but I think that defeats the purpose of this exercise as I want to use pure JavaScript.</p>
<p>Pushing this computation onto worker threads allowed this solution to run at ~380 MB/s with 12 threads.</p>
<p><strong>Side note:</strong> For some reason, my <code>pv</code> command freezes when testing:</p>
<pre class="lang-sh prettyprint-override"><code>node worker-threads.js | pv &gt; /dev/null
93.7KiB 0:00:10 [0.00 B/s]
</code></pre>
<p>Instead I piped the output to a temp file <code>timeout 30 node worker-threads.js &gt; tmp.txt</code> and then just manually calculated <code>speed = tmp.txt size / 30s</code>. Maybe someone can offer some insight why this is happening for me.</p>
</div>
<div id="pu14" class="pu"><h1>Go</h1>
<p>Compile and run with <code>go run main.go</code></p>
<p>Some notes:</p>
<ul>
<li>Creates output in 15-line templates where possible.</li>
<li>Divides work into sections of lines with same base10 integer width, so locations of integers in output buffer can easily be precomputed.</li>
<li>Processes work in large chunks of multiple templates, computed in parallel with goroutines and channels.</li>
<li>Uses modified versions of standard library itoa for int-&gt;string conversion to avoid memory allocation.</li>
<li>Caches small (&lt;10000) integer string representations and reuses them where possible.</li>
</ul>
<p>4.3 GiB/s running this on my desktop</p>
<pre class="lang-go prettyprint-override"><code>package main

import (
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;os&quot;
    &quot;runtime&quot;
)

const limit = 1 &lt;&lt; 61

func main() {
    initItoaCache()
    parallelFizzBuzz(1, limit)
}

const cacheSize = 10000

var logCacheSize = log10(cacheSize)
var itoaCache = make([]string, cacheSize)

func initItoaCache() {
    // precompute string representations
    fmtString := fmt.Sprintf(&quot;%%0%dd&quot;, logCacheSize)
    for j := 0; j &lt; cacheSize; j++ {
        itoaCache[j] = fmt.Sprintf(fmtString, j)
    }
}

func parallelFizzBuzz(from, to int) {

    for _, wr := range getWidthRanges(from, to) {
        // range which can be filled with templates
        templatesStart := min(wr.to, ceilDiv(wr.from, templateLines)*templateLines)
        templatesEnd := templatesStart + floorDiv(wr.to-templatesStart+1, templateLines)*templateLines

        // handle values before first template
        for i := wr.from; i &lt;= templatesStart; i++ {
            os.Stdout.WriteString(fizzBuzzLine(i))
        }

        // write large chunks in parallel
        const templatesPerJob = 250
        template, placeholderIdxs := fixedWidthTemplate(wr.width)
        nWorkers := runtime.NumCPU()
        chunkSize := nWorkers * templateLines * templatesPerJob

        chunksStart := templatesStart
        chunksEnd := chunksStart + floorDiv(templatesEnd-templatesStart+1, chunkSize)*chunkSize

        if chunksEnd &gt; templatesStart {
            writeParallel(os.Stdout, chunksStart+1, chunksEnd, nWorkers, templatesPerJob, template, wr.width, placeholderIdxs)
        }

        // handle values after last chunk
        for i := chunksEnd + 1; i &lt;= wr.to; i++ {
            os.Stdout.WriteString(fizzBuzzLine(i))
        }
    }
}

type widthRange struct{ from, to, width int }

// getWidthRanges splits integer range [from,to] into disjoint ranges grouped by base10 representation length
func getWidthRanges(from, to int) []widthRange {
    ranges := []widthRange{}

    fromWidth := log10(from + 1)
    toWidth := log10(to + 1)

    for fromWidth &lt; toWidth {
        toVal := pow(10, fromWidth) - 1
        ranges = append(ranges, widthRange{from, toVal, fromWidth})
        from = toVal + 1
        fromWidth += 1
    }

    ranges = append(ranges, widthRange{from, to, fromWidth})
    return ranges
}

// fizzBuzzLine is used to form lines outside of &quot;chunkable&quot; regions
func fizzBuzzLine(i int) string {
    if (i%3 == 0) &amp;&amp; (i%5 == 0) {
        return &quot;FizzBuzz\n&quot;
    } else if i%3 == 0 {
        return &quot;Fizz\n&quot;
    } else if i%5 == 0 {
        return &quot;Buzz\n&quot;
    } else {
        return fastItoa(uint64(i)) + &quot;\n&quot;
    }
}

const templateLines = 15

func fixedWidthTemplate(valueWidth int) ([]byte, []int) {
    template := make([]byte, 0, 15+valueWidth*8+4*8)
    formatString := fmt.Sprintf(&quot;%%0%dd\n&quot;, valueWidth)
    placeholder := []byte(fmt.Sprintf(formatString, 0))
    placeholderIdxs := make([]int, 0, 8)
    fizzBytes := []byte(&quot;Fizz\n&quot;)
    buzzBytes := []byte(&quot;Buzz\n&quot;)
    fizzBuzzBytes := []byte(&quot;FizzBuzz\n&quot;)

    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    template = append(template, fizzBytes...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    template = append(template, buzzBytes...)
    template = append(template, fizzBytes...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    template = append(template, fizzBytes...)
    template = append(template, buzzBytes...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    template = append(template, fizzBytes...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    placeholderIdxs = append(placeholderIdxs, len(template))
    template = append(template, placeholder...)
    template = append(template, fizzBuzzBytes...)
    return template, placeholderIdxs
}

func writeParallel(f io.Writer, firstLine, lastLine, nWorkers, templatesPerJob int, template []byte, width int, placeholderIdxs []int) {

    totalLines := lastLine - firstLine + 1
    workerLines := templateLines * templatesPerJob
    linesPerRound := nWorkers * workerLines
    if totalLines%linesPerRound != 0 {
        panic(&quot;uneven work allocation&quot;)
    }

    jobChannels := make([]chan int, nWorkers)
    resultChannels := make([]chan []byte, nWorkers)
    totalJobs := ceilDiv(totalLines, workerLines)
    jobsPerWorker := ceilDiv(totalLines, workerLines*nWorkers)

    for i := 0; i &lt; nWorkers; i++ {
        jobChannels[i] = make(chan int, jobsPerWorker*2)
        resultChannels[i] = make(chan []byte, 1)
        go worker(jobChannels[i], resultChannels[i], templatesPerJob, template, width, placeholderIdxs)
    }

    // deal out jobs to workers
    for job := 0; job &lt; totalJobs; job++ {
        jobLine := firstLine + job*workerLines
        jobChannels[job%nWorkers] &lt;- jobLine
    }

    // read buffers from workers
    for job := 0; job &lt; totalJobs; job++ {
        f.Write(&lt;-resultChannels[job%nWorkers])
    }
}

func worker(in &lt;-chan int, out chan&lt;- []byte, templatesPerJob int, template []byte, width int, idxs []int) {
    buffer := make([]byte, len(template)*templatesPerJob)
    buffer2 := make([]byte, len(template)*templatesPerJob)
    buffer3 := make([]byte, len(template)*templatesPerJob)

    for i := 0; i &lt; templatesPerJob; i++ {
        copy(buffer[len(template)*i:], template)
    }
    copy(buffer2, buffer)
    copy(buffer3, buffer)

    for jobLine := range in {

        nextFlush := (jobLine / cacheSize) * cacheSize
        repeat := false // need to fill twice for a clean template for cached ints

        for i := 0; i &lt; templatesPerJob; i++ {
            off := i * len(template)
            if i*templateLines+jobLine+13 &gt; nextFlush || repeat {
                bufFastItoa(buffer, off+idxs[0]+width, uint64(i*templateLines+jobLine))
                bufFastItoa(buffer, off+idxs[1]+width, uint64(i*templateLines+jobLine+1))
                bufFastItoa(buffer, off+idxs[2]+width, uint64(i*templateLines+jobLine+3))
                bufFastItoa(buffer, off+idxs[3]+width, uint64(i*templateLines+jobLine+6))
                bufFastItoa(buffer, off+idxs[4]+width, uint64(i*templateLines+jobLine+7))
                bufFastItoa(buffer, off+idxs[5]+width, uint64(i*templateLines+jobLine+10))
                bufFastItoa(buffer, off+idxs[6]+width, uint64(i*templateLines+jobLine+12))
                bufFastItoa(buffer, off+idxs[7]+width, uint64(i*templateLines+jobLine+13))
                repeat = !repeat
                if repeat {
                    nextFlush += cacheSize
                }
            } else {
                copy(buffer[off:], buffer[off-len(template):off])
                copy(buffer[off+idxs[0]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine)%cacheSize])
                copy(buffer[off+idxs[1]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+1)%cacheSize])
                copy(buffer[off+idxs[2]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+3)%cacheSize])
                copy(buffer[off+idxs[3]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+6)%cacheSize])
                copy(buffer[off+idxs[4]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+7)%cacheSize])
                copy(buffer[off+idxs[5]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+10)%cacheSize])
                copy(buffer[off+idxs[6]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+12)%cacheSize])
                copy(buffer[off+idxs[7]+width-logCacheSize:], itoaCache[(i*templateLines+jobLine+13)%cacheSize])
            }
        }

        out &lt;- buffer
        buffer, buffer2, buffer3 = buffer2, buffer3, buffer
    }

    close(out)
}

//
// Helpers
//

func max(a, b int) int {
    if a &lt; b {
        return b
    }
    return a
}

func min(a, b int) int {
    if a &lt; b {
        return a
    }
    return b
}

func ceilDiv(val, divisor int) int {
    return (val + divisor - 1) / divisor
}

func floorDiv(val, divisor int) int {
    return val / divisor
}

// pow returns n^k
func pow(n, k int) int {
    if k == 0 {
        return 1
    } else if k == 1 {
        return n
    } else {
        return pow(n, k/2) * pow(n, k-k/2)
    }
}

// log10 returns base 10 logarithm for positive n
func log10(n int) int {
    if n &lt;= 0 {
        panic(&quot;bad input&quot;)
    }
    i := 0
    c := 1
    for c &lt; n {
        c *= 10
        i++
    }
    return i
}

const smallsString = &quot;00010203040506070809&quot; +
    &quot;10111213141516171819&quot; +
    &quot;20212223242526272829&quot; +
    &quot;30313233343536373839&quot; +
    &quot;40414243444546474849&quot; +
    &quot;50515253545556575859&quot; +
    &quot;60616263646566676869&quot; +
    &quot;70717273747576777879&quot; +
    &quot;80818283848586878889&quot; +
    &quot;90919293949596979899&quot;

// bufFastItoa writes base10 string representation of a positive integer to index i in buffer
// adapted from Go source strconv/itoa.go
func bufFastItoa(buf []byte, i int, u uint64) {

    for u &gt;= 100 {
        is := u % 100 * 2
        u /= 100
        i -= 2
        buf[i+1] = smallsString[is+1]
        buf[i+0] = smallsString[is+0]
    }

    // u &lt; 100
    is := u * 2
    i--
    buf[i] = smallsString[is+1]
    if u &gt;= 10 {
        i--
        buf[i] = smallsString[is]
    }
}

// fastItoa returns base10 string representation of a positive integer
// adapted from Go source strconv/itoa.go
func fastItoa(u uint64) string {

    var dst [20]byte
    i := len(dst)

    for u &gt;= 100 {
        is := u % 100 * 2
        u /= 100
        i -= 2
        dst[i+1] = smallsString[is+1]
        dst[i+0] = smallsString[is+0]
    }

    // u &lt; 100
    is := u * 2
    i--
    dst[i] = smallsString[is+1]
    if u &gt;= 10 {
        i--
        dst[i] = smallsString[is]
    }

    return string(dst[i:])
}
</code></pre>
</div>
<div id="pu15" class="pu"><p>I'm surprised there is no <strong>JavaScript</strong> answer here.<br />
But when I try to write a solution, I think I understand why.<br />
JavaScript's score are pretty bad, and the very uncertainty.<br />
But anyway, I want to release my solution first.</p>
<p>It's <code>AMD Ryzen 5 3400G (2.6GHz)</code> using <code>Node v16.13.1</code> on <code>Ubuntu 18.04.5, Linux 5.6.19</code>.</p>
<p><code>main.js</code></p>
<pre class="lang-js prettyprint-override"><code>let buffer = &quot;&quot;;

for (i = 0; i &lt; 1e7; i += 15) {
    buffer += `${i+1}\n${i+2}\nfizz\n${i+4}\nbuzz\nfizz\n${i+7}\n${i+8}\nfizz\nbuzz\n${i+11}\nfizz\n${i+13}\n${i+14}\nfizzbuzz\n`;

    if(buffer.length &gt; 40000) {
        process.stdout.write(buffer);
        buffer = &quot;&quot;;
    }
}

process.stdout.write(buffer);
</code></pre>
<p>Because of the high uncertainty, I will test 10 times in a row.</p>
<p><code>run.sh</code></p>
<pre class="lang-bash prettyprint-override"><code>#!/bin/bash

for ((i=1; i&lt;=10; i++)); do
    node main.js | pv -ab &gt; /dev/null
done
</code></pre>
<p>And the result is:</p>
<pre><code>64.9MiB [47.8MiB/s]
64.9MiB [ 150MiB/s]
64.9MiB [ 150MiB/s]
64.9MiB [ 149MiB/s]
64.9MiB [ 151MiB/s]
64.9MiB [ 149MiB/s]
64.9MiB [ 150MiB/s]
64.9MiB [ 153MiB/s]
64.9MiB [78.8MiB/s]
64.9MiB [ 149MiB/s]
</code></pre>
</div>
<div id="pu16" class="pu"><p><strong>PHP (simple)</strong></p>
<pre><code>&lt;?php

ob_start(null, 32000);

for ($i = 0; $i &lt; PHP_INT_MAX; $i++) {
        $out = $i;
        if ($i % 3 === 0) $out = 'fizz';
        if ($i % 5 === 0) {
                $out = 'buzz';
                if ($i % 3 === 0) $out = 'fizzbuzz';
        }
        echo &quot;$out\n&quot;;
}
</code></pre>
<p><strong>PHP (optimized)</strong></p>
<pre><code>&lt;?php

ob_start(null, 32000);

$a = [0, 1, 'fizz', 3, 'buzz', 'fizz',
      6, 7, 'fizz', 'buzz', 10, 'fizz',
      12, 13, 'fizzbuzz', ''];

for ($i = 1; $i &lt; PHP_INT_MAX-15; $i+=15) {
    $a[0] = $i;
    $a[1] = $i+1;
    $a[3] = $i+3;
    $a[6] = $i+6;
    $a[7] = $i+7;
    $a[10] = $i+10;
    $a[12] = $i+12;
    $a[13] = $i+13;
    echo join(&quot;\n&quot;, $a);
}
</code></pre>
<p><strong>PHP (multithreaded)</strong></p>
<pre><code>&lt;?php

$nWorkers = preg_match_all('/^processor\s/m', file_get_contents('/proc/cpuinfo'), $discard);
$iterationsPerFlush = 20000;
define('CHILD_TOKEN_KEY', 0);

//1 byte SHM segment holding the worker ID whose turn it is to write 
//initialise to child 0.
$shm = shm_attach(1);
shm_put_var($shm, CHILD_TOKEN_KEY, 0);

//Semaphore to protect access to the SHM var
$key = ftok(__FILE__, 1);
$sem = sem_get($key);
$childPids = [];
pcntl_sigprocmask(SIG_BLOCK, [SIGTERM, SIGINT, SIGCHLD]);

for ($i=0; $i&lt;$nWorkers; $i++){
        if (!$pid = pcntl_fork()){
                doWork($sem, $shm, $i, $nWorkers, $iterationsPerFlush);
                exit;
        }else{
                $childPids[] = $pid;
        }
}

//If we get killed or one of our children does, clean everything up
pcntl_sigwaitinfo([SIGTERM, SIGINT, SIGCHLD], $info);
foreach ($childPids as $pid){
        posix_kill($pid, SIGKILL);
}
sem_remove($sem);
shm_remove($shm);

function doWork($sem, $shm, $childId, $nWorkers, $iterationsPerFlush){
        $nextChildId = ($childId + 1) % $nWorkers;
        $increment = ($nWorkers - 1) * $iterationsPerFlush * 15;
        $startOffset = $childId * $iterationsPerFlush * 15;

        $a = [-14 + $startOffset, -13 + $startOffset, &quot;fizz&quot;, -11 + $startOffset, &quot;buzz\nfizz&quot;,
                -8 + $startOffset, -7 + $startOffset, &quot;fizz\nbuzz&quot;, -4 + $startOffset, &quot;fizz&quot;,
                -2 + $startOffset, -1 + $startOffset, &quot;fizzbuzz\n&quot;];

        ob_start();

        while (true){
                for ($i = 0; $i &lt; $iterationsPerFlush; $i++){
                        $a[0] += 15; 
                        $a[1] += 15; 
                        $a[3] += 15; 
                        $a[5] += 15; 
                        $a[6] += 15; 
                        $a[8] += 15; 
                        $a[10] += 15; 
                        $a[11] += 15; 
                        echo join(&quot;\n&quot;, $a);
                }

                //Acquire the semaphore and check if it's our turn to flush.  If not, repeat.
                while (true){
                        sem_acquire($sem);
                        if (shm_get_var($shm, CHILD_TOKEN_KEY) === $childId){
                                break;
                        }
                        sem_release($sem);
                }

                ob_flush();

                //Pass the token on to the next child and release the semaphore
                shm_put_var($shm, CHILD_TOKEN_KEY, $nextChildId);
                sem_release($sem);

                //Skip over the numbers the other workers already handled
                $a[0] += $increment; 
                $a[1] += $increment; 
                $a[3] += $increment; 
                $a[5] += $increment; 
                $a[6] += $increment; 
                $a[8] += $increment;
                $a[10] += $increment; 
                $a[11] += $increment; 
        }
}
</code></pre>
<p>The multithreaded version is the result of this thread on Reddit:</p>
<p><a href="https://old.reddit.com/r/PHP/comments/v94ly2/php_fizzbuzz/" rel="nofollow noreferrer">https://old.reddit.com/r/PHP/comments/v94ly2/php_fizzbuzz/</a></p>
<p>It was mostly done by therealgaxbo.</p>
</div>
<div id="pu17" class="pu"><p>Can you check my version in rust ? On my laptop it seems faster than @aiden version</p>
<pre class="lang-rust prettyprint-override"><code>use nix::unistd::write;
use std::time::{Duration, Instant};

use libc::exit;
use itoap;

#[inline(always)]
fn u64_to_bytes(n: u64, v: &amp;mut Vec&lt;u8&gt;) {
    itoap::write_to_vec(v, n);
    v.push(0x0a);
}

fn main() {
    let mut i: u64 = 0;

    let Fizz = &quot;Fizz\n&quot;.as_bytes();
    let Buzz = &quot;Buzz\n&quot;.as_bytes();
    let FizzBuzz = &quot;FizzBuzz\n&quot;.as_bytes();

    let mut buffering: Vec&lt;u8&gt; = Vec::with_capacity(1024*1024*2);
    loop {
        for _ in 0..512 {
            i += 1;
            u64_to_bytes(i, &amp;mut buffering);
        
            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            buffering.extend_from_slice(&amp;Fizz);

            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            buffering.extend_from_slice(&amp;Buzz);

            i += 1;
            buffering.extend_from_slice(&amp;Fizz);

            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            buffering.extend_from_slice(&amp;Fizz);

            i += 1;
            buffering.extend_from_slice(&amp;Buzz);

            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            buffering.extend_from_slice(&amp;Fizz);

            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            u64_to_bytes(i, &amp;mut buffering);

            i += 1;
            buffering.extend_from_slice(&amp;FizzBuzz);            
        }
        write(1, buffering.as_slice());
        buffering.clear();
    }
}
</code></pre>
<pre><code>[package]
name = &quot;fizzbuzz&quot;
version = &quot;0.1.0&quot;
edition = &quot;2021&quot;

[dependencies]
nix = &quot;0.24.1&quot;
libc = &quot;*&quot;
itoap = &quot;*&quot;
</code></pre>
</div>
<div id="pu18" class="pu"><h3>Update</h3>
<p>A minor change to remove a branch, and some code cleanup, <s>about 10% speedup on my machine</s>.</p>
<p>Because the SysV calling convention sets all <code>xmm</code> registers as clobbers across function calls, and this includes a call to the <code>vmsplice</code> wrapper function, I had to make a manual <code>syscall</code> to <code>vmsplice</code> with inline assembly to tell the compiler that there are no <code>xmm</code> clobbers, so that the compiler can preload more values in <code>xmm</code> registers. This was the main source of speedup. Let me know if there's a better way.</p>
<p>The inline assembly part is now commented out because Omer (who opened the challenge) thinks inline assembly makes the code no longer pure C. It's best for me to compete with C entries.</p>
<hr />
<p>This program will run faster than any other C or C++ entry, at least twice the speed. It is also noticeably faster than the last edit which was a bit buggy (blame <code>vmplice</code>). <code>gcc</code> as a compiler and SSE4.1 is a requirement.</p>
<p>There are two main optimizations that make this program run fast.</p>
<p>First, the digits are stored in a single XMM register with 128-bits, and since each character consumes 8-bits, one register can hold maximum 16 digits, which is more than enough. All operations to digits are done with one or several SIMD instructions, and the data always stays in a register before it gets copied to the buffer.</p>
<p>The <code>PSHUFB</code> instruction or <code>_mm_shuffle_epi8</code> is the main source of speedup. It does the otherwise complicated byte reversal and shifting all bytes to one direction, in a single instruction. Both happen in the <code>writeDigits</code> function.</p>
<p>Second is <code>vmsplice</code>. I do not like the person who wrote this Linux-specific system call and probably the same person who wrote the documentation very badly. All would've been simple if such poorly-documented and unpredictable syscall didn't exist at all. I was really forced to use it because the speedup it could provide was too big. If you ever consider using this syscall, the following notes may help.</p>
<ul>
<li>The safest and probably intended use of <code>vmplice</code> is the sequence of <code>mmap</code> -&gt; <code>vmplice</code> with <code>SPLICE_F_GIFT</code> -&gt; <code>munmap</code>. You can call <code>munmap</code> directly after <code>vmsplice</code> retruns. This works in a similar way to asynchronous IO, and is very efficient in that sense. However since you are <code>mmap</code>ing a new buffer every time, the buffer will unlikely be in cache.</li>
<li>If you overwrite the buffer after a call to <code>vmsplice</code>, things can get very unpredictable. Whether <code>SPLICE_F_GIFT</code> is set or not doesn't make a difference, and I'm not even sure whether that flag does a thing at all. That <code>vmsplice</code> has returned does not mean that the pipe has consumed all of the buffer. That's why I said it is similar to asynchronous IO. It is not documented at all when it is safe to overwrite the buffer after <code>vmsplice</code> has returned. All I can say is it is somehow predictable when,
<ol>
<li><code>vmsplice</code> is always called with the same buffer size.</li>
<li>The pipe size matches the buffer size.</li>
<li>The <em>same thread</em> writes to the buffer and calls <code>vmsplice</code>.</li>
<li>The buffer is not overwritten <em>too fast</em>... and I don't know how much is <em>too fast</em>, but for example if you overwrite the buffer right after <code>vmsplice</code> returns, things get unpredictable.</li>
</ol>
</li>
</ul>
<p>Compile the program with <code>gcc -s -O3 -msse4.1 -fwhole-program</code>.</p>
<pre><code>#define _GNU_SOURCE
#include &lt;stdlib.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdalign.h&gt;
#include &lt;string.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;smmintrin.h&gt;

static const __m128i shiftMask[] = {
  {0x0706050403020100, 0x0f0e0d0c0b0a0908},
  {0x0807060504030201, 0xff0f0e0d0c0b0a09},
  {0x0908070605040302, 0xffff0f0e0d0c0b0a},
  {0x0a09080706050403, 0xffffff0f0e0d0c0b},
  {0x0b0a090807060504, 0xffffffff0f0e0d0c},
  {0x0c0b0a0908070605, 0xffffffffff0f0e0d},
  {0x0d0c0b0a09080706, 0xffffffffffff0f0e},
  {0x0e0d0c0b0a090807, 0xffffffffffffff0f},
  {0x0f0e0d0c0b0a0908, 0xffffffffffffffff},
  {0xff0f0e0d0c0b0a09, 0xffffffffffffffff},
  {0xffff0f0e0d0c0b0a, 0xffffffffffffffff},
  {0xffffff0f0e0d0c0b, 0xffffffffffffffff},
  {0xffffffff0f0e0d0c, 0xffffffffffffffff},
  {0xffffffffff0f0e0d, 0xffffffffffffffff},
  {0xffffffffffff0f0e, 0xffffffffffffffff},
  {0xffffffffffffff0f, 0xffffffffffffffff}
};

static __m128i inc(__m128i d) {
  return _mm_sub_epi64(d, _mm_set_epi64x(0, -1));
}

static __m128i carry(__m128i d) {
  d = _mm_sub_epi64(d,
    _mm_bslli_si128(_mm_cmpeq_epi64(d, _mm_setzero_si128()), 8));
  return _mm_or_si128(d,
    _mm_and_si128(_mm_cmpeq_epi8(d, _mm_setzero_si128()), _mm_set1_epi8(0xf6)));
}

static int writeDigits(char *b, __m128i d, int i) {
  _mm_storeu_si128((__m128i *)b,
    _mm_shuffle_epi8(
      _mm_shuffle_epi8(_mm_sub_epi64(d, _mm_set1_epi8(0xc6)),
        _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)),
      shiftMask[i]));
  b[16 - i] = '\n';
  return 17 - i;
}

static int writeFizz(void *b) {
  memcpy(b, &amp;(int64_t){0x0a7a7a6946}, 8);
  return 5;
}

static int writeFizzBuzz(void *b) {
  memcpy(b, &amp;(int64_t){0x7a7a75427a7a6946}, 8);
  ((char *)b)[8] = '\n';
  return 9;
}

static int writeFizzAndBuzz(void *b) {
  memcpy(b, &amp;(int64_t){0x7a75420a7a7a6946}, 8);
  memcpy(b + 8, &amp;(int16_t){0x0a7a}, 2);
  return 10;
}

static int writeBuzzAndFizz(void *b) {
  memcpy(b, &amp;(int64_t){0x7a69460a7a7a7542}, 8);
  memcpy(b + 8, &amp;(int16_t){0x0a7a}, 2);
  return 10;
}

static void memcpy_simple(void *d, void *s, int n) {
  int i = 0;
  do {
    _mm_store_si128((void *)((char *)d + i),
      _mm_load_si128((void *)((char *)s + i)));
  } while ((i += 16) &lt; n);
}

#define ALIGN 0x1000
#define SIZE (ALIGN &lt;&lt; 8)
#define I d = inc(d)
#define IC d = carry(inc(d))
#define D I; p += writeDigits(p, d, i)
#define F I; p += writeFizz(p)
#define FB I; p += writeFizzBuzz(p)
#define FNB I; I; p += writeFizzAndBuzz(p)
#define BNF I; I; p += writeBuzzAndFizz(p)

int main() {
  if (fcntl(1, F_SETPIPE_SZ, SIZE) != SIZE) {
    abort();
  }
  alignas(ALIGN) char b[2][SIZE + ALIGN];
  int f = 0;
  char *p = b[f];
  __m128i d = _mm_set1_epi8(0xf6);
  int i = 15;
  for (int64_t j = 10, k = 10;; j += 30) {
    D; D; F; D; BNF; D; D; I; IC; p += writeFizzAndBuzz(p);
    if (j == k) {
      k *= 10;
      --i;
    }
    D; F; D; D; FB; D; D; F; D; IC; p += writeBuzzAndFizz(p);
    I; D; D; FNB; D; F; D; D; IC; p += writeFizzBuzz(p);
    int n = p - b[f] - SIZE;
    if (n &gt;= 0) {
      struct iovec v = {b[f], SIZE};
      do {
        /*register long rax __asm__ (&quot;rax&quot;) = 278;
        register long rdi __asm__ (&quot;rdi&quot;) = 1;
        register long rsi __asm__ (&quot;rsi&quot;) = (long)&amp;v;
        register long rdx __asm__ (&quot;rdx&quot;) = 1;
        register long r10 __asm__ (&quot;r10&quot;) = 0;
        __asm__ (&quot;syscall&quot; : &quot;+r&quot;(rax) : &quot;r&quot;(rdi), &quot;r&quot;(rsi), &quot;r&quot;(rdx), &quot;r&quot;(r10)
        : &quot;rcx&quot;, &quot;r11&quot;);*/
        long rax = vmsplice(1, &amp;v, 1, 0);
        if (rax &lt; 0) {
          abort();
        }
        v.iov_base = (char *)v.iov_base + rax;
        v.iov_len -= rax;
      } while (v.iov_len);
      f = !f;
      memcpy_simple(b[f], b[!f] + SIZE, n);
      p = b[f] + n;
    }
  }
  return 0;
}
</code></pre>
</div>
<div id="pu19" class="pu"><p>Did answer with Go, got my Dell 5560 2.35G but please test with your system. 12 threads(routines in go terms) was best with this 8 core 2 threads per core cpu but please test other numbers too as it changes which is best. Thanks for interesting challenge!</p>
<pre><code>package main

import (
    &quot;os&quot;
    &quot;strconv&quot;
    &quot;sync&quot;
    &quot;unsafe&quot;
)

const buffSize = 200000000
const innerloop = 25000

const routines = 12

func main() {
    eightZeroLock := &amp;sync.Mutex{}
    startLock := eightZeroLock
    endLock := &amp;sync.Mutex{}
    endLock.Lock()
    for i := 0; i &lt; routines-1; i++ {
        go routine(i, startLock, endLock)
        startLock = endLock
        endLock = &amp;sync.Mutex{}
        endLock.Lock()
    }
    go routine(routines-1, startLock, eightZeroLock)
    wg := sync.WaitGroup{}
    wg.Add(1)
    wg.Wait()
}

func routine(num int, start, end *sync.Mutex) {
    counter := num * 15 * innerloop

    var sb Builder
    sb.Grow(buffSize)
    for {

        for i := 0; i &lt; innerloop; i++ {
            sb.WriteString(strconv.Itoa(counter + 1))
            sb.WriteString(&quot;\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 2))
            sb.WriteString(&quot;\nFizz\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 4))
            sb.WriteString(&quot;\nBuzz\nFizz\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 7))
            sb.WriteString(&quot;\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 8))
            sb.WriteString(&quot;\nFizz\nBuzz\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 11))
            sb.WriteString(&quot;\nFizz\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 13))
            sb.WriteString(&quot;\n&quot;)
            sb.WriteString(strconv.Itoa(counter + 14))
            sb.WriteString(&quot;\nFizzBuzz\n&quot;)

            counter += 15
        }
        start.Lock()
        os.Stdout.WriteString((sb.String()))
        end.Unlock()
        sb.buf = sb.buf[:0]
        counter += 15 * (routines - 1) * innerloop

    }
}

// After this copied from go stringBuilder(some lines removed)
// Copyright 2017 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

// A Builder is used to efficiently build a string using Write methods.
// It minimizes memory copying. The zero value is ready to use.
// Do not copy a non-zero Builder.
type Builder struct {
    addr *Builder // of receiver, to detect copies by value
    buf  []byte
}

// noescape hides a pointer from escape analysis.  noescape is
// the identity function but escape analysis doesn't think the
// output depends on the input. noescape is inlined and currently
// compiles down to zero instructions.
// USE CAREFULLY!
// This was copied from the runtime; see issues 23382 and 7921.
//go:nosplit
//go:nocheckptr
func noescape(p unsafe.Pointer) unsafe.Pointer {
    x := uintptr(p)
    return unsafe.Pointer(x ^ 0)
}

func (b *Builder) copyCheck() {
    if b.addr == nil {
        // This hack works around a failing of Go's escape analysis
        // that was causing b to escape and be heap allocated.
        // See issue 23382.
        // TODO: once issue 7921 is fixed, this should be reverted to
        // just &quot;b.addr = b&quot;.
        b.addr = (*Builder)(noescape(unsafe.Pointer(b)))
    } else if b.addr != b {
        panic(&quot;strings: illegal use of non-zero Builder copied by value&quot;)
    }
}

// String returns the accumulated string.
func (b *Builder) String() string {
    return *(*string)(unsafe.Pointer(&amp;b.buf))
}

// grow copies the buffer to a new, larger buffer so that there are at least n
// bytes of capacity beyond len(b.buf).
func (b *Builder) grow(n int) {
    buf := make([]byte, len(b.buf), 2*cap(b.buf)+n)
    copy(buf, b.buf)
    b.buf = buf
}

// Grow grows b's capacity, if necessary, to guarantee space for
// another n bytes. After Grow(n), at least n bytes can be written to b
// without another allocation. If n is negative, Grow panics.
func (b *Builder) Grow(n int) {
    if n &lt; 0 {
        panic(&quot;strings.Builder.Grow: negative count&quot;)
    }
    if cap(b.buf)-len(b.buf) &lt; n {
        b.grow(n)
    }
}

// WriteString appends the contents of s to b's buffer.
// It returns the length of s and a nil error.
func (b *Builder) WriteString(s string) (int, error) {
    b.buf = append(b.buf, s...)
    return len(s), nil
}
</code></pre>
<p>go run main.go | pv -a &gt;/dev/null</p>
<p>Github: <a href="https://github.com/Bysmyyr/fizzbuzz" rel="nofollow noreferrer">https://github.com/Bysmyyr/fizzbuzz</a></p>
</div>
<div id="pu20" class="pu"><h1>x86-64+AVX2 assembly language (Linux, <code>gcc</code>+<code>gas</code>)</h1>

<h3>Build and usage instructions</h3>
<p>This program is most conveniently built using <code>gcc</code>. Save it as <code>fizzbuzz.S</code> (that's a capital <code>S</code> as the extension), and build using the commands</p>
<pre><code>gcc -mavx2 -c fizzbuzz.S
ld -o fizzbuzz fizzbuzz.o
</code></pre>
<p>Run as <code>./fizzbuzz</code> piped into one command, e.g. <code>./fizzbuzz | pv &gt; /dev/null</code> (as suggested in the question), <code>./fizzbuzz | cat</code>, or <code>./fizzbuzz | less</code>. To simplify the I/O, this will not work (producing an error on startup) if you try to output to a file/terminal/device rather than a pipe. Additionally, this program may produce incorrect output if piped into two commands (e.g. <code>./fizzbuzz | pv | cat &gt; fizzbuzz.txt</code>), but only in the case where the middle command uses the <code>splice</code> system call; this is either a bug in Linux (very possible with system calls this obscure!) or a mistake in the documentation of the system calls in question (also possible). However, it should work correctly for the use case in the question, which is all that matters on CGCC.</p>
<p>This program is somewhat system-specific; it requires the operating system to be a non-ancient version of Linux, and the processor to be an x86-64 implementation that supports AVX2. (Most moderately recent processors by Intel and AMD have AVX2 support, including the Ryzen 9 mentioned in the question, and almost all use the x86-64 instruction set.) However, it avoids assumptions about the system it's running on beyond those mentioned in the header, so there's a decent chance that if you can run Linux, you can run this.</p>
<p>The program outputs a quintillion lines of FizzBuzz and then exits (going further runs into problems related to the sizes of registers). This would take tens of years to accomplish, so hopefully counts as &quot;a very high astronomical number&quot; (although it astonishes me that it's a small enough timespan that it might be theoretically possible to reach a number as large as a quintillion without the computer breaking).</p>
<p>As a note: this program's performance is dependent on whether it and the program it outputs to are running on sibling CPUs or not, something which will be determined arbitrarily by the kernel when you start it. If you want to compare the two possible timings, use <code>taskset</code> to force the programs onto particular CPUs:
<code>taskset 1 ./fizzbuzz | taskset 2 pv &gt; /dev/null</code> versus <code>taskset 1 ./fizzbuzz | taskset 4 pv &gt; /dev/null</code>. (The former will probably run faster, but might be slower on some CPU configurations.)</p>
<h3>Discussion</h3>
<p>I've spent months working on this program. I've long thought that &quot;how fast can you make a FizzBuzz&quot; would be a really interesting question for learning about high-performance programming, and when I subsequently saw this question posted on CGCC, I pretty much had to try.</p>
<p>This program aims for the maximum possible single-threaded performance. In terms of the FizzBuzz calculation itself, it is intended to sustain a performance of 64 bytes of FizzBuzz per 4 clock cycles (and is future-proofed where possible to be able to run faster if the relevant processor bottleneck – L2 cache write speed – is ever removed). This is faster than a number of standard functions. In particular, it's faster than <code>memcpy</code>, which presents interesting challenges when it comes to I/O (if you try to output using <code>write</code> then the copies in <code>write</code> will take up almost all the runtime – replacing the I/O routine here with <code>write</code> causes the performance on my CPU to drop by a factor of 5). As such, I needed to use much more obscure system calls to keep I/O-related copies to a minimum (in particular, the generated FizzBuzz text is only sent to main memory if absolutely necessary; most of the time it's stored in the processor's L2 cache and piped into the target program from there, which is why reading it from a sibling CPU can boost performance – the physical connection to the L2 cache is shorter and higher bandwidth than it would be to a more distant CPU).</p>
<p>On my computer (which has a fairly recent, but not particularly powerful, Intel processor), this program generates around 31GiB of FizzBuzz per second. I'll be interested to see how it does on the OP's computer.</p>
<p>I did experiment with multithreaded versions of the program, but was unable to gain any speed. Experiments with simpler programs show that it could be possible, but any gains may be small; the cost of communication between CPUs is sufficiently high to negate most of the gains you could get by doing work in parallel, assuming that you only have one program reading the resulting FizzBuzz (and anything that writes to memory will be limited by the write speed of main memory, which is slower than the speed with which the FizzBuzz can be generated).</p>
<h3>The program</h3>
<p>This isn't <a href="/questions/tagged/code-golf" class="post-tag" title="show questions tagged &#39;code-golf&#39;" rel="tag">code-golf</a>, so my explanation of the program and its algorithm are given as comments in the program itself. (I still had to lightly golf the program, and especially the explanation, to fit this post within the 65536 byte size limit.)</p>
<p>The program is written in a &quot;literate&quot; assembly style; it will be easiest to understand if you read it in order, from start to end. (I also added a number of otherwise useless line labels to separate the program into logical groups of instructions, in order to make the disassembly easier to read, if you're one of the people who prefers to read assembly code like that.)</p>
<pre class="lang-c prettyprint-override"><code>.intel_syntax prefix

// Header files.
#include &lt;asm/errno.h&gt;
#include &lt;asm/mman.h&gt;
#include &lt;asm/unistd.h&gt;
#define F_SETPIPE_SZ 1031 // not in asm headers, define it manually

// The Linux system call API (limited to 4 arguments, the most this
// program uses). 64-bit registers are unsuffixed; 32-bit have an &quot;e&quot;
// suffix.
#define ARG1 %rdi
#define ARG1e %edi
#define ARG2 %rsi
#define ARG2e %esi
#define ARG3 %rdx
#define ARG3e %edx
#define ARG4 %r10
#define ARG4e %r10d
#define SYSCALL_RETURN %rax
#define SYSCALL_RETURNe %eax
#define SYSCALL_NUMBER %eax

// %rax, %rcx, %rdx, %ymm0-3 are general-purpose temporaries. Every
// other register is used for just one or two defined purposes; define
// symbolic names for them for readability. (Bear in mind that some of
// these will be clobbered sometimes, e.g. OUTPUT_LIMIT is clobbered
// by `syscall` because it's %r11.)
#define OUTPUT_PTR %rbx
#define BYTECODE_IP %rbp
#define SPILL %rsi
#define BYTECODE_GEN_PTR %rdi
#define REGEN_TRIGGER %r8
#define REGEN_TRIGGERe %r8d
#define YMMS_AT_WIDTH %r9
#define YMMS_AT_WIDTHe %r9d
#define BUZZ %r10
#define BYTECODE_NEG_LEN %r10
#define FIZZ %r11
#define FIZZe %r11d
#define OUTPUT_LIMIT %r11
#define BYTECODE_END %r12
#define BYTECODE_START %r13
#define BYTECODE_STARTe %r13d
#define PIPE_SIZE %r13
#define LINENO_WIDTH %r14
#define LINENO_WIDTHe %r14d
#define GROUPS_OF_15 %r15
#define GROUPS_OF_15e %r15d
#define LINENO_LOW %ymm4
#define LINENO_MID %ymm5
#define LINENO_MIDx %xmm5
#define LINENO_TOP %ymm6
#define LINENO_TOPx %xmm6
#define LINENO_MID_TEMP %ymm7
#define ENDIAN_SHUFFLE %ymm8
#define ENDIAN_SHUFFLEx %xmm8
#define LINENO_LOW_INCR %ymm9
#define LINENO_LOW_INCRx %xmm9

// The last six vector registers are used to store constants, to avoid
// polluting the cache by loading their values from memory.
#define LINENO_LOW_INIT %ymm10
#define LINENO_MID_BASE %ymm11
#define LINENO_TOP_MAX %ymm12
#define ASCII_OFFSET %ymm13
#define ASCII_OFFSETx %xmm13
#define BIASCII_OFFSET %ymm14
#define BASCII_OFFSET %ymm15


// Global variables.
.bss
.align 4 &lt;&lt; 20
// The most important global variables are the IO buffers. There are
// two of these, each with 2MiB of memory allocated (not all of it is
// used, but putting them 2MiB apart allows us to simplify the page
// table; this gives a 30% speedup because page table contention is
// one of the main limiting factors on the performance).
io_buffers:
.zero 2 * (2 &lt;&lt; 20)
// The remaining 2MiB of memory stores everything else:
iovec_base:          // I/O config buffer for vmsplice(2) system call
.zero 16
error_write_buffer:  // I/O data buffer for write(2) system call
.zero 1
.p2align 9,0
bytecode_storage:    // the rest is a buffer for storing bytecode
.zero (2 &lt;&lt; 20) - 512


// The program starts here. It doesn't use the standard library (or
// indeed any libraries), so the start point is _start, not main.
.text
.globl _start
_start:

// This is an AVX2 program, so check for AVX2 support by running an
// AVX2 command. This is a no-op, but generates SIGILL if AVX2 isn't
// supported.
vpand %ymm0, %ymm0, %ymm0

// Initialize constant registers to their constant values.
vmovdqa LINENO_LOW_INIT, [%rip + lineno_low_init]
vmovdqa LINENO_MID_BASE, [%rip + lineno_mid_base]
vmovdqa LINENO_TOP_MAX, [%rip + lineno_top_max]
vmovdqa ASCII_OFFSET, [%rip + ascii_offset]
vmovdqa BIASCII_OFFSET, [%rip + biascii_offset]
vmovdqa BASCII_OFFSET, [%rip + bascii_offset]

// Initialize global variables to their initial values.
vmovdqa ENDIAN_SHUFFLE, [%rip + endian_shuffle_init]
vmovdqa LINENO_TOP, [%rip + lineno_top_init]

// Check the size of the L2 cache.
//
// This uses the CPUID interface. To use it safely, check what range
// of command numbers is legal; commands above the legal range have
// undefined behaviour, commands within the range might not be
// implemented but will return all-zeros rather than undefined values.
// CPUID clobbers a lot of registers, including some that are normally
// call-preserved, so this must be done first.
mov %eax, 0x80000000 // asks which CPUID extended commands exist
cpuid                // returns the highest supported command in %eax
cmp %eax, 0x80000006 // does 0x80000006 give defined results?
jb bad_cpuid_error

mov %eax, 0x80000006 // asks about the L2 cache size
cpuid                // returns size in KiB in the top half of %ecx
shr %ecx, 16
jz bad_cpuid_error   // unsupported commands return all-0s

// Calculate the desired pipe size, half the size of the L2 cache.
// This value is chosen so that the processor can hold a pipeful of
// data being output, plus a pipeful of data being calculated, without
// needing to resort to slow L3 memory operations.
shl %ecx, 10 - 1     // convert KiB to bytes, then halve
mov PIPE_SIZE, %rcx

// Ask the kernel to resize the pipe on standard output.
mov ARG1e, 1
mov ARG2e, F_SETPIPE_SZ
mov ARG3e, %ecx
mov SYSCALL_NUMBER, __NR_fcntl
syscall
cmp SYSCALL_RETURNe, -EBADF
je pipe_error
cmp SYSCALL_RETURNe, -EPERM
je pipe_perm_error
call exit_on_error
cmp SYSCALL_RETURN, PIPE_SIZE
jne pipe_size_mismatch_error

// Ask the kernel to defragment the physical memory backing the BSS
// (read-write data) segment. This simplifies the calculations needed
// to find physical memory addresses, something that both the kernel
// and processor would otherwise spend a lot of time doing, and
// speeding the program up by 30%.
lea ARG1, [%rip + io_buffers]
mov ARG2e, 3 * (2 &lt;&lt; 20)
mov ARG3e, MADV_HUGEPAGE
mov SYSCALL_NUMBER, __NR_madvise
syscall
call exit_on_error

// From now on, OUTPUT_PTR is permanently set to the memory location
// where the output is being written. This starts at the start of the
// first I/O buffer.
lea OUTPUT_PTR, [%rip + io_buffers]


///// First phase of output
//
// The FizzBuzz output is produced in three distinct phases. The first
// phase is trivial; just a hardcoded string, that's left in the
// output buffer, to be output at the end of the second phase.

first_phase:

.section .rodata
fizzbuzz_intro:
.ascii &quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\n&quot;
.text
vmovdqu %ymm0, [%rip + fizzbuzz_intro]
vmovdqu [OUTPUT_PTR], %ymm0
add OUTPUT_PTR, 30


///// Second phase of output
//
// This is a routine implementing FizzBuzz in x86-64+AVX2 assembler in
// a fairly straightforward and efficient way. This isn't as fast as
// the third-phase algorithm, and can't handle large numbers, but will
// introduce some of the basic techniques this program uses.

second_phase_init:

// The outer loop of the whole program breaks the FizzBuzz output into
// sections where all the line numbers contain the same number of
// digits. From now on, LINENO_WIDTH tracks the number of digits in
// the line number. This is currently 2; it ranges from 2-digit
// numbers to 18-digit numbers, and then the program ends.
mov LINENO_WIDTHe, 2

// GROUPS_OF_15 is permanently set to the number of groups of 15 lines
// that exist at this line number width; it's multiplied by 10 whenever
// LINENO_WIDTH is incremented.
//
// A general note about style: often the program uses numbers that are
// statically known to fit into 32 bits, even in a register that's
// conceptually 64 bits wide (like this one). In such cases, the
// 32-bit and 64-bit versions of a command will be equivalent (as the
// 32-bit version zero-extends to 64-bits on a 64-bit processor); this
// program generally uses the 32-bit version, both because it
// sometimes encodes to fewer bytes (saving cache pressure), and
// because some processors recognise zeroing idioms only if they're 32
// bits wide.
mov GROUPS_OF_15e, 6

// Some constants used throughout the second phase, which permanently
// stay in their registers. Note that short string literals can be
// stored in normal integer registers - the processor doesn't care.
mov FIZZ, 0x0a7a7a6946  // &quot;Fizz\n&quot;
mov BUZZ, 0x0a7a7a7542  // &quot;Buzz\n&quot;

.section .rodata
.p2align 5, 0
second_phase_constants:
.byte 0, 0, 0, 0, 0, 0, 0, 0
.byte 1, 0, 0, 0, 0, 0, 0, 0
.text
vmovdqa %xmm3, [%rip + second_phase_constants]

// This program makes extensive use of a number format that I call
// &quot;high-decimal&quot;. This is a version of decimal where the digit 0 is
// encoded as the byte 246, the digit 1 as the byte 247, ..., the
// digit 9 as the byte 255. The bytes are stored in the normal
// endianness for the processor (i.e. least significant first), and
// padded to a known length (typically 8 digits) with leading zeroes.
//
// The point of high-decimal is that it allows us to use arithmetic
// operators intended for binary on high-decimal numbers, and the
// carries will work the same way (i.e. the same digits will carry,
// although carries will be 0-based rather than 246-based); all that's
// required is to identify the digits that carried and add 246 to
// them. That means that the processor's binary ALU can be used to do
// additions directly in decimal - there's no need for loops or
// anything like that, and no need to do binary/decimal conversions.
//
// The first use for high-decimal is to store the line number during
// the second phase (it's stored differently in the third phase).
// It's stored it in the top half of %xmm1 (although it's only 64 bits
// wide, it needs to be in a vector register so that it can be
// interpreted as 8 x 8 bits when necessary; general-purpose
// registers can't do that). The bottom half of %xmm1 is unused, and
// frequently overwritten with arbitrary data.
.section .rodata
line_number_init:
#define REP8(x) x,x,x,x,x,x,x,x
.byte REP8(0)
.byte 246, 247, 246, 246, 246, 246, 246, 246
.text
vmovdqa %xmm1, [%rip + line_number_init]

// Writing line numbers is nontrivial because x86-64 is little-endian
// but FizzBuzz output is big-endian; also, leading zeroes aren't
// allowed. ENDIAN_SHUFFLE is used to fix both these problems; when
// used to control the vector shuffler, it reverses the order of a
// vector register, and rotates the elements to put the first digit
// (based on LINENO_WIDTH) into the first byte. (This method is used
// by both the second and third phases; the second phase uses only the
// bottom half, with the top half used by the third phase, but they
// are both initialized together.)
.section .rodata
endian_shuffle_init:
.byte 9, 8, 7, 6, 5, 4, 3, 2
.byte 1, 0, 255, 254, 253, 252, 251, 250
.byte 3, 2, 1, 0, 255, 254, 253, 252
.byte 251, 250, 249, 248, 247, 246, 245, 244
.text


second_phase_per_width_init:

// The second phase writing routines are macros.
//
// Fizz and Buzz are trivial. (This writes a little beyond the end of
// the string, but that's OK; the next line will overwrite them.)
#define WRITE_FIZZ   mov [OUTPUT_PTR], FIZZ; add OUTPUT_PTR, 5
#define WRITE_BUZZ   mov [OUTPUT_PTR], BUZZ; add OUTPUT_PTR, 5

// For FizzBuzz, output 32 bits of FIZZ to write &quot;Fizz&quot; with no
// newline, then write a &quot;Buzz&quot; after that.
#define WRITE_FIZZBUZZ \
  mov [OUTPUT_PTR], FIZZe; mov [OUTPUT_PTR + 4], BUZZ; \
  add OUTPUT_PTR, 9

// To write a line number, add 58 to each byte of the line number
// %xmm1, fix the endianness and width with a shuffle, and write a
// final newline.
.section .rodata
ascii_offset:
.byte REP8(58), REP8(58), REP8(58), REP8(58)
.text
#define WRITE_LINENO \
  vpaddb %xmm0, ASCII_OFFSETx, %xmm1; \
  vpshufb %xmm0, %xmm0, ENDIAN_SHUFFLEx; \
  vmovdqu [OUTPUT_PTR], %xmm0; \
  lea OUTPUT_PTR, [OUTPUT_PTR + LINENO_WIDTH + 1]; \
  mov byte ptr [OUTPUT_PTR - 1], 10  // 10 = newline

// Incrementing the line number is fairly easy: add 1 (in the usual
// binary notation, taken from %xmm3) to the high-decimal number, then
// convert any bytes that produced a carry to high-decimal 0s by
// max-ing with 246.
//
// Normally I'd use a separate constant for this, but there randomly
// happens to be an %xmm register with 246s in its top half already
// (it's intended for an entirely different purpose, but it'll do for
// this one too).
#define INC_LINENO \
  vpaddq %xmm1, %xmm3, %xmm1; vpmaxub %xmm1, LINENO_TOPx, %xmm1

// Avoid modulus tests by unrolling the FizzBuzz by 15. (Bear in mind
// that this starts at 10, not 0, so the pattern will have a different
// phase than usual.)
mov %ecx, GROUPS_OF_15e
fifteen_second_phase_fizzbuzz_lines:
WRITE_BUZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZBUZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_BUZZ; INC_LINENO
WRITE_FIZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZ; INC_LINENO
dec %ecx
jnz fifteen_second_phase_fizzbuzz_lines

second_phase_increment_width:

lea GROUPS_OF_15e, [GROUPS_OF_15 + GROUPS_OF_15 * 4]
add GROUPS_OF_15e, GROUPS_OF_15e
inc LINENO_WIDTHe

// Increment every element of the low half of ENDIAN_SHUFFLE to
// adjust it for the new width, while leaving the top half unchanged.
vpcmpeqb %xmm0, %xmm0, %xmm0
vpsubb ENDIAN_SHUFFLE, ENDIAN_SHUFFLE, %ymm0

// The second phase handles line numbers with 2 to 5 digits.
cmp LINENO_WIDTHe, 6
jne second_phase_per_width_init

///// The output routine
//
// Most FizzBuzz routines produce output with `write` or a similar
// system call, but these have the disadvantage that they need to copy
// the data being output from userspace into kernelspace. It turns out
// that when running full speed (as seen in the third phase), FizzBuzz
// actually runs faster than `memcpy` does, so `write` and friends are
// unusable when aiming for performance - this program runs five times
// faster than an equivalent that uses `write`-like system calls.
//
// To produce output without losing speed, the program therefore needs
// to avoid copies, or at least do them in parallel with calculating
// the next block of output. This can be accomplished with the
// `vmsplice` system call, which tells the kernel to place a reference
// to a buffer into a pipe (as opposed to copying the data into the
// pipe); the program at the other end of this pipe will then be able
// to read the output directly out of this program's memory, with no
// need to copy the data into kernelspace and then back into
// userspace. In fact, it will be reading out of this program's
// processor's L2 cache, without main memory being touched at all;
// this is the secret to high-performance programming, because the
// cache is much faster than main memory is.
//
// Of course, it's therefore important to avoid changing the output
// buffer until the program connected to standard output has actually
// read it all. This is why the pipe size needed to be set earlier; as
// long as the amount of output is always at least as large as the
// pipe size, successfully outputting one buffer will ensure that none
// of the other buffer is left in the pipe, and thus it's safe to
// overwrite the memory that was previously output. There is some need
// to jump through hoops later on to make sure that `swap_buffers` is
// never called with less than one pipeful of data, but it's worth it
// to get the huge performance boost.

mov %rdx, OUTPUT_PTR
and %edx, (2 &lt;&lt; 20) - 1

call swap_buffers
jmp third_phase_init

// Takes the amount of data to output in %rdx, and outputs from the
// buffer containing OUTPUT_PTR.
swap_buffers:
and OUTPUT_PTR, -(2 &lt;&lt; 20)  // rewind to the start of the buffer
mov [%rip + iovec_base], OUTPUT_PTR
mov [%rip + iovec_base + 8], %rdx
mov ARG1e, 1
lea ARG2, [%rip + iovec_base]
mov ARG3e, 1
xor ARG4e, ARG4e

// As with most output commands, vmsplice can do a short write
// sometimes, so it needs to be called in a loop in order to ensure
// that all the output is actually sent.
1: mov SYSCALL_NUMBER, __NR_vmsplice
syscall
call exit_on_error
add [ARG2], SYSCALL_RETURN
sub [ARG2 + 8], SYSCALL_RETURN
jnz 1b

xor OUTPUT_PTR, (2 &lt;&lt; 20)  // swap to the other buffer
ret


///// Third phase of output
//
// This is the heart of this program. It aims to be able to produce a
// sustained output rate of 64 bytes of FizzBuzz per four clock cycles
// in its main loop (with frequent breaks to do I/O, and rare breaks
// to do more expensive calculations).
//
// The third phase operates primarily using a bytecode interpreter; it
// generates a program in &quot;FizzBuzz bytecode&quot;, for which each byte of
// bytecode generates one byte of output. The bytecode language is
// designed so that it can be interpreted using SIMD instructions; 32
// bytes of bytecode can be loaded from memory, interpreted, and have
// its output stored back into memory using just four machine
// instructions. This makes it possible to speed up the FizzBuzz
// calculations by hardcoding some of the calculations into the
// bytecode (this is similar to how JIT compilers can create a version
// of the program with some variables hardcoded, and throw it away on
// the rare occasions that those variables' values change).

third_phase_init:

// Reinitialize ENDIAN_SHUFFLE by copying the initializer stored in
// its high half to both halves. This works in the same way as in the
// second phase.
vpermq ENDIAN_SHUFFLE, ENDIAN_SHUFFLE, 0xEE

// Up to this point, PIPE_SIZE has held the size of the pipe. In order
// to save on registers, the pipe size is from now on encoded via the
// location in which the bytecode program is stored; the bytecode is
// started at iovec_base + PIPE_SIZE (which will be somewhere within
// bytecode_storage), so the same register can be used to find the
// bytecode and to remember the pipe size.
lea %rax, [%rip + iovec_base]
add BYTECODE_START, %rax  // BYTECODE_START is a synonym for PIPE_SIZE

// The bytecode program always holds instructions to produce exactly
// 600 lines of FizzBuzz. At width 6, those come to 3800 bytes long.
lea BYTECODE_END, [BYTECODE_START + 3800]

mov REGEN_TRIGGER, -1  // irrelevant until much later, explained there


third_phase_per_width_init:

// Calculate the amount of output at this LINENO_WIDTH. The result
// will always be divisible by 32, and thus is stored as the number of
// 32-byte units at this width; storing it in bytes would be more
// convenient, but sadly would overflow a 64-bit integer towards the
// end of the program.
lea %ecx, [LINENO_WIDTH * 8 + 47]   // bytes per 15 lines
mov YMMS_AT_WIDTH, GROUPS_OF_15
shr YMMS_AT_WIDTH, 5   // to avoid overflow, divide by 32 first
imul YMMS_AT_WIDTH, %rcx

// This program aims to output 64 bytes of output per four clock
// cycles, which it achieves via a continuous stream of 32-byte writes
// calculated by the bytecode program. One major complication here is
// that the 32-byte writes won't correspond to lines of FizzBuzz; a
// single processor instruction may end up outputting multiple
// different line numbers. So it's no longer possible to have a simple
// line number register, like it was in the second phase.
//
// Instead, the program stores an *approximation* of the line number,
// which is never allowed to differ by 100 or more from the &quot;actual&quot;
// line number; the bytecode program is responsible for fixing up the
// approximation to work out the correct line number to output (this
// allows the same CPU instruction to output digits from multiple
// different line numbers, because the bytecode is being interpreted
// in a SIMD way and thus different parts of the bytecode can fix the
// line number up differently within a single instruction.
//
// The line number is split over three processor registers:
// - LINENO_LOW: stores the line number modulo 200
// - LINENO_MID: stores the hundreds to billions digits
// - LINENO_TOP: stores the ten-billions and more significant digits
// (The parity of the 100s digit is duplicated between LINENO_MID and
// LINENO_LOW; this allows a faster algorithm for LINENO_MID updates.)
//
// Because there's only a need to be within 100 of the real line
// number, the algorithm for updating the line numbers doesn't need to
// run all that often (saving processor cycles); it runs once every
// 512 bytes of output, by simply adding a precalculated value
// (LINENO_LOW_INCR) to LINENO_LOW, then processing the carry to
// LINENO_MID (see later for LINENO_TOP). The amount by which the line
// number increases per 512 bytes of output is not normally going to
// be an integer; LINENO_LOW is therefore stored as a 64-bit fixpoint
// number (in which 2**64 represents &quot;200&quot;, e.g. 2**63 would be the
// representation of &quot;the line number is 100 mod 200&quot;), in order to
// delay the accumulation of rounding errors as long as possible. It's
// being stored in a vector register, so there are four copies of its
// value; two of them have 50 (i.e 2**62) added, and two of them have
// 50 subtracted, in order to allow for more efficient code to handle
// the carry to LINENO_MID. Additionally, LINENO_LOW is interpreted as
// a signed number (an older version of this program was better at
// checking for signed than unsigned overflow and I had no reason to
// change).
//
// LINENO_LOW and LINENO_MID are reset every LINENO_WIDTH increase
// (this is because the program can calculate &quot;past&quot; the width
// increase due to not being able to break out of every instruction of
// the main loop, which may cause unwanted carries into LINENO_MID and
// force a reset).

.section .rodata
lineno_low_init:
.byte 0, 0, 0, 0, 0, 0, 0, 192
.byte 0, 0, 0, 0, 0, 0, 0, 64
.byte 0, 0, 0, 0, 0, 0, 0, 192
.byte 0, 0, 0, 0, 0, 0, 0, 64
.text
vmovdqa LINENO_LOW, LINENO_LOW_INIT

// %ecx is the number of bytes in 15 lines. That means that the number
// of 200-line units in 512 bytes is 38.4/%ecx, i.e. 384/(%ecx*10).
// Multiply by 2**64 (i.e. 384*2**64/(%ecx*10) to get LINENO_LOW_INCR.
lea %ecx, [%rcx + %rcx * 4]
add %ecx, %ecx
mov %edx, 384
xor %eax, %eax
div %rcx  // 128-bit divide, %rax = %rdx%rax / %rcx
vpxor LINENO_LOW_INCR, LINENO_LOW_INCR, LINENO_LOW_INCR
vpinsrq LINENO_LOW_INCRx, LINENO_LOW_INCRx, %rax, 0
vpermq LINENO_LOW_INCR, LINENO_LOW_INCR, 0

// LINENO_MID is almost stored in high-decimal, as four eight-digit
// numbers. However, the number represented is the closest line number
// that's 50 mod 100, stored as the two closest multiples of 100 (e.g.
// if the true line number is 235, it's approximated as 250 and then
// stored using the representations for 200 and 300), which is why
// LINENO_LOW needs the offsets of 50 and -50 to easily do a carry. A
// ymm vector holds four 64-bit numbers, two of which hold the value
// that's 0 mod 200, two which hold the value that's 100 mod 200. So
// carries on it are handled using a vector of mostly 246s, with 247s
// in the two locations which are always odd.
.section .rodata
lineno_mid_base:
.byte 246, 246, 246, 246, 246, 246, 246, 246
.byte 247, 246, 246, 246, 246, 246, 246, 246
.byte 246, 246, 246, 246, 246, 246, 246, 246
.byte 247, 246, 246, 246, 246, 246, 246, 246
.text

// This code is some fairly complex vector manipulation to initialise
// LINENO_MID to a power of 10 (handling the case where LINENO_WIDTH
// is so high that the hundreds to billions digits are all zeroes).
mov %edx, 1
mov %eax, 11
sub %eax, LINENO_WIDTHe
cmovbe %eax, %edx
shl %eax, 3
vpxor %xmm0, %xmm0, %xmm0
vpinsrq %xmm0, %xmm0, %rax, 0
vpermq %ymm0, %ymm0, 0
vpcmpeqb LINENO_MID, LINENO_MID, LINENO_MID
vpsrlq LINENO_MID, LINENO_MID, %xmm0
vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID
vpermq %ymm0, LINENO_MID_BASE, 0x55
vpsubb %ymm0, %ymm0, LINENO_MID_BASE
vpaddq LINENO_MID, LINENO_MID, %ymm0
vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID

// LINENO_TOP doesn't need to be initialized for new widths, because
// an overrun by 100 lines is possible, but by 10 billion lines isn't.
// The format consists of two 64-bit sections that hold high-decimal
// numbers (these are always the same as each other), and two that
// hold constants that are used by the bytecode generator.
.section .rodata
lineno_top_init:
.byte 198, 197, 196, 195, 194, 193, 192, 191
.byte 246, 246, 246, 246, 246, 246, 246, 246
.byte 190, 189, 188, 187, 186, 185, 184, 183
.byte 246, 246, 246, 246, 246, 246, 246, 246
.text

// When moving onto a new width, start at the start of the bytecode
// program.
mov BYTECODE_IP, BYTECODE_START


// Generating the bytecode program
//
// The bytecode format is very simple (in order to allow it to be
// interpreted in just a couple of machine instructions):
// - A negative byte represents a literal character (e.g. to produce
//   a literal 'F', you use the bytecode -'F', i.e. -70 = 0xba)
// - A byte 0..7 represents the hundreds..billions digit of the line
//   number respectively, and asserts that the hundreds digit of the
//   line number is even
// - A byte 8..15 represents the hundreds..billions digit of the line
//   number respectively, and asserts that the hundreds digit of the
//   line number is odd
//
// In other words, the bytecode program only ever needs to read from
// LINENO_MID; the information stored in LINENO_LOW and LINENO_TOP
// therefore has to be hardcoded into it. The program therefore needs
// to be able to generate 600 lines of output (as the smallest number
// that's divisible by 100 to be able to hardcode the two low digits,
// 200 to be able to get the assertions about the hundreds digits
// correct, and 3 and 5 to get the Fizzes and Buzzes in the right
// place).

generate_bytecode:

mov BYTECODE_GEN_PTR, BYTECODE_START

// FIZZ and BUZZ work just like in the second phase, except that they
// are now bytecode programs rather than ASCII.
mov FIZZ, 0xf6868697ba  // -&quot;Fizz\n&quot;
mov BUZZ, 0xf686868bbe  // -&quot;Buzz\n&quot;

// %ymm2 holds the bytecode for outputting the hundreds and more
// significant digits of a line number. The most significant digits of
// this can be obtained by converting LINENO_TOP from high-decimal to
// the corresponding bytecode, which is accomplished by subtracting
// from 198 (i.e. 256 - 10 - '0'). The constant parts of LINENO_TOP
// are 198 minus the bytecode for outputting the hundreds to billions
// digit of a number; this makes it possible for a single endian
// shuffle to deal with all 16 of the mid and high digits at once.
.section .rodata
bascii_offset:
.byte REP8(198), REP8(198), REP8(198), REP8(198)
.text
vpsubb %ymm2, BASCII_OFFSET, LINENO_TOP
vpshufb %ymm2, %ymm2, ENDIAN_SHUFFLE

#define GEN_FIZZ  mov [BYTECODE_GEN_PTR], FIZZ; add BYTECODE_GEN_PTR, 5
#define GEN_BUZZ  mov [BYTECODE_GEN_PTR], BUZZ; add BYTECODE_GEN_PTR, 5
#define GEN_FIZZBUZZ \
  mov [BYTECODE_GEN_PTR], FIZZe; \
  mov [BYTECODE_GEN_PTR + 4], BUZZ; add BYTECODE_GEN_PTR, 9
#define GEN_LINENO(units_digit) \
  vmovdqu [BYTECODE_GEN_PTR], %xmm2; \
  lea BYTECODE_GEN_PTR, [BYTECODE_GEN_PTR + LINENO_WIDTH + 1]; \
  mov [BYTECODE_GEN_PTR - 3], %al; \
  mov word ptr [BYTECODE_GEN_PTR - 2], 0xf6d0 - units_digit

// The bytecode generation loop is unrolled to depth 30, allowing the
// units digits to be hardcoded. The tens digit is stored in %al, and
// incremented every ten lines of output. The parity of the hundreds
// digit is stored in %ymm2: one half predicts the hundreds digit to
// be even, the other to be odd, and the halves are swapped every time
// the tens digit carries (ensuring the predictions are correct).
mov %eax, 0xd0
jmp 2f
inc_tens_digit:
cmp %al, 0xc7
je 1f  // jumps every 10th execution, therefore predicts perfectly
dec %eax
ret
1: mov %eax, 0xd0
vpermq %ymm2, %ymm2, 0x4e
ret

2: mov %ecx, 20
thirty_bytecode_lines:
GEN_BUZZ
GEN_LINENO(1)
GEN_FIZZ
GEN_LINENO(3)
GEN_LINENO(4)
GEN_FIZZBUZZ
GEN_LINENO(6)
GEN_LINENO(7)
GEN_FIZZ
GEN_LINENO(9)
call inc_tens_digit
GEN_BUZZ
GEN_FIZZ
GEN_LINENO(2)
GEN_LINENO(3)
GEN_FIZZ
GEN_BUZZ
GEN_LINENO(6)
GEN_FIZZ
GEN_LINENO(8)
GEN_LINENO(9)
call inc_tens_digit
GEN_FIZZBUZZ
GEN_LINENO(1)
GEN_LINENO(2)
GEN_FIZZ
GEN_LINENO(4)
GEN_BUZZ
GEN_FIZZ
GEN_LINENO(7)
GEN_LINENO(8)
GEN_FIZZ
call inc_tens_digit
dec %ecx
jnz thirty_bytecode_lines

generate_bytecode_overrun_area:

// Duplicate the first 512 bytes of the bytecode program at the end,
// so that there's no need to check to see whether BYTECODE_IP needs
// to be looped back to the start of the program any more than once
// per 512 bytes
mov %rax, BYTECODE_START
#define COPY_64_BYTECODE_BYTES(offset) \
  vmovdqa %ymm0, [%rax + offset]; \
  vmovdqa %ymm3, [%rax + (offset + 32)]; \
  vmovdqu [BYTECODE_GEN_PTR + offset], %ymm0; \
  vmovdqu [BYTECODE_GEN_PTR + (offset + 32)], %ymm3
COPY_64_BYTECODE_BYTES(0)
COPY_64_BYTECODE_BYTES(64)
COPY_64_BYTECODE_BYTES(128)
COPY_64_BYTECODE_BYTES(192)
COPY_64_BYTECODE_BYTES(256)
COPY_64_BYTECODE_BYTES(320)
COPY_64_BYTECODE_BYTES(384)
COPY_64_BYTECODE_BYTES(448)


// Preparing for the main loop
//
// Work out how long the main loop is going to iterate for.
// OUTPUT_LIMIT holds the address just beyond the end of the output
// that the main loop should produce. The aim here is to produce
// exactly one pipeful of data if possible, but to stop earlier if
// there's a change in digit width (because any output beyond that
// point will be useless: the bytecode will give it the wrong number
// of digits).
calculate_main_loop_iterations:

// Extract the pipe size from BYTECODE_START, in 32-byte units.
// During this calculation, OUTPUT_LIMIT holds the amount of output
// produced, rather than an address like normal.
mov OUTPUT_LIMIT, BYTECODE_START
lea %rdx, [%rip + iovec_base]
sub OUTPUT_LIMIT, %rdx
shr OUTPUT_LIMIT, 5

// Reduce the output limit to the end of this width, if it would be
// higher than that.
cmp OUTPUT_LIMIT, YMMS_AT_WIDTH
cmovae OUTPUT_LIMIT, YMMS_AT_WIDTH

// If there's already some output in the buffer, reduce the amount
// of additional output produced accordingly (whilst ensuring that
// a multiple of 512 bytes of output is produced).
//
// This would be buggy if the YMMS_AT_WIDTH limit were hit at the
// same time, but that never occurs as it would require two width
// changes within one pipeful of each other, and 9000000 lines of
// FizzBuzz is much more than a pipeful in size.
mov %rax, OUTPUT_PTR
and %eax, ((2 &lt;&lt; 20) - 1) &amp; -512
shr %eax, 5
sub OUTPUT_LIMIT, %rax

// The amount of output to produce is available now, and won't be
// later, so subtract it from the amount of output that needs to
// be produced now.
sub YMMS_AT_WIDTH, OUTPUT_LIMIT

// Return OUTPUT_LIMIT back to being a pointer, not an amount.
shl OUTPUT_LIMIT, 5
add OUTPUT_LIMIT, OUTPUT_PTR

prepare_main_loop_invariants:

// To save one instruction in the bytecode interpreter (which is very
// valuable, as it runs every second CPU cycle), LINENO_MID_TEMP is
// used to store a reformatted version of LINENO_MID, in which each
// byte is translated from high-decimal to ASCII, and the bytecode
// command that would access that byte is added to the result (e.g.
// the thousands digit for the hundreds-digits-odd version has 10
// added to convert from high-decimal to a pure number, '0' added to
// convert to ASCII, then 9 added because that's the bytecode command
// to access the thousands digit when the hundreds digit is odd, so
// the amount added is 10 + '0' + 9 = 57).
//
// LINENO_MID_TEMP is updated within the main loop, immediately after
// updating LINENO_MID, but because the bytecode interpreter reads
// from it it needs a valid value at the start of the loop.
.section .rodata
biascii_offset:
.byte 58, 59, 60, 61, 62, 63, 64, 65
.byte 66, 67, 68, 69, 70, 71, 72, 73
.byte 58, 59, 60, 61, 62, 63, 64, 65
.byte 66, 67, 68, 69, 70, 71, 72, 73
.text
vpaddb LINENO_MID_TEMP, BIASCII_OFFSET, LINENO_MID

// To save an instruction, precalculate minus the length of the
// bytecode. (Although the value of this is determined entirely by
// LINENO_WIDTH, the register it's stored in gets clobbered by
// system calls and thus needs to be recalculated each time.)
mov BYTECODE_NEG_LEN, BYTECODE_START
sub BYTECODE_NEG_LEN, BYTECODE_END


// The main loop

// The bytecode interpreter consists of four instructions:
// 1. Load the bytecode from memory into %ymm2;
// 2. Use it as a shuffle mask to shuffle LINENO_MID_TEMP;
// 3. Subtract the bytecode from the shuffle result;
// 4. Output the result of the subtraction.
//
// To see why this works, consider two cases. If the bytecode wants to
// output a literal character, then the shuffle will produce 0 for
// that byte (in AVX2, a shuffle with a a negative index produces an
// output of 0), and subtracting the bytecode from 0 then produces the
// character (because the bytecode encoded minus the character). If
// the bytecode instead wants to output a digit, then the shuffle will
// fetch the relevant digit from LINENO_MID_TEMP (which is the desired
// ASCII character plus the bytecode instruction that produces it),
// and subtract the bytecode instruction to just produce the character
// on its own.
//
// This produces an exactly correct line number as long as the line
// number approximation is within 100 of the true value: it will be
// correct as long as the relevant part of LINENO_MID is correct, and
// the worst case is for LINENO_MID to be storing, say, 200 and 300
// (the representation of 250) when the true line number is 400. The
// value in LINENO_MID specifically can be up to 50 away from the
// value of the line number as recorded by LINENO_MID and LINENO_LOW
// together, so as long as the line number registers are within 100,
// LINENO_MID will be within 150 (which is what is required).
//
// This doesn't update the bytecode instruction pointer or the pointer
// into the output buffer; those are updated once every 512 bytes (and
// to &quot;advance the instruction pointer&quot; the rest of the time, the main
// loop is unrolled, using hardcoded offsets with the pointer updates
// baked in).
//
// The bytecode instruction pointer itself is read from %rdx, not
// BYTECODE_IP, so that mid-loop arithmetic on BYTECODE_IP won't cause
// the interpreter to break.
//
// It's important to note one potential performance issue with this
// code: the read of the bytecode from memory is not only misalignable
// (`vmovdqu`); it splits a cache line 3/8 of the time. This causes L1
// split-load penalties on the 3/8 cycles where it occurs. I am not
// sure whether this actually reduces the program's performance in
// practice, or whether the split loads can be absorbed while waiting
// for writes to go through to the L2 cache. However, even if it does
// have a genuine performance cost, it seems like the least costly way
// to read the bytecode; structuring the bytecode to avoid split loads
// makes it take up substantially more memory, and the less cache that
// is used for the bytecode, the more that can be used for the output
// buffers. (In particular, increasing the bytecode to 2400 lines so
// that it's available at all four of the alignments required of it
// does not gain, because it then becomes so large that the processor
// struggles to keep it in L1 cache - it only just fits, and there
// isn't any way for it to know which parts of the cache are meant to
// stay in L1 and which are meant to leave to L2, so there's a large
// slowdown when it guesses wrong.)
#define INTERPRET_BYTECODE(bc_offset, buf_offset) \
  vmovdqu %ymm2, [%rdx + bc_offset]; \
  vpshufb %ymm0, LINENO_MID_TEMP, %ymm2; \
  vpsubb %ymm0, %ymm0, %ymm2; \
  vmovdqa [OUTPUT_PTR + buf_offset], %ymm0

// The main loop itself consists of sixteen uses of the bytecode
// interpreter, interleaved (to give the reorder buffer maximum
// flexibility) with all the other logic needed in the main loop.
// (Most modern processors can handle 4-6 instructions per clock cycle
// as long as they don't step on each others' toes; thus this loop's
// performance will be limited by the throughput of the L2 cache, with
// all the other work (bytecode interpretation, instruction decoding,
// miscellaneous other instructions, etc.) fitting into the gaps while
// the processor is waiting for the L2 cache to do its work.)

.p2align 5
main_loop:
// %rdx caches BYTECODE_IP's value at the start of the loop
mov %rdx, BYTECODE_IP
INTERPRET_BYTECODE(0, 0)

// %ymm1 caches LINENO_LOW's value at the start of the loop
vmovdqa %ymm1, LINENO_LOW
INTERPRET_BYTECODE(32, 32)

// Add LINENO_LOW_INCR to LINENO_LOW, checking for carry; it carried
// if the sign bit changed from 0 to 1. (vpandn is unintuitive; this
// is ~%ymm1 &amp; LINENO_LOW, not %ymm1 &amp; ~LINENO_LOW like the name
// suggests.)
vpaddq LINENO_LOW, LINENO_LOW_INCR, LINENO_LOW
INTERPRET_BYTECODE(64, 64)

vpandn %ymm3, %ymm1, LINENO_LOW
INTERPRET_BYTECODE(96, 96)

vpsrlq %ymm3, %ymm3, 63
INTERPRET_BYTECODE(128, 128)

// Add the carry to LINENO_MID (doubling it; LINENO_MID counts in
// units of 100 but a LINENO_LOW carry means 200).
vpaddb %ymm3, %ymm3, %ymm3
INTERPRET_BYTECODE(160, 160)

vpaddq LINENO_MID, LINENO_MID, %ymm3
INTERPRET_BYTECODE(192, 192)

vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID
INTERPRET_BYTECODE(224, 224)

// Update LINENO_MID_TEMP with the new value from LINENO_MID; this is
// the point at which the new value takes effect. This is done at the
// exact midpoint of the loop, in order to reduce the errors from
// updating once every 512 bytes as far as possible.
vpaddb LINENO_MID_TEMP, BIASCII_OFFSET, LINENO_MID
INTERPRET_BYTECODE(256, 256)

// Update the output and bytecode instruction pointers. The change to
// the output pointer kicks in immediately, but is cancelled out via
// the use of a negative offset until the end of the loop.
add OUTPUT_PTR, 512
INTERPRET_BYTECODE(288, -224)

add BYTECODE_IP, 512
INTERPRET_BYTECODE(320, -192)

// The change to the bytecode instruction pointer doesn't kick in
// immediately, because it might need to wrap back to the start (this
// can be done by adding BYTECODE_NEG_LEN to it); this is why the
// interpreter has a cached copy of it in %rdx.
lea %rax, [BYTECODE_IP + BYTECODE_NEG_LEN]
INTERPRET_BYTECODE(352, -160)

INTERPRET_BYTECODE(384, -128)
// Some modern processors can optimise `cmp` better if it appears
// immediately before the command that uses the comparison result, so
// a couple of commands have been moved slightly to put the `cmp` next
// to the use of its result. With modern out-of-order processors,
// there is only a marginal advantage to manually interleaving the
// instructions being used, and the `cmp` advantage outweighs that.
cmp BYTECODE_IP, BYTECODE_END

cmovae BYTECODE_IP, %rax
INTERPRET_BYTECODE(416, -96)

INTERPRET_BYTECODE(448, -64)

INTERPRET_BYTECODE(480, -32)
cmp OUTPUT_PTR, OUTPUT_LIMIT
jb main_loop

after_main_loop:
// There are two reasons the main loop might terminate: either there's
// a pipeful of output, or the line number has increased in width
// (forcing the generaion of new bytecode to put more digits in the
// numbers being printed). In the latter case, a) the output may have
// overrun slightly, and OUTPUT_PTR needs to be moved back to
// OUTPUT_LIMIT:
mov OUTPUT_PTR, OUTPUT_LIMIT
// and b) there may be less than a pipeful of output, in which case it
// wouldn't be safe to output it and the swap_buffers call needs to be
// skipped. Calculate the pipe size into %rax, the amount of output
// into %rdx (swap_buffers needs it there anyway), and compare.
lea %rax, [%rip + iovec_base]
sub %rax, BYTECODE_START
neg %eax
mov %rdx, OUTPUT_PTR
and %edx, (2 &lt;&lt; 20) - 1
cmp %edx, %eax
jb 1f
call swap_buffers

// If all the lines at this width have been exhausted, move to the
// next width.
1: test YMMS_AT_WIDTH, YMMS_AT_WIDTH
jnz check_lineno_top_carry

cmp LINENO_WIDTHe, 18  // third phase handles at most 18 digits
je fourth_phase

inc LINENO_WIDTHe
vpcmpeqb %ymm0, %ymm0, %ymm0
vpsubb ENDIAN_SHUFFLE, ENDIAN_SHUFFLE, %ymm0

lea GROUPS_OF_15, [GROUPS_OF_15 + GROUPS_OF_15 * 4]
add GROUPS_OF_15, GROUPS_OF_15

add BYTECODE_END, 320

jmp third_phase_per_width_init

// So far, the code has kept LINENO_MID and LINENO_LOW updated, but
// not LINENO_TOP. Because 10 billion lines of FizzBuzz don't normally
// have a length that's divisible by 512 (and indeed, vary in size a
// little because 10 billion isn't divisible by 15), it's possible for
// the 10-billions and higher digits to need to change in the middle
// of a main loop iteration - indeed, even in the middle of a single
// CPU instruction!
//
// It turns out that when discussing the line number registers above,
// I lied a little about the format. The bottom seven bytes of
// LINENO_MID do indeed represent the hundreds to hundred millions
// digits. However, the eighth changes in meaning over the course of
// the program. It does indeed represent the billions digit most of
// the time; but when the line number is getting close to a multiple
// of 10 billion, the billions and hundred-millions digits will always
// be the same as each other (either both 9s or both 0s). When this
// happens, the format changes: the hundred-millions digit of
// LINENO_MID represents *both* the hundred-millions and billions
// digits of the line number, and the top byte then represents the
// ten-billions digit. Because incrementing a number causes a row of
// consecutive 9s to either stay untouched, or all roll over to 0s at
// once, this effectively lets us do maths on more than 8 digits,
// meaning that the normal arithmetic code within the main loop can
// handle the ten-billions digit in addition to the digits below.
//
// Of course, the number printing code also needs to handle the new
// representation, but the number printing is done by a bytecode
// program, which can be made to output some of the digits being
// printed multiple times by repeating &quot;print digit from LINENO_MID&quot;
// commands within it. Those commands are generated from COUNTER_TOP
// anyway, so the program just changes the constant portion of
// COUNTER_TOP (and moves print-digit commands into the top half) in
// order to produce the appropriate bytecode changes.
//
// A similar method is used to handle carries in the hundred-billions,
// trillions, etc. digits.
//
// Incidentally, did you notice the apparent off-by-one in the
// initialisation of LINENO_MID within third_phase_per_width_init? It
// causes the &quot;billions&quot; digit to be initialised to 1 (not 0) when the
// line number width is 11 or higher. That's because the alternate
// representation will be in use during a line number width change (as
// higher powers of 10 are close to multiples of 10 billion), so the
// digit that's represented by that byte of LINENO_MID genuinely is a
// 1 rather than a 0.
check_lineno_top_carry:

// The condition to change line number format is:
// a) The line number is in normal format, and the hundred-millions
//    and billions digits are both 9; or
// b) The line number is in alternate format, and the hundred-millions
//    digit is 0.
// To avoid branchy code in the common case (when no format change is
// needed), REGEN_TRIGGER is used to store the specific values of the
// hundred-millions and billions digits that mean a change is needed,
// formatted as two repeats of billions, hundred-millions, 9, 9 in
// high-decimal (thus, when using normal format, REGEN_TRIGGER is
// high-decimal 99999999, i.e. -1 when interpreted as binary). The 9s
// are because vpshufd doesn't have very good resolution: the millions
// and ten-millions digits get read too, but can simply just be masked
// out. The two repeats are to ensure that both halves of LINENO_MID
// (the even-hundreds-digit and odd-hundreds-digit halves) have the
// correct value while changing (changing the format while half the
// register still ended ...98999999 would produce incorrect output).
vpshufd %xmm0, LINENO_MIDx, 0xED
vpextrq %rax, %xmm0, 0
mov %rdx, 0x0000ffff0000ffff
or %rax, %rdx
cmp %rax, REGEN_TRIGGER
jne calculate_main_loop_iterations

cmp REGEN_TRIGGER, -1
jne switch_to_normal_representation


switch_to_alternate_representation:
// Count the number of 9s at the end of LINENO_TOP. To fix an edge
// case, the top bit of LINENO_TOP is interpreted as a 0, preventing
// a 9 being recognised there (this causes 10**18-1 to increment to
// 10**17 rather than 10**18, but the program immediately exits
// before this can become a problem).
vpextrq %rdx, LINENO_TOPx, 1
mov SPILL, %rdx
shl %rdx, 1
shr %rdx, 1
not %rdx
bsf %rcx, %rdx
and %rcx, -8

// Change the format of LINENO_TOP so that the digit above the
// consecutive 9s becomes a reference to the top byte of LINENO_MID,
// and the 9s themselves references to the hundred-millions digit.
// This is done via a lookup table that specifies how to move the
// bytes around.
.section .rodata
alternate_representation_lookup_table:
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 7, 9, 10, 11, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 7, 9, 10, 11, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 7, 10, 11, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 7, 10, 11, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 7, 11, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 7, 11, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 7, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 7, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 7, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 7, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 7, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 7, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 7, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 7, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 6, 7
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 6, 7
.text

lea %rax, [%rip + alternate_representation_lookup_table]
vpshufb LINENO_TOP, LINENO_TOP, [%rax + 4 * %rcx]

// The top byte of LINENO_MID also needs the appropriate digit of
// LINENO_TOP placed there.
mov %rdx, SPILL
shr %rdx, %cl
vpinsrb LINENO_MIDx, LINENO_MIDx, %edx, 7
vpinsrb LINENO_MIDx, LINENO_MIDx, %edx, 15
vpermq LINENO_MID, LINENO_MID, 0x44

// Finally, REGEN_TRIGGER needs to store the pattern of digits that
// will prompt a shift back to the normal representation (the hundred-
// millions digit must be 0, and the value of the billions digit will
// be predictable).
inc %edx
shl %edx, 24
or %edx, 0xF6FFFF
mov REGEN_TRIGGERe, %edx
shl %rdx, 32
or REGEN_TRIGGER, %rdx
jmp generate_bytecode


switch_to_normal_representation:
// Switching back is fairly easy: LINENO_TOP can almost be converted
// back into its usual format by running the bytecode program stored
// there to remove any unusual references into LINENO_MID, then
// restoring the usual references manually. Running the program will
// unfortunately convert high-decimal to ASCII (or in this case zeroes
// because there's no need to do the subtraction), but that can be
// worked around by taking the bytewise maximum of the converted and
// original LINENO_TOP values (high-decimal is higher than bytecode
// references and much higher than zero).
vpsubb %ymm2, BASCII_OFFSET, LINENO_TOP
vpshufb %ymm0, LINENO_MID, %ymm2
vpmaxub LINENO_TOP, LINENO_TOP, %ymm0

// Manually fix the constant parts of lineno_top to contain their
// usual constant values
.section .rodata
lineno_top_max:
.byte 198, 197, 196, 195, 194, 193, 192, 191
.byte 255, 255, 255, 255, 255, 255, 255, 255
.byte 190, 189, 188, 187, 186, 185, 184, 183
.byte 255, 255, 255, 255, 255, 255, 255, 255
.text
vpminub LINENO_TOP, LINENO_TOP_MAX, LINENO_TOP

// The billions digit of LINENO_MID needs to be set back to 0 (which
// is its true value at this point: the same as the hundred-thousands
// digit, which is also 0).
vpsllq LINENO_MID, LINENO_MID, 8
vpsrlq LINENO_MID, LINENO_MID, 8
vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID

mov REGEN_TRIGGER, -1

jmp generate_bytecode


///// Fourth phase
//
// Ending at 999999999999999999 lines would be a little unsatisfying,
// so here's a routine to write the quintillionth line and exit.
//
// It's a &quot;Buzz&quot;, which we can steal from the first phase's constant.

fourth_phase:

mov ARG1e, 1
lea ARG2, [%rip + fizzbuzz_intro + 11]
mov ARG3, 5
mov SYSCALL_NUMBER, __NR_write
syscall
call exit_on_error
xor ARG1e, ARG1e
jmp exit


///// Error handling code
//
// This doesn't run in a normal execution of the program, and isn't
// particularly optimised; I didn't comment it much because it isn't
// very interesting and also is fairly self-explanatory.

write_stderr:
mov ARG1e, 2
mov SYSCALL_NUMBER, __NR_write
syscall
ret

inefficiently_write_as_hex:
push %rax
push %rcx
shr %rax, %cl
and %rax, 0xF
.section .rodata
hexdigits: .ascii &quot;0123456789ABCDEF&quot;
.text
lea %rcx, [%rip + hexdigits]
movzx %rax, byte ptr [%rcx + %rax]
mov [%rip + error_write_buffer], %al
lea ARG2, [%rip + error_write_buffer]
mov ARG3e, 1
call write_stderr
pop %rcx
pop %rax
sub %ecx, 4
jns inefficiently_write_as_hex
ret

exit_on_error:
test SYSCALL_RETURN, SYSCALL_RETURN
js 1f
ret

.section .rodata
error_message_part_1: .ascii &quot;Encountered OS error 0x&quot;
error_message_part_2: .ascii &quot; at RIP 0x&quot;
error_message_part_3: .ascii &quot;, exiting program.\n&quot;
.text

1: push SYSCALL_RETURN
lea ARG2, [%rip + error_message_part_1]
mov ARG3e, 23
call write_stderr
pop SYSCALL_RETURN
neg SYSCALL_RETURN
mov %rcx, 8
call inefficiently_write_as_hex
lea ARG2, [%rip + error_message_part_2]
mov ARG3e, 10
call write_stderr
pop %rax  // find the caller's %rip from the stack
sub %rax, 5  // `call exit_on_error` compiles to 5 bytes
mov %rcx, 60
call inefficiently_write_as_hex
lea ARG2, [%rip + error_message_part_3]
mov ARG3e, 19
call write_stderr
mov ARG1e, 74
// fall through

exit:
mov SYSCALL_NUMBER, __NR_exit_group
syscall
ud2

.section .rodata
cpuid_error_message:
.ascii &quot;Error: your CPUID command does not support command &quot;
.ascii &quot;0x80000006 (AMD-style L2 cache information).\n&quot;
.text
bad_cpuid_error:
lea ARG2, [%rip + cpuid_error_message]
mov ARG3e, 96
call write_stderr
mov ARG1e, 59
jmp exit

.section .rodata
pipe_error_message:
.ascii &quot;This program can only output to a pipe &quot;
.ascii &quot;(try piping into `cat`?)\n&quot;
.text
pipe_error:
lea ARG2, [%rip + pipe_error_message]
mov ARG3e, 64
call write_stderr
mov ARG1e, 73
jmp exit

.section .rodata
pipe_perm_error_message_part_1:
.ascii &quot;Cannot allocate a sufficiently large kernel buffer.\n&quot;
.ascii &quot;Try setting /proc/sys/fs/pipe-max-size to 0x&quot;
pipe_perm_error_message_part_2: .ascii &quot;.\n&quot;
.text
pipe_perm_error:
lea ARG2, [%rip + pipe_perm_error_message_part_1]
mov ARG3e, 96
call write_stderr
mov %rax, PIPE_SIZE
mov %ecx, 28
call inefficiently_write_as_hex
lea ARG2, [%rip + pipe_perm_error_message_part_2]
mov ARG3e, 2
call write_stderr
mov ARG1e, 77
jmp exit

.section .rodata
pipe_size_error_message_part_1:
.ascii &quot;Failed to resize the kernel pipe buffer.\n&quot;
.ascii &quot;Requested size: 0x&quot;
pipe_size_error_message_part_2: .ascii &quot;\nActual size: 0x&quot;
pipe_size_error_message_part_3:
.ascii &quot;\n(If the buffer is too large, this may cause errors;&quot;
.ascii &quot;\nthe program could run too far ahead and overwrite&quot;
.ascii &quot;\nmemory before it had been read from.)\n&quot;
.text
pipe_size_mismatch_error:
push SYSCALL_RETURN
lea ARG2, [%rip + pipe_size_error_message_part_1]
mov ARG3e, 59
call write_stderr
mov %rax, PIPE_SIZE
mov %ecx, 28
call inefficiently_write_as_hex
lea ARG2, [%rip + pipe_size_error_message_part_2]
mov ARG3e, 16
call write_stderr
pop %rax
mov %ecx, 28
call inefficiently_write_as_hex
lea ARG2, [%rip + pipe_size_error_message_part_3]
mov ARG3e, 141
call write_stderr
mov ARG1e, 73
jmp exit
</code></pre>
</div>
<div id="pu21" class="pu"><h1>C99 (gcc)</h1>
<pre class="lang-c prettyprint-override"><code>#include &lt;unistd.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdbool.h&gt;

#define SIZE (1 &lt;&lt; 16)

int main(void) {
  
  char buffer[SIZE] = {};

  char *buf = buffer;
  unsigned long long int prev_n_3=0; 
  unsigned long long int prev_n_5=0; 

  for (unsigned long long int n=3; 3; n++) {          
    if ((buf - buffer) &gt;= (SIZE-21)) {
      write(1, buffer, buf-(buffer+1));
      buf = buffer;
    }


    if (n-prev_n_3==3) {
      buf[0] = 'F';
      buf[1] = 'i';
      buf[2] = 'z';
      buf[3] = 'z';
      buf += 4; 
      prev_n_3=n;
    }
    if (n-prev_n_5==5) {
      buf[0] = 'B';
      buf[1] = 'u';
      buf[2] ='z';
      buf[3] = 'z';
      buf += 4;
      prev_n_5=n;

    }
    

    if (!(prev_n_5==n)  &amp;&amp; !(prev_n_3==n)) {
      buf += sprintf(buf,&quot;%llu&quot;,n);
    }

    *buf='\n';
    buf++;
  }
  return 0;
}
</code></pre>
<p>About 140 MiBs by my measurement. I measured using <code>gcc -flto -Ofast</code>, on a 2015 MacBook Air running Big Sur. I deleted my previous answer a while ago. This is a partial rewrite.</p>
</div>
<div id="pu22" class="pu"><p><strong>Python3</strong></p>
<p>I ported <a href="https://codegolf.stackexchange.com/a/215231">Neil</a>+<a href="https://codegolf.stackexchange.com/a/215236">Kamila</a> answers to python3</p>
<pre class="lang-python prettyprint-override"><code>from os import write

buf = bytearray(256)
out = bytearray(65536 + 4096)

init = b&quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\n&quot;

out[:len(init)] = init

fmt = &quot;Buzz\n{}1\nFizz\n{}3\n{}4\nFizzBuzz\n{}6\n{}7\nFizz\n{}9\nBuzz\nFizz\n{}2\n{}3\nFizz\nBuzz\n{}6\nFizz\n{}8\n{}9\nFizzBuzz\n{}1\n{}2\nFizz\n{}4\nBuzz\nFizz\n{}7\n{}8\nFizz\n&quot;

t = 30
i = 1
j = 1

for l in range(1, 20):
    txt = fmt.format(i, i, i, i, i, i, i + 1, i + 1, i + 1, i + 1, i + 1, i + 2, i + 2, i + 2, i + 2, i + 2).encode()
    buf[:len(txt)] = txt

    i *= 10
    while j &lt; i:
        out[t:t+len(txt)] = buf[:len(txt)]
        t += len(txt)
        if t &gt;= 65536:
            u = write(1, out[:65536])
            while u &lt; 65536:
                u += write(1, out[u:65536])

            t -= 65536
            out[:t] = out[65536:65536+t]

        q = 0
        for z in (4, 7, 2, 11, 2, 7, 12, 2, 12, 7, 2, 11, 2, 7, 12, 2):
            q += z + l
            p = q
            if buf[p] &lt; 55:
                buf[p] += 3
            else:
                buf[p] -= 7
                p -= 1
                while buf[p] == 57:
                    buf[p] = 48
                    p -= 1

                buf[p] += 1

        j += 3
</code></pre>
<p>On my laptop with i5-8300H <code>python3 fizzbuzz.py | pv &gt; /dev/null</code> results in throughput of 48 MiB/s on average.
While running the same code with <code>pypy3</code> gives me up to 820 MiB/s.</p>
</div>
<div id="pu23" class="pu"><p>I tweaked Neil's <a href="https://codegolf.stackexchange.com/a/215231">code</a> a bit (so most credit goes to him) and managed to squeeze some more performance out of it; I also prepared it for unrolling more loops but ultimately I gave up (that's why the code is unreadable gobbledygook).</p>
<pre class="lang-c prettyprint-override"><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;

#define f(Z) {char*p=q+=Z+l;if(*p&lt;'7')*p+=3;else{*p---=7;while(*p=='9')*p--='0';++*p;}}
#define v(N) {while(j&lt;i){memcpy(t,buf,N);t+=n;if(t&gt;=&amp;out[65536]){char*u=out; \
           do{int w=write(1,u,&amp;out[65536]-u);if(w&gt;0)u+=w;}while(u&lt;&amp;out[65536 \
           ]);memcpy(out,out+65536,t-&amp;out[65536]);t-=65536;}char*q=buf;f(4); \
           f(7);f(2);f(11);f(2);f(7);f(12);f(2);f(12);f(7);f(2);f(11);f(2);f \
           (7);f(12);f(2);j+=3;}}
char buf[256];
char out[65536 + 4096] = &quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\n&quot;;
int main(void) {
  char *t = out + 30;
  unsigned long long i = 1, j = 1;
  for (int l = 1; l &lt; 20; l++) {
    int n=sprintf(buf, &quot;Buzz\n%llu1\nFizz\n%llu3\n%llu4\nFizzBuzz\n%llu6\n%llu7\nFizz\n%llu9\nBuzz\nFizz\n%llu2\n%llu3\nFizz\nBuzz\n%llu6\nFizz\n%llu8\n%llu9\nFizzBuzz\n%llu1\n%llu2\nFizz\n%llu4\nBuzz\nFizz\n%llu7\n%llu8\nFizz\n&quot;, i, i, i, i, i, i, i + 1, i + 1, i + 1, i + 1, i + 1, i + 2, i + 2, i + 2, i + 2, i + 2);
    i*=10;
    v(n);
  }
  return 0;
}
</code></pre>
<p>On my PC, Neil's submission is ~5% slower. I also tried it on friend's Intel box and the tweaked version is faster.</p>
</div>
<div id="pu24" class="pu"><h2>Python</h2>
<h2>with numba (original)</h2>
<pre><code>import numpy as np
from numba import njit

@njit
def get_arr(i,j):
    a = np.arange(i,j)
    return a[np.bitwise_and(a%5 != 0, a%3 != 0)]

def fizzbuzzv3(chunk,length):
    string = &quot;&quot;
    for i in range(1,chunk+1):
        if i%15 == 0:
            string += &quot;FizzBuzz&quot;
        elif i%3 == 0:
            string += &quot;Fizz&quot;
        elif i%5 == 0:
            string += &quot;Buzz&quot;
        else:
            string += &quot;{}&quot;
        string += &quot;\n&quot;
    string = string[:-2]
    for i in range(1,length,chunk):
        print(string.format(*get_arr(i,i+chunk)))
        
fizzbuzzv3(6000,int(1e100))
</code></pre>
<p>Tested on Google Colaboratory with int(1e9) instead of int(1e100) for practical reasons and got 38.3MiB/s.</p>
<pre><code>!python3 test.py | pv &gt; /dev/null
7.33GiB 0:03:16 [38.3MiB/s] [    &lt;=&gt;                                           ]
</code></pre>
<h2>Faster version with os.write, % string formatting and removed numba</h2>
<pre><code>import numpy as np
import os
def fizzbuzz(chunk,length):
    string_arr = np.empty(chunk).astype('&lt;U8')
    string_arr[:] = '%d'
    string_arr[::3] = 'Fizz'
    string_arr[::5] = 'Buzz'
    string_arr[::15] = 'FizzBuzz'
    string = '\n'.join(string_arr) + '\n'
    offset_arr = np.arange(chunk)
    offset_arr = (offset_arr%5 != 0)&amp;(offset_arr%3 != 0)
    offset_arr = np.where(offset_arr)[0]
    for i in range(0,length,chunk):
        to_output = string%tuple(offset_arr.tolist())
        os.write(1,to_output.encode())
        offset_arr += chunk
fizzbuzz(8100,int(1e100))
</code></pre>
<p>Google Colaboratory with int(1e9) - 125MiB/s</p>
<pre><code>!python3 test.py | pv &gt; /dev/null
7.33GiB 0:00:59 [ 125MiB/s] [                                     &lt;=&gt;          ]
</code></pre>
<h2>Pure python, no imports</h2>
<pre><code>def fizzbuzz(chunk,length):
    fb_string = &quot;&quot;
    for i in range(0,chunk):
        if i%15 == 0: fb_string += &quot;FizzBuzz&quot;
        elif i%3 == 0: fb_string += &quot;Fizz&quot;
        elif i%5 == 0: fb_string += &quot;Buzz&quot;
        else: fb_string += &quot;%i&quot;
        fb_string += &quot;\n&quot;
    offset_tuple = tuple(i for i in range(chunk) if i%3 != 0 and i%5 != 0)
    for i in range(0,length,chunk):
        print(fb_string % offset_tuple, end='')
        offset_tuple = tuple(i + chunk for i in offset_tuple)
fizzbuzz(6000,int(1e100))
</code></pre>
<p>Google Colaboratory with int(1e9) - 87.5MiB/s</p>
<pre><code>!python3 test.py | pv &gt; /dev/null
7.33GiB 0:01:25 [87.5MiB/s] [             &lt;=&gt;                                  ]
</code></pre>
<h2>Multiprocessing + numpy Version</h2>
<p>requires python 3.9 and uses shared memory objects to get output from return_string() on as many cores as possible.</p>
<pre><code>import numpy as np
from os import write
from multiprocessing import shared_memory
from multiprocessing import Pool

def return_string(stringmemory_name,arraymemory_name,offset_arr_shape,offset):
    #recover string from shared bytes
    stringmemory = shared_memory.SharedMemory(name=stringmemory_name)
    fb_string = bytes(stringmemory.buf).decode()
    stringmemory.close()

    #recover numpy array from shared bytes
    arraymemory = shared_memory.SharedMemory(name=arraymemory_name)
    offset_arr = np.ndarray(offset_arr_shape, dtype=np.int64, buffer=arraymemory.buf) + offset
    arraymemory.close()

    #Get output
    to_output = fb_string % tuple(offset_arr.tolist())
    
    #Return encoded
    return to_output.encode()

def fizzbuzz(chunk,length,number_processes):

    #Make the string. Uses numpy arrays because it's easy
    string_arr = np.empty(chunk).astype('&lt;U8')
    string_arr[:] = '%d'
    string_arr[::3] = 'Fizz'
    string_arr[::5] = 'Buzz'
    string_arr[::15] = 'FizzBuzz'
    fb_string = '\n'.join(string_arr.tolist()) + '\n'

    #Convert string to bytes and put it into shared memory
    fb_string = fb_string.encode()
    stringmemory = shared_memory.SharedMemory(create=True, size=len(fb_string))
    stringmemory.buf[:len(fb_string)] = fb_string

    #Make the offset array
    offset_arr = np.arange(chunk)
    offset_arr = (offset_arr%5 != 0)&amp;(offset_arr%3 != 0)
    offset_arr = np.where(offset_arr)[0]

    #Put array into shared memory
    arraymemory = shared_memory.SharedMemory(create=True, size=offset_arr.nbytes)
    temp = np.ndarray(offset_arr.shape, dtype=offset_arr.dtype, buffer=arraymemory.buf)
    temp[:] = offset_arr[:]

    #Go over chunks
    with Pool(processes=number_processes) as pool:
        running_list = []
        for i in range(0,length,chunk):
            #Do not exceed number_processes
            if len(running_list) &gt;= number_processes:
                running_list[0].wait()
            #Call a new function
            async_instance = pool.apply_async(return_string, \
            (stringmemory.name,arraymemory.name,offset_arr.shape,i))
            running_list.append(async_instance)
            #output
            if running_list[0].ready():
                write(1,running_list[0].get())
                del running_list[0]

        while len(running_list) != 0:
            running_list[0].wait()
            if running_list[0].ready():
                write(1,running_list[0].get())
                del running_list[0]

    stringmemory.close()
    stringmemory.unlink()
    arraymemory.close()
    arraymemory.unlink()

fizzbuzz(750000,int(1e100),32)
</code></pre>
<p>Google collab with fizzbuzz(750000,int(1e9),8) was only 77.7 MiB/s but that only has 2 cores. On a 16C/32T cpu I think it should do much better.
If it isn't too much trouble, please try out different values for for the chunk size (first argument - 750000) and number of processes (last argument - 32)</p>
<pre><code>!python3 test.py | pv &gt; /dev/null
7.34GiB 0:01:36 [77.7MiB/s] [  &lt;=&gt;                                             ]
</code></pre>
<h2>Multicore, numpy and improvised locks</h2>
<pre><code>import numpy as np
from os import write
from multiprocessing import shared_memory
from multiprocessing import Pool

def return_string(stringmemory_name,arraymemory_name,offset_arr_shape,offset,process_id,lock_name):
    #recover string from shared bytes
    stringmemory = shared_memory.SharedMemory(name=stringmemory_name)
    fb_string = bytes(stringmemory.buf).decode()
    stringmemory.close()

    #recover numpy array from shared bytes
    arraymemory = shared_memory.SharedMemory(name=arraymemory_name)
    offset_arr = np.ndarray(offset_arr_shape, dtype=np.int64, buffer=arraymemory.buf) + offset
    arraymemory.close()

    #Get output
    to_output = fb_string % tuple(offset_arr.tolist())
    to_output = to_output.encode()

    #lock 
    lock = shared_memory.SharedMemory(name=lock_name)
    while lock.buf[0:] != process_id:
        pass
    lock.close()

    write(1,to_output)
    return int(process_id.decode()) + 1

def fizzbuzz(chunk,length,number_processes):

    #Make the string. Uses numpy arrays because it's easy
    string_arr = np.empty(chunk).astype('&lt;U8')
    string_arr[:] = '%d'
    string_arr[::3] = 'Fizz'
    string_arr[::5] = 'Buzz'
    string_arr[::15] = 'FizzBuzz'
    fb_string = '\n'.join(string_arr.tolist()) + '\n'

    #Convert string to bytes and put it into shared memory
    fb_string = fb_string.encode()
    stringmemory = shared_memory.SharedMemory(create=True, size=len(fb_string))
    stringmemory.buf[:len(fb_string)] = fb_string

    #Make the offset array
    offset_arr = np.arange(chunk)
    offset_arr = (offset_arr%5 != 0)&amp;(offset_arr%3 != 0)
    offset_arr = np.where(offset_arr)[0]

    #Put array into shared memory
    arraymemory = shared_memory.SharedMemory(create=True, size=offset_arr.nbytes)
    temp = np.ndarray(offset_arr.shape, dtype=offset_arr.dtype, buffer=arraymemory.buf)
    temp[:] = offset_arr[:]

    #Improvised Lock
    lock = shared_memory.SharedMemory(create=True, size=1)
    lock.buf[0:] = '0'.encode()

    #Go over chunks
    with Pool(processes=number_processes) as pool:
        running_list = []
        for i in range(0,length,chunk):
            #Do not exceed number_processes
            if len(running_list) &gt;= number_processes:
                running_list[0].wait()
            #Call a new function
            async_instance = pool.apply_async(return_string, \
            (stringmemory.name, arraymemory.name, offset_arr.shape, i, \
            str((i//chunk)%number_processes).encode(), lock.name))
            running_list.append(async_instance)
            #output
            if running_list[0].ready():
                lock.buf[0:] = str(running_list[0].get()%number_processes).encode()
                del running_list[0]
        #overflow
        while len(running_list) != 0:
            running_list[0].wait()
            if running_list[0].ready():
                lock.buf[0:] = str(running_list[0].get()%number_processes).encode()
                del running_list[0]

    stringmemory.close()
    stringmemory.unlink()
    arraymemory.close()
    arraymemory.unlink()
    lock.close()
    lock.unlink()

fizzbuzz(1500000,int(1e100),8)
</code></pre>
<p>On google collab (with int(1e9) as usual) this is 15% faster, which makes sense because it doesn't need to pickle the output and send it back to the main program. The improvised lock (single byte of data that contains the printing order) should allow it to print in the correct order despite being async. Also larger chunk size.</p>
<pre><code>!python3 fizzbuzz_multiprocessing_numpy_os.py | pv &gt; /dev/null
7.34GiB 0:01:14 [ 100MiB/s] [                        &lt;=&gt;                       ]
</code></pre>
</div>
<div id="pu25" class="pu"><h1>Trivial Rust</h1>
<p>This one is just plain Rust without any tricks (no <code>unsafe</code>, no <code>vmsplice()</code>, no assembly), just a light loop unrolling. <s>It manages to reach 6GiB/s on my laptop (XPS 15 i9)</s> (it's wrong, see in comments), I'm curious to know how much it does on the reference hardware.</p>
<p>Compile with <code>cargo build --release</code>, run with <code>./target/release/fizzbuzz | pv &gt;/dev/null</code></p>
<pre class="lang-rust prettyprint-override"><code>use std::error::Error;
use std::fmt::Write;
use std::io::Write as OtherWrite;

const LEN: usize = 1000000000;

fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {
    let stdout = std::io::stdout();
    let mut stdout = std::io::BufWriter::new(stdout.lock());
    let mut buffer = String::new();
    buffer.reserve(80);
    let mut n = 0usize;
    while n &lt; LEN {
        write!(
            &amp;mut buffer,
            r#&quot;{}
{}
Fizz
{}
Buzz
Fizz
{}
{}
Fizz
Buzz
{}
Fizz
{}
{}
FizzBuzz
&quot;#,
            n + 1,
            n + 2,
            n + 4,
            n + 7,
            n + 8,
            n + 11,
            n + 13,
            n + 14
        )?;
        stdout.write_all(buffer.as_bytes())?;
        n += 15;
        buffer.clear(); // forgot that ...
    }
    Ok(())
}
</code></pre>
</div>
<div id="pu26" class="pu"><p><strong>Java: On my 11th gen intel laptop</strong></p>
<ul>
<li>The OP's simple C version: 25 MiB/s</li>
<li>My simple Java version: 140 MiB/s</li>
<li>python neil+kamila: 8 MiB/s</li>
<li>python ksoua chunking: 4.33 MiB/s</li>
<li>Jan's C version: 1.0 GiB/s</li>
</ul>
<p>Sometimes simple is better!</p>
<p>To the guy that did a threaded C++ version: wow!</p>
<pre class="lang-java prettyprint-override"><code>public class FizzBuzz {

    public static void main(String[] args) {

        long maxBufLen=4096&lt;&lt;3;

        var sb=new StringBuilder((int)maxBufLen + 10);
        for (long i = 1; ; i+=1) {

            if ((i % 3 == 0) &amp;&amp; (i % 5 == 0)) {
                sb.append(&quot;FizzBuzz\n&quot;);
            } else if (i % 3 == 0) {
                sb.append(&quot;Fizz\n&quot;);
            } else if (i % 5 == 0) {
                sb.append(&quot;Buzz\n&quot;);
            } else {
                sb.append(i).append(&quot;\n&quot;);
            }
            
            if(sb.length()&gt;maxBufLen) {
                System.out.print(sb);
                sb.setLength(0);
            }
        }
        
    }

} 
</code></pre>
<p>Copied Ioan's threaded version (not the way I'd do it but it works...) and added some efficiencies:</p>
<p>750MiB/s same laptop</p>
<pre><code>
import java.io.FileDescriptor;
import java.io.FileOutputStream;
import java.nio.ByteBuffer;
import java.nio.CharBuffer;
import java.nio.channels.FileChannel;
import java.nio.charset.CharsetEncoder;
import java.nio.charset.StandardCharsets;
import java.util.LinkedList;
import java.util.Queue;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ForkJoinPool;
import java.util.function.Supplier;
import java.util.stream.IntStream;

public class FizzBuzzIoan {

    static final String NEWLINE = String.format(&quot;%n&quot;);
    static final CharsetEncoder encoder = StandardCharsets.US_ASCII.newEncoder();

    static void fizzBuzz(long src, StringBuilder destination) {
        
        if (src % 15 == 0) {
            destination.append(&quot;FizzBuzz&quot;+NEWLINE);
        } else if (src % 5 == 0) {
            destination.append(&quot;Fizz&quot;+NEWLINE);
        } else if (src % 3 == 0) {
            destination.append(&quot;Buzz&quot;+NEWLINE);
        } else {
            destination.append(src).append(NEWLINE);
        }

    }

    record Pair&lt;T1, T2&gt;(T1 item1, T2 item2) {
    }

    public static void main(String[] args) throws Exception {

        try (var fis= new FileOutputStream(FileDescriptor.out)) {
            var channel = fis.getChannel();
            doIt(channel);
        }
    }

    static void doIt(FileChannel channel) {

        var max=Math.max(ForkJoinPool.getCommonPoolParallelism(), 1);
        
        final Queue&lt;CompletableFuture&lt;Pair&lt;StringBuilder, ByteBuffer&gt;&gt;&gt; queue =
                new LinkedList&lt;&gt;(
                        IntStream.range(0, max).mapToObj(i -&gt;
                            CompletableFuture.completedFuture(
                                    new Pair&lt;&gt;(new StringBuilder(20 * 1024 * 1024), ByteBuffer.allocateDirect(41 * 1024 * 1024)))).toList()
                        );

        CompletableFuture&lt;?&gt; last = CompletableFuture.completedFuture(null);

        final Supplier&lt;Pair&lt;StringBuilder, ByteBuffer&gt;&gt; supplier = () -&gt; {
            try {
                return queue.poll().get();
            } catch (Exception ex) {
                ex.printStackTrace();
                System.exit(1);
                return null;
            }
        };


        var nr = 0L;
        var segment = 1_000_000L;
        

        while (true) {
            final var start = nr;
            final var end = nr + segment;


            final var finalLast = last;

            var cf = CompletableFuture.completedFuture(supplier.get())
                    .thenApplyAsync(p -&gt; {
                        var sb = p.item1();
                        var bb = p.item2();
                        
                        sb.setLength(0);
                        
                        for (long l = start; l &lt; end; l++) {
                            fizzBuzz(l, sb);
                        }
                        bb.clear();
                        
                        try {
                            var cb=CharBuffer.wrap(sb);
                            encoder.encode(cb, bb, true);

                        } catch(Exception ex) {
                            throw new RuntimeException(ex);
                        }
                        return p;
                        
                    })
                    .thenCombineAsync(finalLast, (p, v) -&gt; {
                        try {
                            channel.write(p.item2().flip());
                        } catch (Exception ex) {
                            ex.printStackTrace();
                            System.exit(1);
                        }
                        return p;
                    });

            queue.add(cf);
            last = cf;

            nr = end;


        }

    }

}

<span class="math-container">```</span>
</code></pre>
</div>
<div id="pu27" class="pu"><h2>Ruby</h2>
<pre class="lang-ruby prettyprint-override"><code># frozen_string_literal: true
FMT = &quot;%d\n%d\nFizz\n%d\nBuzz\nFizz\n%d\n%d\nFizz\nBuzz\n%d\nFizz\n%d\n%d\nFizzBuzz&quot;
(1..).each_slice(15) do |slice|
  puts format(FMT, slice[0], slice[1], slice[3], slice[6], slice[7], slice[10], slice[12], slice[13])
end
</code></pre>
<p>Doesn't seem to be as magical as system languages though. On MacBook Air 1,7 GHz Dual-Core Intel Core i7 8 GB 1600 MHz DDR3 (while watching a twitch stream)</p>
<p>I'm getting from <code>ruby fizzbuzz.rb | pv &gt; /dev/null</code>:</p>
<ul>
<li>[44.4MiB/s] for ruby 2.7.4 but seems fuctuating</li>
<li>[39.3MiB/s] for ruby 3.1-dev but seems to be more stable</li>
</ul>
</div>
<div id="pu28" class="pu"><h1><a href="http://julialang.org/" rel="nofollow noreferrer">Julia 1.7</a></h1>
<pre class="lang-julia prettyprint-override"><code>@inbounds function inc!(l::Vector{UInt8}, n, i = length(l)-1)
    if i &gt; 0
        l[i] += n
        if l[i] &gt; 0x39 # '9' 
            l[i] -= 0x0A # 10
            inc!(l, 0x01, i-1)
        end
    else
        pushfirst!(l, 0x31) # '1'
    end
    
    return nothing
end

function main(maxi = typemax(Int), N = 2^16)

    io = IOBuffer(; sizehint=N)
    a = UInt8['1', '\n']
    sizehint!(a, 100)

    for j in 1:N:maxi

        s = take!(io)
        write(stdout, s)
        l = ll = 0
        
        while ll+l+8 &lt; N
            l = 0
            l += write(io, a)
            inc!(a, 0x01)
            l += write(io, a)
            l += write(io, &quot;Fizz\n&quot;)
            inc!(a, 0x02)
            l += write(io, a)
            l += write(io, &quot;Buzz\nFizz\n&quot;)
            inc!(a, 0x03)
            l += write(io, a)
            inc!(a, 0x01)
            l += write(io, a)
            l += write(io, &quot;Fizz\nBuzz\n&quot;)
            inc!(a, 0x03)
            l += write(io, a)
            l += write(io, &quot;Fizz\n&quot;)
            inc!(a, 0x02)
            l += write(io, a)
            inc!(a, 0x01)
            l += write(io, a)
            l += write(io, &quot;FizzBuzz\n&quot;)
            inc!(a, 0x02)
            ll += l
        end
    end
end

main()
</code></pre>
<p>The buffer of size <code>N</code> is optimized for my machine. I get about <strong>350-400 MiB/s</strong> in WSL, it might be better on a real Linux machine (let's not talk about the performance in windows). I got slightly better results with julia 1.7 than with 1.6.</p>
<p><a href="https://tio.run/##xVRRT8IwEH7frzjwgTWMZJVEAZ1RHkx4wSd9AUwmdKxYWrJ1ETH@9nntYASIIUaMfeja@3p3332X2ywTPKTLPL/l8kVlcpJClMmx5koCl@OKKzqdJzbWKvl47End@vRAesAhAMHkVMeuIA1KHMDFI7TfgG8vZokBH0E9AFla8Ik14qtlsw1nUGvXSrB0aQQI@3cIU38HLQh5BqVIYpPYLCYn9sxEykrjIkvjiCepXns1KTE5aZFz42K3hOkskSCVjrmcOgZzSiHmIZfuPFyasvX7guHRRTGIB320nD/TC@IUEii89x66WRSxxL2ClK8YxtNBv2AaImxlHCAJD2pDWRtZYPOw4oYeVu2v40UqgRmWDbTT7xgCTllbariEr6zicrWV4S3hmrmpnqhMe5BuAWE6ZratolunmAuGaF3UW3AN/d2O7PgUFuxpkYgrD0Jy2KOw6BH5gd8eWr3nq9VQVr8Nfv6b4N3MBD@Wokn@re6C4Imo/am0p6z7WNX7xGwMcfgPwK8dYDu3OJ6XdUry/As" rel="nofollow noreferrer" title="Julia 1.0 – Try It Online">Try it online!</a></p>
</div>
<div id="pu29" class="pu"><p>Adding a bit upon ksousa's answer, you can make two tweaks while keeping readability:</p>
<ul>
<li><p>Use f-strings <strong>not .format()</strong> (because that'd add a function call) in the derailleur() function</p>
</li>
<li><p>Use os.write() instead of print(), because <strong>print() is slow</strong> (not that os.write is much faster, but it is faster)</p>
</li>
</ul>
<p>It ends up looking like this:</p>
<pre><code>from itertools import cycle, count
from os import write

def derailleur(counter, carousel):
    return f&quot;{carousel if carousel else counter}\n&quot;

def main():
    carousel = cycle([0, 0, &quot;Fizz&quot;, 0, &quot;Buzz&quot;, &quot;Fizz&quot;, 0, 0, &quot;Fizz&quot;, &quot;Buzz&quot;, 0, &quot;Fizz&quot;, 0, 0, &quot;FizzBuzz&quot;])
    counter = count(1)
    f = map(derailleur, counter, carousel)
    while True:
        write(1,  &quot;&quot;.join( [ next(f) for _ in range(8192) ] ).encode(&quot;utf-8&quot;) )

main()
</code></pre>
<p>I also played a bit with extending the range, but didn't get a significant speedup from that.</p>
<p>Under WSL2 on a 7200u w/ 16GiB of RAM I'm getting about a 10% to 20% better throughput, but the readings are super noisy (it starts at 15 MiB/s, jumps to 25, back to 20, etc...).</p>
<p>I don't have a Linux machine at hand to test this under a better environment, but I don't expect these changes to make a significant impact. After a few measurements, either using print() or os.write(), about 95% of the time is spent writing the output, and I haven't done much to address that with my changes.</p>
<p><strong>Edit:</strong> fixed a few typos and tested on PyPy3 under the same environment:</p>
<ul>
<li>Nearing 100 MiB/s using os.write()</li>
<li>Slightly faster 108 MiB/s using print()</li>
</ul>
<p><strong>Edit 2:</strong> <strong>moar PyPy!</strong></p>
<p>If we throw CPython performance out of the window, we can go with this pretty straightforward code:</p>
<pre><code>def fizzbuzz(x: int) -&gt; str:
    if x % 15 == 0: return &quot;FizzBuzz&quot;
    if x % 5  == 0: return &quot;Buzz&quot;
    if x % 3  == 0: return &quot;Fizz&quot;
    return f&quot;{x}&quot;

def main():
    c = 0
    while True:
        print( &quot;\n&quot;.join( fizzbuzz( c + i) for i in range(8192) ) )
        c += 8192

main()
</code></pre>
<p>And that is netting about 148 MiB/s on my PC, using PyPy. So about 6x faster than ksousas CPython version. Running it under python3 gives me 22-24 MiB/s, which is close to where I started. Again, I'm fairly certain on my environment writing to stdout dominates and there's very little to be done unless that bottleneck can be addressed.</p>
</div>
<div id="pu30" class="pu"><p>I wrote two versions in C# 10: one using &quot;vanilla&quot; language features and one based on Isaac's implementation.</p>
<p>In the optimized version, I exploited the fact that an exact length memcpy is not necessary if the buffer is large enough. It's limited to 10^16 iterations, and the first 10 results have a leading 0 (I just thought it would be worth posting it anyway).</p>
<p>Results:</p>
<pre><code>OS: Ubuntu 20.04.3 LTS
CPU: Intel(R) Xeon(R) Platinum 8171M CPU @ 2.60GHz
(note: this is a GitHub Actions worker)

Author              Lang             Avg. Speed
-----------------------------------------------
Paolo Bonzini       C               11.38 GiB/s
Isaac G.            C                1.90 GiB/s
Neil                C                1.83 GiB/s
Kamila Szewczyk     C                1.44 GiB/s
Daniel              C# (opt)      1006.00 MiB/s
Olivier Grégoire    Java           242.62 MiB/s
Daniel              C# (simpl)    125.125 MiB/s
</code></pre>
<h2>Simple version</h2>
<pre class="lang-cs prettyprint-override"><code>using System.Text;

var sb = new StringBuilder();
ulong c = 0;

while (true) {
    while (sb.Length &lt; 1024 * 1024 * 4) {
        sb.Append($&quot;{c + 1}\n{c + 2}\nFizz\n{c + 4}\nBuzz\nFizz\n{c + 7}\n{c + 8}\nFizz\nBuzz\n{c + 11}\nFizz\n{c + 13}\n{c + 14}\nFizzBuzz\n&quot;);
        c += 15;
    }
    Console.Out.Write(sb);
    sb.Clear();
}
</code></pre>
<h2>&quot;Optimized&quot; version</h2>
<pre class="lang-cs prettyprint-override"><code>using System.Runtime.CompilerServices;
using System.Runtime.Intrinsics;

using var stdout = Console.OpenStandardOutput();

var buf = new byte[1024 * 1024 * 4];
var counter = new Counter();

while (true) {
    int pos = 0;
    for (int i = 0; i &lt; 4096; i++) {
        pos = Fill30(buf, pos, ref counter);
    }
    stdout.Write(buf.AsSpan(0, pos));
}

int Fill30(byte[] buf, int pos, ref Counter ctr)
{
    var Fizz_ = 0x0A_7A_7A_69_46ul;
    var Fizz_Buzz_ = Vector128.Create(0x7A_75_42_0A_7A_7A_69_46ul, 0x0A_7A).AsByte();
    var Buzz_Fizz_ = Vector128.Create(0x7A_69_46_0A_7A_7A_75_42ul, 0x0A_7A).AsByte();
    var FizzBuzz__ = Vector128.Create(0x7A_7A_75_42_7A_7A_69_46, 0x0Aul).AsByte();

    //0..9
    var prefix = ctr.Get();
    int prefixLen = ctr.NumDigits;
    ctr.Inc();

    AddCtr(1);
    AddCtr(2);
    Add(Fizz_, 5);
    AddCtr(4);
    Add(Buzz_Fizz_, 10);
    AddCtr(7);
    AddCtr(8);
    Add(Fizz_Buzz_, 10);
    //10..19
    prefix = ctr.Get();
    prefixLen = ctr.NumDigits;
    ctr.Inc();
    
    AddCtr(1);
    Add(Fizz_, 5);
    AddCtr(3);
    AddCtr(4);
    Add(FizzBuzz__, 9);
    AddCtr(6);
    AddCtr(7);
    Add(Fizz_, 5);
    AddCtr(9);

    //20..29
    prefix = ctr.Get();
    prefixLen = ctr.NumDigits;
    ctr.Inc();
    
    Add(Buzz_Fizz_, 10);
    AddCtr(2);
    AddCtr(3);
    Add(Fizz_Buzz_, 10);
    AddCtr(6);
    Add(Fizz_, 5);
    AddCtr(8);
    AddCtr(9);
    Add(FizzBuzz__, 9);
    return pos;

    void Add&lt;T&gt;(T val, int len)
    {
        //ref byte ptr = ref Unsafe.Add(ref MemoryMarshal.GetArrayDataReference(buf), pos);
        //Unsafe.WriteUnaligned(ref ptr, val);
        Unsafe.WriteUnaligned(ref buf[pos], val);
        pos += len;
    }
    void AddCtr(int digit)
    {
        Add(prefix, prefixLen);
        Add((short)(0x0A_30 + digit), 2); // &quot;&lt;digit&gt;\n&quot; ascii in little endian
    }
}

unsafe struct Counter
{
    public const int MAX_DIGITS = 16;
    public fixed byte Digits[MAX_DIGITS * 2];
    public int NumDigits;

    public Counter()
    {
        Unsafe.InitBlock(ref Digits[0], (byte)'0', MAX_DIGITS);
        NumDigits = 1;
    }
    public void Inc()
    {
        int i = MAX_DIGITS - 1;
        for (; i &gt;= 0; i--) {
            if (Digits[i] != (byte)'9') {
                Digits[i]++;
                break;
            }
            Digits[i] = (byte)'0';
        }
        NumDigits = Math.Max(NumDigits, MAX_DIGITS - i);
    }
    public Vector128&lt;byte&gt; Get()
    {
        ref byte ptr = ref Digits[MAX_DIGITS - NumDigits];
        return Unsafe.ReadUnaligned&lt;Vector128&lt;byte&gt;&gt;(ref ptr);
    }
}
<span class="math-container">```</span>
</code></pre>
</div>
<div id="pu31" class="pu"><p>Just tried the following Kotlin, compiled to Kotlin Native:</p>
<pre><code>fun main(){
  for (i in 1..1_000_000_000){
    when {
        (i % 3 == 0 &amp;&amp; i % 5 == 0) -&gt; println(&quot;FizzBuzz&quot;)
        i % 3 == 0 -&gt; println(&quot;Fizz&quot;)
        i % 5 == 0 -&gt; println(&quot;Buzz&quot;)
        else -&gt; println(&quot;$i&quot;)
      }
  }
}
</code></pre>
<p><strong>2.91MiB/s</strong></p>
<p>Machine specs:</p>
<ul>
<li>Linux 5.14.18</li>
<li>i7-8550U</li>
<li>16GB Ram</li>
</ul>
</div>
<div id="pu32" class="pu"><h2>Python3</h2>
<p>Interesting problem. I see most answers used static languages, except the Powershell answer, so far untimed. As I was curious about how dynamic languages would fare in this task, I wrote a simple implementation in Python.</p>
<p>I ran it under GNU/Linux Mint 20.02 64-bit, using default Python3 (3.8.10) and pypy (7.3.1) in the repositories. Processor model in my machine: AMD Athlon(tm) X4 750 Quad Core.</p>
<h2>Initial version</h2>
<p>The initial version just keeps a carousel running in sync to a counter, where the carousel carries either False or the results different from the current count, in the proper positions. The derailleur function selects what is to be printed.</p>

<pre class="lang-python prettyprint-override"><code>from itertools import cycle, count

def derailleur(counter, carousel):
    if not carousel:
        return counter
    return carousel

def main():
    carousel = cycle([0,0,'Fizz',0,'Buzz','Fizz',0,0,'Fizz','Buzz',0,'Fizz',0,0,'FizzBuzz'])
    counter = count(1)
    f = map(print, map(derailleur, counter, carousel))
    while 1:
        next(f)

main()
</code></pre>
<p>In my machine it ran at about 14,2MiB/s under CPython, and got a modest boost up to 25,0MiB/s under pypy:</p>
<pre class="lang-python prettyprint-override"><code>user@Desktop:~$ python3 fizzbuzz.py | pv &gt; /dev/null
^C21MiB 0:00:30 [14,2MiB/s] [                            &lt;=&gt;                   ]
Traceback (most recent call last):
  File &quot;fizzbuzz.py&quot;, line 15, in &lt;module&gt;
    main()
  File &quot;fizzbuzz.py&quot;, line 13, in main
    next(f)
  File &quot;fizzbuzz.py&quot;, line 3, in derailleur
    def derailleur(counter, carousel):
KeyboardInterrupt
Exception ignored in: &lt;_io.TextIOWrapper name='&lt;stdout&gt;' mode='w' encoding='utf-8'&gt;
BrokenPipeError: [Errno 32] Broken pipe

user@Desktop:~$ pypy3 fizzbuzz.py | pv &gt; /dev/null
^C57MiB 0:00:30 [25,0MiB/s] [                            &lt;=&gt;                   ]
Traceback (most recent call last):
  File &quot;fizzbuzz.py&quot;, line 15, in &lt;module&gt;
    main()
  File &quot;fizzbuzz.py&quot;, line 13, in main
    next(f)
KeyboardInterrupt
</code></pre>
<h2>Chunking version</h2>
<p>Afterwards I modified the initial version to print the results in chunks, instead of one by one.</p>
<pre class="lang-python prettyprint-override"><code>from itertools import cycle, count

def derailleur(counter, carousel):
    if not carousel:
        return counter
    return carousel

def main():
    carousel = cycle([0,0,'Fizz',0,'Buzz','Fizz',0,0,'Fizz','Buzz',0,'Fizz',0,0,'FizzBuzz'])
    counter = map(str, count(1))
    f = map(derailleur, counter, carousel)
    while 1:
        print('\n'.join([next(f) for _ in range(256)]))

main()
</code></pre>
<p>Now under CPython it runs a bit faster, at about 19,6MiB/s. But under pypy it receives a large boost, achieving 84,9MiB/s, within half the speed of the naive implementation written in C reported by the OP (170MiB/s):</p>
<pre class="lang-python prettyprint-override"><code>user@Desktop:~$ python3 chunking_fizzbuzz.py | pv &gt; /dev/null
^C84MiB 0:00:30 [19,6MiB/s] [                            &lt;=&gt;                   ]
Traceback (most recent call last):
  File &quot;chunking_fizzbuzz.py&quot;, line 15, in &lt;module&gt;
    main()
  File &quot;chunking_fizzbuzz.py&quot;, line 13, in main
    print('\n'.join([next(f) for _ in range(256)]))
KeyboardInterrupt

user@Desktop:~$ pypy3 chunking_fizzbuzz.py | pv &gt; /dev/null
^C49GiB 0:00:30 [84,9MiB/s] [                            &lt;=&gt;                   ]
Traceback (most recent call last):
  File &quot;chunking_fizzbuzz.py&quot;, line 15, in &lt;module&gt;
    main()
  File &quot;chunking_fizzbuzz.py&quot;, line 13, in main
    print('\n'.join([next(f) for _ in range(256)]))
  File &quot;chunking_fizzbuzz.py&quot;, line 13, in &lt;listcomp&gt;
    print('\n'.join([next(f) for _ in range(256)]))
KeyboardInterrupt
</code></pre>
<p>I'm curious to see how much this result can be improved upon, for Python, and how other dynamic languages perform.</p>
</div>
<div id="pu33" class="pu"><p>There's plenty room for improvement here and I'll try to update when I can. (Most of the optimizations above will also be applicable):</p>
<p>A simple <strong>Powershell</strong> solution:</p>
<pre><code>$i = 1
#While ($i -gt 0){
While ($i -lt 100000){    # Limiting to 100k for testing
if ((($i % 5) -eq 0) -and (($i % 3) -eq 0)){Write-Host &quot;FizzBuzz&quot;}
elseif (($i % 3) -eq 0) {Write-Host &quot;Fizz&quot;}
elseif (((($i -split &quot;&quot; | Select-Object -SkipLast 1) | 
    Select-Object -Last 1) - eq 0) -or ((($i -split &quot;&quot; | 
    Select-Object -SkipLast 1) | Select-Object -Last 1) -eq 5)){Write-Host &quot;Buzz&quot;}
else {Write-Host $i}
$i++}
</code></pre>
</div>
<div id="pu34" class="pu"><p>Here is my attempt at using just-in-time compilation to emit fast FizzBuzz assembly that is specialized for every digit length.  It's basically the same idea as Neil's answer, just more overengineered.  A further 2x comes from the vmsplice system call as in the winning answer.  While there are a few other similarities in the AVX2 code, the usage of vmsplice is the only bit that I downright &quot;stole&quot; from there; all the vector code is my own.</p>
<p>The basic idea is to extract 32 bytes out of a prebuilt set of 32 characters that includes the current line number divided by ten (lo_bytes), the digits 0-9 (hi_bytes 0-9), the letters in Fizz and Buzz (hi_bytes 11-15) and the newline character (hi_bytes byte 10).  There are some extra complications:</p>
<ul>
<li><p>about half of the time the 32 bytes must be extracted in two steps, with the increment of lo_bytes inserted between the two extractions. The alternation of &quot;mov&quot;, &quot;or&quot;, &quot;store&quot;, &quot;increment lo_bytes&quot; and &quot;end of run&quot; operations is stored as a kind of &quot;bytecode&quot;. First, the program generates a string with the template of the FizzBuzz output for 30 consecutive numbers (30 is the LCM of 3, 5 and 10); then, to generate the bytecode, it operates on three substrings corresponding to 10 consecutive numbers.</p>
</li>
<li><p>the AVX2 vpshufb instruction operates on two &quot;lanes&quot; of 128 bits. Therefore it can only gather from bytes 0-15 into bytes 0-15, and from bytes 16-31 into bytes 16-31.  It can also place a zero in any byte though, which comes in really handy. This is why there are separate &quot;lo_bytes&quot; and &quot;hi_bytes&quot;. Each mask is split in two parts, one for the &quot;lo_bytes&quot; and one for the &quot;hi_bytes&quot;; each is vpshufb'ed while filling the bytes that come from the &quot;wrong&quot; character with a zero, and then the two parts are ORed together.</p>
</li>
</ul>
<p>I mentioned the bytecode before. There are two reasons why the program does not go directly to x86 code. First, going through bytecode simplifies noticeably the JIT compiler. Second, the JIT-compiled inner loop does not handle carry from byte 7 to byte 8 of the lo_bytes (which happens every 10^9 numbers written); that part is handled by interpreting the bytecode.</p>
<p>Actually, there's a third reason to have the bytecode, and it is possibly the most important even though it doesn't apply to the code submitted below.  The bytecode approach separates very well the tasks of preprocessing (figuring out the exact sequence for each number length) and emitting output; therefore, during development I could first work on the preprocessor while keeping a stupid for loop for the output, then add vectorized C code (which actually survives in the slow path to handle carries), and finally generated the code on the fly. Of course the program was super slow until the introduction of the JIT, but being able to test AVX2 code in C is obviously much easier! The whole implementation only took about 6 hours, hence more optimization is probably possible (sizing the piping buffer, better scheduling of the x86 code, etc.).</p>
<p>The hints about <code>taskset</code> and the same warnings about needing a &quot;useless cat&quot; apply to this program as well due to the use of vmsplice.</p>
<p>The code is not super polished. Variable names are especially horrible, sorry about that.</p>
<pre class="lang-c prettyprint-override"><code>/*
 * Author: Paolo Bonzini
 * gcc fb.c -o fb -O2 -g -mavx -mavx2 -flax-vector-conversions
 */
#define _GNU_SOURCE

#include &lt;sys/mman.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/uio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;assert.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;immintrin.h&gt;
#include &lt;avxintrin.h&gt;

#define F_SETPIPE_SZ 1031

#define ZERO    15

typedef uint8_t v32qi __attribute__((vector_size(32), aligned(32)));
typedef uint8_t v32qi_u __attribute__((vector_size(32), aligned(1)));

v32qi lo_bytes = {
    '1', '0', '0', '0', '0', '0', '0', '0',     /* 0 */
    '0', '0', '0', '0', '0', '0', '0', '\0',    /* 8 */
    '1', '0', '0', '0', '0', '0', '0', '0',     /* 0 */
    '0', '0', '0', '0', '0', '0', '0', '\0',    /* 8 */
};

uint8_t hi_bytes[16] = {
    '0', '1', '2', '3', '4', '5', '6', '7',     /* 16 */
    '8', '9', '\n', 'z', 'u', 'B', 'i', 'F',    /* 24 */
};

static v32qi biased_zero = {
    246, 246, 246, 246, 246, 246, 246, 246,
    246, 246, 246, 246, 246, 246, 246, 246,
    246, 246, 246, 246, 246, 246, 246, 246,
    246, 246, 246, 246, 246, 246, 246, 246,
};

static v32qi biased_line = {
    247, 246, 246, 246, 246, 246, 246, 246,
    246, 246, 246, 246, 246, 246, 246, 246,
    247, 246, 246, 246, 246, 246, 246, 246,
    246, 246, 246, 246, 246, 246, 246, 246,
};

static v32qi incr_low_mask = {
    1, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0,
    1, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0,
};

static v32qi incr_high_mask = {
    0, 0, 0, 0, 0, 0, 0, 0,
    1, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0,
    1, 0, 0, 0, 0, 0, 0, 0,
};

#define OUTPUT_SIZE(n)      (94+16*n)
#define TEMPLATE_SIZE(n)    ((OUTPUT_SIZE(n) + 31) &amp; ~31)
#define MAX         15

#define OUTBUF_SIZE     1048576

static uint8_t template[TEMPLATE_SIZE(MAX)];
static uint8_t *output1;
static uint8_t *output2;
static uint8_t *output;
#define BOUNDARY (output + OUTBUF_SIZE)

static v32qi mask[26];
static v32qi *mask_ptr;

static uint8_t code_buffer[64];
static uint8_t *code_ptr;

static uint8_t *jit_buffer;
static uint8_t *jit_ptr;
typedef uint8_t *jit_fn(uint8_t *, int);

/*
 * Bytecode language:
 *   0 = mov 32 bytes into temp buffer from the next mask
 *   1 = or 32 bytes into temp buffer from the next mask
 *   2 = increment the line
 *   3 = store 32 bytes from temp buffer
 *   -32..-1 = add n to the output pointer
 */
static void gen_prolog(void)
{
    code_ptr = code_buffer;
    mask_ptr = mask;
}

static void gen_epilog(int template_size)
{
    *code_ptr++ = 3;
    *code_ptr++ = (template_size &amp; 31) - 32;
}

static void do_gen_or_code(int from)
{
    assert(mask_ptr - mask &lt; sizeof(mask) / sizeof(mask[0]));

    // o[i++] |= out_bytes[template[from + i]];
    for (int i = 0; i &lt; 32; i++) {
        uint8_t m = template[from + i];
        if (m &lt; 16) {
            mask_ptr[0][i] = m;
            mask_ptr[1][i] = 0;
        } else {
            mask_ptr[0][i] = -1;
            mask_ptr[1][i] = hi_bytes[m - 16];
        }
    }
    *code_ptr++ = 1;
    mask_ptr += 2;
}

static void do_gen_mov_code(int from, int to)
{
    assert(mask_ptr - mask &lt; sizeof(mask) / sizeof(mask[0]));

    // o[i++] = out_bytes[template[from + i]];
    for (int i = 0; i &lt; 32; i++) {
        uint8_t m = (from + i &gt; to) ? ZERO : template[from + i];
        if (m &lt; 16) {
            mask_ptr[0][i] = m;
            mask_ptr[1][i] = 0;
        } else {
            mask_ptr[0][i] = -1;
            mask_ptr[1][i] = hi_bytes[m - 16];
        }
    }
    *code_ptr++ = 0;
    mask_ptr += 2;
}

static void gen_inc_code(void)
{
    *code_ptr++ = 2;
}

static void gen_out_code(int from, int to)
{
    int offset = from &amp; ~31;
    if (offset &lt; from) {
        assert(to &gt;= offset + 32);
        do_gen_or_code(offset);
        offset += 32;
        *code_ptr++ = 3;
    }
    while (offset &lt; to) {
        do_gen_mov_code(offset, to);
        offset += 32;
        if (offset &lt;= to)
            *code_ptr++ = 3;
    }
    memset(template + from, ZERO, to - from);
}

static void inc_line(v32qi incr_mask)
{
    v32qi old = biased_line;
    v32qi incr = _mm256_add_epi64((__m256i)incr_mask, (__m256i)old);
    biased_line = _mm256_max_epu8(incr, biased_zero);
    lo_bytes += biased_line - old;
}

static v32qi do_shuffle(v32qi *mask)
{
    v32qi digits = __builtin_ia32_pshufb256(lo_bytes, mask[0]);
    return digits | mask[1];
}

static uint8_t *maybe_output(uint8_t *o)
{
    if (o &gt; output + OUTBUF_SIZE) {
#if 1
        struct iovec iov = {output, OUTBUF_SIZE};
        do {
            ssize_t r = vmsplice(1, &amp;iov, 1, 0);
            if (r &lt; 0) {
                perror(&quot;vmsplice&quot;);
                exit(1);
            }
            iov.iov_base += r;
            iov.iov_len -= r;
        } while (iov.iov_len);
#else
        write(1, output, OUTBUF_SIZE);
#endif
        if (output == output1) {
            memcpy(output2, BOUNDARY, o - BOUNDARY);
            o = output2 + (o - BOUNDARY);
            output = output2;
        } else {
            memcpy(output1, BOUNDARY, o - BOUNDARY);
            o = output1 + (o - BOUNDARY);
            output = output1;
        }
    }
    return o;
}

static uint8_t *slow_run(uint8_t *o, int carry)
{
    const uint8_t *p;
    v32qi *m = mask;
    v32qi temp;
    for (p = code_buffer; p &lt; code_ptr; p++) {
        uint8_t c = *p;
        if (c == 0) {
            temp = do_shuffle(m);
            m += 2;
        } else if (c == 1) {
            temp |= do_shuffle(m);
            m += 2;
        } else if (c == 3) {
            *(v32qi_u *)o = temp;
            o += 32;
        } else if (c == 2) {
            inc_line(incr_low_mask);
            if (--carry == 0)
                inc_line(incr_high_mask);
        } else {
            o += (int8_t) c;
        }
    }
    return maybe_output(o);
}

#define o(b) (*jit_ptr++ = (0x##b))
#define s(p) jit_ptr += ({ uint32_t x = (uintptr_t)p - (uintptr_t)(jit_ptr + 4); memcpy(jit_ptr, &amp;x, 4); 4; })
#define d(i) jit_ptr += ({ uint32_t x = (i); memcpy(jit_ptr, &amp;x, 4); 4; })

void compile(void)
{
    const uint8_t *p, *label;
    v32qi *m = mask;
    int ofs = 0;

    jit_ptr = jit_buffer;
    o(C5),o(FD),o(6F),o(05),s(&amp;lo_bytes);      // vmovdqa ymm0, lo_bytes
    o(C5),o(FD),o(6F),o(15),s(&amp;biased_line);   // vmovdqa ymm2, biased_line
    o(C5),o(FD),o(6F),o(1D),s(&amp;biased_zero);   // vmovdqa ymm3, biased_zero
    o(C5),o(FD),o(6F),o(25),s(&amp;incr_low_mask); // vmovdqa ymm4, incr_low_mask

    /* in inc_line, lo_bytes - old is always the same.  Put it in ymm1.  */
    o(C5),o(FD),o(F8),o(CA);           // vpsubb ymm1, ymm0, ymm2

    label = jit_ptr;
    for (p = code_buffer; p &lt; code_ptr; p++) {
        uint8_t c = *p;
        if (c == 0) {
            o(C5),o(FD),o(6F),o(35),s(m);  // vmovdqa ymm6, MASK
            m++;
            o(C5),o(FD),o(6F),o(2D),s(m);  // vmovdqa ymm5, MASK
            m++;
            o(C4),o(E2),o(7D),o(00),o(F6); // vpshufb ymm6, ymm0, ymm6
            o(C5),o(D5),o(EB),o(EE);       // vpor ymm5, ymm5, ymm6
        } else if (c == 1) {
            o(C5),o(FD),o(6F),o(35),s(m);  // vmovdqa ymm6, MASK
            m++;
            o(C5),o(FD),o(6F),o(3D),s(m);  // vmovdqa ymm7, MASK
            m++;
            o(C4),o(E2),o(7D),o(00),o(F6); // vpshufb ymm6, ymm0, ymm6
            o(C5),o(D5),o(EB),o(EF);       // vpor ymm5, ymm5, ymm7
            o(C5),o(D5),o(EB),o(EE);       // vpor ymm5, ymm5, ymm6
        } else if (c == 3) {
            o(C5),o(FE),o(7F),o(AF),d(ofs); // vmovdqu [rdi+NNN], ymm5
            ofs += 32;
        } else if (c == 2) {
            o(C5),o(ED),o(D4),o(D4);      // vpaddq ymm2, ymm2, ymm4
            o(C5),o(ED),o(DE),o(D3);      // vpmaxub ymm2, ymm2, ymm3
            o(C5),o(F5),o(FC),o(C2);      // vpaddb ymm0, ymm1, ymm2
        } else {
            ofs += (int8_t) c;
        }
    }
    o(48),o(81),o(C7),d(ofs);   // add rdi, ofs
    o(FF),o(CE);                // dec esi
    o(0F),o(85),s(label);       // jnz label
    o(48),o(89),o(F8);          // mov rax, rdi
    o(C5),o(FD),o(7F),o(05),s(&amp;lo_bytes);     // vmovdqa lo_bytes, ymm0
    o(C5),o(FD),o(7F),o(15),s(&amp;biased_line);  // vmovdqa biased_line, ymm2
    o(C3);                // ret
}

#define INITIAL &quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\n&quot;
#define TENS_FOR_VPADDQ (10000 * 10000)

int main()
{
    uint8_t shuffle[] = { 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 16, 26 };
    const uint8_t fizz[] = { 31, 30, 27, 27, 26 };
    const uint8_t fizzbuzz[] = { 31, 30, 27, 27, 29, 28, 27, 27, 26 };
    const uint8_t *buzz = fizzbuzz + 4;
    
    int l;
    uint64_t n;
    uint32_t tens_till_carry = TENS_FOR_VPADDQ - 1;

    output1 = mmap(NULL, OUTBUF_SIZE + 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, -1, 0);
    output2 = mmap(NULL, OUTBUF_SIZE + 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, -1, 0);
    output = output1;
    uint8_t *o = mempcpy(output, INITIAL, strlen(INITIAL));

    fcntl(1, F_SETPIPE_SZ, OUTBUF_SIZE);
    memset(template, ZERO, sizeof(template));

    jit_buffer = mmap(NULL, 16384, PROT_READ|PROT_WRITE|PROT_EXEC,
              MAP_32BIT|MAP_PRIVATE|MAP_ANON, -1, 0);
    assert((uintptr_t)mask &lt;= 0x7FFFFFFF);
    assert((uintptr_t)jit_buffer &lt;= 0x7FFFFFFF);

    for (l = 2, n = 3; l &lt;= MAX; l++, n = n * 10) {
        int output_size = OUTPUT_SIZE(l);
        int template_size = TEMPLATE_SIZE(l);

        uint8_t *s = shuffle + sizeof(shuffle) - l - 1;
        uint8_t *p = template;

#define ZERO_UNITS s[l - 1] = 16;
#define INC_UNITS s[l - 1]++;

        ZERO_UNITS; p = mempcpy(p, buzz, 5); // 10
        INC_UNITS; p = mempcpy(p, s, l + 1); // 11
        INC_UNITS; p = mempcpy(p, fizz, 5); // 12
        INC_UNITS; p = mempcpy(p, s, l + 1); // 13
        INC_UNITS; p = mempcpy(p, s, l + 1); // 14
        INC_UNITS; p = mempcpy(p, fizzbuzz, 9); // 15
        INC_UNITS; p = mempcpy(p, s, l + 1); // 16
        INC_UNITS; p = mempcpy(p, s, l + 1); // 17
        INC_UNITS; p = mempcpy(p, fizz, 5); // 18
        INC_UNITS; p = mempcpy(p, s, l + 1); // 19
        ZERO_UNITS; p = mempcpy(p, buzz, 5); // 20
        INC_UNITS; p = mempcpy(p, fizz, 5); // 21
        INC_UNITS; p = mempcpy(p, s, l + 1); // 22
        INC_UNITS; p = mempcpy(p, s, l + 1); // 23
        INC_UNITS; p = mempcpy(p, fizz, 5); // 24
        INC_UNITS; p = mempcpy(p, buzz, 5); // 25
        INC_UNITS; p = mempcpy(p, s, l + 1); // 26
        INC_UNITS; p = mempcpy(p, fizz, 5); // 27
        INC_UNITS; p = mempcpy(p, s, l + 1); // 28
        INC_UNITS; p = mempcpy(p, s, l + 1); // 29
        ZERO_UNITS; p = mempcpy(p, fizzbuzz, 9); // 30
        INC_UNITS; p = mempcpy(p, s, l + 1); // 31
        INC_UNITS; p = mempcpy(p, s, l + 1); // 32
        INC_UNITS; p = mempcpy(p, fizz, 5); // 33
        INC_UNITS; p = mempcpy(p, s, l + 1); // 34
        INC_UNITS; p = mempcpy(p, buzz, 5); // 35
        INC_UNITS; p = mempcpy(p, fizz, 5); // 36
        INC_UNITS; p = mempcpy(p, s, l + 1); // 37
        INC_UNITS; p = mempcpy(p, s, l + 1); // 38
        INC_UNITS; p = mempcpy(p, fizz, 5); // 39
        memset(p, ZERO, template + template_size - p);

        gen_prolog();
        gen_out_code(0, 30+6*l);
        gen_inc_code();
        gen_out_code(30+6*l, 60+11*l);
        gen_inc_code();
        gen_out_code(60+11*l, 94+16*l);
        gen_inc_code();
        gen_epilog(94+16*l);

        compile();

        uint64_t left = n;
        do {
            int runs;
            if (tens_till_carry &lt;= 3) {
                if (tens_till_carry == 0) {
                    inc_line(incr_high_mask);
                    runs = 0;
                } else {
                    o = slow_run(o, tens_till_carry);
                    runs = 1;
                }
                tens_till_carry += TENS_FOR_VPADDQ;
            } else {
                runs = (BOUNDARY - o) / output_size + 1;
                if (runs &gt; left)
                    runs = left;
                if (runs * 3 &gt; tens_till_carry)
                    runs = tens_till_carry / 3;

                o = ((jit_fn *)jit_buffer) (o, runs);
                o = maybe_output(o);
            }
            left -= runs;
            tens_till_carry -= runs * 3;
        } while (left);
    }
    write(1, output, o - output);
}
</code></pre>
<p>Last minute add: here is how the number of source code lines grew as the bells and whistles were added. Handling the pesky carry is more work than the JIT compiler!</p>
<pre><code>227 basic implementation
252 rewrite mask operations as AVX2
253 add store bytecode
258 move loop inside the run function
276 increment line number using AVX
332 handle carry over 10^8
377 generate custom AVX2 code for each length
404 use the &quot;vmsplice&quot; system call
</code></pre>
</div>
<div id="pu35" class="pu"><p>This probably won't be the fastest, but I am curious how it performs compared to a naive stdio-based fizzbuzz. I created this to illustrate the approach I suggested in the comments of using an array of fixed-length regions to format the output, and filtering out null padding before printing the output. I didn't do any multithreading, either, this could probably be improved by using multiple buffers and doing the writing on another thread.</p>
<p>This code does nothing to prevent unusual output after reaching ULONG_MAX. It might be able to be made faster by only supporting up to UINT_MAX, which would also allow more data to fit in a given size of intermediate buffer.</p>
<pre class="lang-c prettyprint-override"><code>// sample outputs [space is null]
//                    1\n
// Fizz                \n
//     Buzz            \n
// FizzBuzz            \n
// 18446744073709551614\n ULLONG_MAX-1 [ULLONG_MAX is FizzBuzz]
#define LEN 21
//#define NUM (200*15)
#define NUM (200*15)

#if defined(_POSIX_C_SOURCE)
#include &lt;unistd.h&gt;
#define WRITE(b,l) write(1,b,l)
#elif defined(_MSC_VER)
#include &lt;io.h&gt;
#define WRITE(b,l) write(1,b,l)
#else
#include &lt;stdio.h&gt;
#define WRITE(b,l) fwrite(b,1,l,stdout)
#endif

char buf[NUM*LEN] = {0}; // 63000
char buf2[NUM*LEN];
int flags[NUM];

int main() {
    // pre-populate buffer
    for(int i=0; i&lt;NUM; i++) {
        char *t = buf+i*LEN;
        int f = flags[i] = i%3==0 | ((i%5==0)&lt;&lt;1);
        if(f&amp;1) { t[0]='F'; t[1]='i'; t[2]='z'; t[3]='z';}
        if(f&amp;2) { t[4]='B'; t[5]='u'; t[6]='z'; t[7]='z';}
        t[LEN-1] = '\n';
    }
    int j=1; // position of current output within buffer
    for(unsigned long long i=1;;i++) {
        if(!flags[j]) {
                char *t = buf+j*LEN+(LEN-2); // position of last digit
                unsigned long long k = i;
                while(k) {
                    *t-- = '0'+k%10;
                    k/=10;
                }
        }
        if(++j == NUM) {
            j=0;
            char *p=buf;
            char *q=buf2;
            if(i == NUM-1) p+=LEN; // skip zero, there's probably a better way
            while(p &lt; buf+NUM*LEN) {
                if(*p) *q++=*p;
                p++;
            }
            WRITE(buf2, q-buf2);
        }
    }
}
</code></pre>
</div>
<div id="pu36" class="pu"><p><b>C++</b></p>
<p>I’m not sure how you did the benchmarking but would appreciate it if you can run my naïve solution through it.</p>
<p>PS, sorry for being late for the party.</p>

<pre><code>#include &lt;vector&gt;
#include &lt;thread&gt;
#include &lt;iostream&gt;
#include &lt;unistd.h&gt;

class worker
{
public:
    worker(size_t size)
    {
        workersize = size;
        buf = new char[workersize * 40];
    }

    ~worker()
    {
        delete buf;
    }

    void run()
    {
        char thisMod = 0;
        char ibMod;
        char ib[20];
        size_t ibStart;
        size_t s;
        size_t last_ib = -100;            
        char* ptr = buf;

        for (size_t i = start; i &lt; end; i++)
        {
            size_t m3 = i % 3;
            size_t m5 = i % 5;
            if (m3 == 0 &amp;&amp; m5 == 0)
            {
                *ptr++ = 'F';
                *ptr++ = 'i';
                *ptr++ = 'z';
                *ptr++ = 'z';
                *ptr++ = 'B';
                *ptr++ = 'u';
                *ptr++ = 'z';
                *ptr++ = 'z';
            }
            else if (m3 == 0)
            {
                *ptr++ = 'F';
                *ptr++ = 'i';
                *ptr++ = 'z';
                *ptr++ = 'z';
            }
            else if (m5 == 0)
            {
                *ptr++ = 'B';
                *ptr++ = 'u';
                *ptr++ = 'z';
                *ptr++ = 'z';
            }
            else
            {
                if (i - last_ib &lt; 10 &amp;&amp; ibMod + thisMod &lt; 10)
                {
                    // uses previous ib
                    for (s = ibStart; s &lt;= 14; s++)
                        *ptr++ = ib[s];
                    *ptr++ = ib[s] + thisMod - ibMod;
                }
                else
                {
                    // calc new ib
                    size_t x = i;
                    size_t s = 15;
                    ibMod = x % 10;
                    ib[s--] = ibMod + '0';
                    x /= 10;
                    while (x &gt; 0)
                    {
                        ib[s--] = (x % 10) + '0';
                        x /= 10;
                    }
                    ibStart = ++s;
                    for (ibStart; s &lt;= 15; s++)
                        *ptr++ = ib[s];
                    last_ib = i;
                }
            }

            *ptr++ = '\n';
            thisMod++;
            if (thisMod &gt; 9)
                thisMod = 0;
        }
        buflen = ptr - buf;
    }

    size_t start;
    size_t end;
    size_t workersize;
    char* buf;
    size_t buflen;
};

void task(worker* w)
{
    w-&gt;run();
}

int main() 
{
    size_t workercount = std::thread::hardware_concurrency();
    size_t workersize = 10000000;

    // create workers
    std::vector&lt;worker*&gt; workers;
    for (size_t i = 0; i &lt; workercount; i++)
        workers.push_back(new worker(workersize));
   
    // main loop
    size_t cur = 0;
    for (;;)
    {
        // init workers
        for (worker* worker : workers)
        {
            worker-&gt;start = cur;
            cur += workersize;
            worker-&gt;end = cur;
        }

        std::vector&lt;std::thread&gt; threads;
        for (worker* worker : workers)
            threads.emplace_back(task, worker);

        for (std::thread&amp; thread : threads)
            thread.join();


        // write output
        for (worker* worker : workers)
             write(1, worker-&gt;buf, worker-&gt;buflen);

        // write progress to cerr
        std::cerr &lt;&lt; cur &lt;&lt; &quot;\n&quot;;
    }
}
</code></pre>
</div>
<div id="pu37" class="pu"><p>A C++ program for Linux.  I use the same method of arithmetic as in <a href="/a/217771/39490">my C answer</a>, but here I create a team of threads by hand rather than using OpenMP.</p>
<p>We divide the problem into ranges of numbers, so that we don't have to touch the low-order digits each iteration.</p>
<p>The workers are arranged in a circular chain, and each is responsible for a subrange.  We do all our addition while other threads are writing, then take a turn at writing.  In order to write an exact number of pages with each write, there's generally one write that straddles two workers, so we combine writes using <code>writev()</code>, temporarily blocking the other worker from beginning its arithmetic.  The timing diagram looks like this:</p>
<pre class="lang-none prettyprint-override"><code>    +--------------------------------------------+
    |                                            |
    |   wait                                     |
-------&gt;                                         |
    |      write (end of prev, start of this)    |          +--------------------------------------------+
&lt;-------                                         |          |                                            |
    |      write (just this one)                 |          |   wait                                     |
    |                                      --------------------&gt;                                         |
    |                                  wait      |          |      write (end of prev, start of this)    |
    |                                      &lt;--------------------                                         |
    |      update each number                    |          |      write (just this one)                 |
    |                                            |          |                                      ------+-----&gt;
    +--------------------------------------------+          |                                  wait      |
                                                            |                                      &lt;------------
                                                            |      update each number                    |
                                                            |                                            |
                                                            +--------------------------------------------+
</code></pre>
<p>On my workstation (8 thread Ivybridge), I measured at around 90% the throughput of <code>cat /dev/zero</code>, or about ¾ that of <code>dd if=/dev/zero bs=64K</code>.</p>
<pre class="lang-cpp prettyprint-override"><code>#include &lt;cassert&gt;
#include &lt;condition_variable&gt;
#include &lt;iostream&gt;
#include &lt;memory&gt;
#include &lt;mutex&gt;
#include &lt;thread&gt;
#include &lt;vector&gt;

#include &lt;unistd.h&gt;
#include &lt;sys/sysinfo.h&gt;
#include &lt;sys/uio.h&gt;

// Select a number of decimal digits to use.  If we produce one billion
// numbers per second, then we'll finish all the 18-digit numbers in
// just 30 years.  24 digits should suffice until the next geological
// epoch, at least.
static constexpr int numlen = 25; // 24 digits plus newline

static constexpr int write_size = 0x10000; // this is fastest on my system

static_assert('0' - '\n' &gt; 1, &quot;Character coding incompatible with the arithmetic&quot;);

#define unlikely(e) __builtin_expect((e), 0)


struct worker
{
    // Storage for the character string we maintain
    std::string lines{&quot;&quot;};
    // Iterators to each newline in 'lines'
    std::vector&lt;std::string::iterator&gt; nl{};

    int units_offset{};         // significant figures in the step
    char digit{};               // the single non-zero digit of step

    // We coordinate with the next and previous threads in the ring.
    // The iovec is used for writing a block of lines that straddles
    // the previous thread and this one.
    std::mutex mutex{};
    std::condition_variable cv{};
    struct iovec iov[2] = { { 0, 0 }, { 0, 0 } };
    worker *next{};

    // The functions
    worker(std::size_t first, std::size_t count, std::size_t step);
    worker(const worker&amp;) = delete;
    worker&amp; operator=(const worker&amp;) = delete;
    void loop();
};


static constexpr auto buf_len(std::size_t digits, std::size_t count)
{
    // each group of 15 lines has 8 numbers and 39 chars of Fizz and Buzz
    return (8 * digits + 39) * count / 15;
}

static constexpr std::size_t optimal_step(long thread_count)
{
    // We need each thread to produce at least write_size each iteration
    for (std::size_t tens = 1000;  tens &lt; 10'000'000;  tens *= 10) {
        auto const digits = std::snprintf(0, 0, &quot;%zu&quot;, tens);
        for (std::size_t digit = 3;  digit &lt; 10;  digit += 3) {
            if (buf_len(digits, digit * tens) / thread_count &gt; write_size) {
                return digit * tens;
            }
        }
    }
    return 9'000'000; // fallback (perhaps we should limit thread count?)
}

int main()
{
    // How many threads will we have?
    auto const nprocs = get_nprocs();
    auto const step = optimal_step(nprocs);

    // Write output the slow way, until we have enough digits for the
    // format strings.
    auto n = 1;
    const auto step_len = std::to_string(step).size();
    // Finish the loop just before a FizzBuzz, so that the lines buffer
    // doesn't start with a number (we need a newline preceding for it
    // to overflow correctly).
    for (;  std::to_string(n).size() &lt;= step_len;  ++n) {
        if ((n % 15) == 0) {
            std::cout &lt;&lt; &quot;FizzBuzz\n&quot;;
        } else if ((n % 5) == 0) {
            std::cout &lt;&lt; &quot;Buzz\n&quot;;
        } else if ((n % 3) == 0) {
            std::cout &lt;&lt; &quot;Fizz\n&quot;;
        } else {
            std::cout &lt;&lt; n &lt;&lt; '\n';
        }
    }
    std::cout.flush();          // use Unix write() from here on

    // create the workers
    auto workers = std::vector&lt;std::unique_ptr&lt;worker&gt;&gt;{};
    workers.reserve(nprocs);
    for (int i = 0;  i &lt; nprocs;  ++i) {
        auto const a = i * step / nprocs;
        auto const z = (i+1) * step / nprocs;
        workers.emplace_back(std::make_unique&lt;worker&gt;(n + a, z - a, step));
    }
    // and connect them in a loop
    workers.back()-&gt;next = workers.front().get();
    for (int i = 1;  i &lt; nprocs;  ++i) {
        workers[i-1]-&gt;next = workers[i].get();
    }

    // a thread for each worker
    auto threads = std::vector&lt;std::unique_ptr&lt;std::thread&gt;&gt;{};
    threads.reserve(nprocs);
    auto const loop = [](worker *w) { w-&gt;loop(); };
    for (auto const&amp; w: workers) {
        threads.emplace_back(std::make_unique&lt;std::thread&gt;(loop, w.get()));
    }

    // start them writing
    auto &amp;first = workers.front();
    {
        std::unique_lock lock{first-&gt;mutex};
        first-&gt;iov[0] = { &amp;first-&gt;lines.front(), 0 };
    }
    first-&gt;cv.notify_one();

    threads.front()-&gt;join();
}

worker::worker(std::size_t first, std::size_t count, std::size_t step)
{
    auto s = std::to_string(step);
    units_offset = s.size() + 1;
    digit = s.front() - '0';

    lines.reserve(buf_len(numlen, count) + 1);
    nl.reserve(count);
    assert(lines.capacity() &gt;= write_size);

    for (auto n = first;  n &lt; first + count;  ++n) {
        if ((n % 15) == 0) {
            lines += &quot;FizzBuzz\n&quot;;
        } else if ((n % 5) == 0) {
            lines += &quot;Buzz\n&quot;;
        } else if ((n % 3) == 0) {
            lines += &quot;Fizz\n&quot;;
        } else {
            lines += std::to_string(n) + '\n';
        }
        nl.push_back(lines.end());
    }
    assert(lines.size() &gt;= write_size);

    // Second half of a straddle write is always from the beginning of our buffer.
    iov[1].iov_base = &amp;lines.front();
}

void worker::loop()
{
    assert(next);
    for (;;) {
        {
            // We can write when the previous thread passes its buffer offcut.
            std::unique_lock lock{mutex};
            cv.wait(lock, [this]{ return iov[0].iov_base; });

            iov[1].iov_len = write_size - iov[0].iov_len;
            assert(iov[1].iov_len &lt; lines.size());
            writev(1, iov, 2);
            // Tell the previous thread that we've finished with its buffer.
            iov[0].iov_base = 0;
        }
        cv.notify_one();

        auto p = lines.begin() + iov[1].iov_len;
        while (unlikely(p + write_size &lt; lines.end())) {
            ::write(1, &amp;*p, write_size);
            p += write_size;
        }

        {
            // Tell the next thread that we have leftover data for it to write.
            std::unique_lock lock{next-&gt;mutex};
            next-&gt;iov[0] = { &amp;*p, static_cast&lt;std::size_t&gt;(lines.end() - p) };
        }
        next-&gt;cv.notify_one();

        {
            // Now wait until next worker has written, and released buffer back to us.
            std::unique_lock lock{next-&gt;mutex};
            next-&gt;cv.wait(lock, [this]{ return !next-&gt;iov[0].iov_base; });
        }


        // Update the numbers in the buffer.
        auto rollover = 0u;
        for (auto const&amp; i: nl) {
            if (i[-2] == 'z') {
                // fizz and/or buzz - not a number
                continue;
            }
            // else add 'step' to the number
            auto p = i - units_offset;
            *p += digit;
            while (*p &gt; '9') {
                *p-- -= 10;
                ++*p;
            }
            if (unlikely(*p == '\n'+1)) {
                // digit rollover
                ++rollover;
            }
        }
        if (unlikely(rollover)) {
            // Add a leading one to each overflowing number.
            auto nlp = nl.end();
            auto p = lines.end();
            assert(lines.size() + rollover &lt; lines.capacity());
            lines.resize(lines.size() + rollover);
            auto dest = lines.end();
            while (--p &lt; --dest) {
                if (*p == '\n'+1) {
                    --*p;
                    *dest-- = '1';
                }
                if (*p == '\n') {
                    *nlp-- = dest + 1;
                }
                *dest = *p;
            }
        }
    }
}

</code></pre>
<p>Compile using <code>g++-10 -std=c++2a -Wall -Wextra -Weffc++ -DNDEBUG -O3 -march=native -fno-exceptions -lpthread</code>.  No special arguments or environment are needed when running.</p>
</div>
<div id="pu38" class="pu">
<p>My solution maintains a buffer with a batch of lines (6000 lines worked best on my system), and updates all the numbers in the buffer in a parallelisable loop.  We use an auxiliary array <code>nl[]</code> to keep track of where each newline lies, so we have random access to all the numbers.</p>
<p>The addition is all in-place decimal character-by-character arithmetic, with no arithmetic division after the buffer is initialised (I could have created the buffer without division, too, but opted for shorter, readable code!).  Every so often, when the number of digits rolls over, we have to stop and re-position all the numbers within the buffer (that's what the <code>shuffle</code> counter is for), and update the corresponding entries in <code>nl[]</code>; this happens more and more infrequently as we proceed.</p>
<p>I compiled using <code>gcc -std=gnu17 -Wall -Wextra -fopenmp -O3 -march=native</code>, and ran with <code>OMP_NUM_THREADS=3</code> set in the environment (a different number of threads may be optimal on another host).</p>
<pre class="lang-c prettyprint-override"><code>#include &lt;stdatomic.h&gt;
#include &lt;stdio.h&gt;              /* sprintf */
#include &lt;string.h&gt;             /* memset */
#include &lt;unistd.h&gt;

/* This is the single tunable you need to adjust for your platform */
#define chunk 6000 /* must be multiple of 3*5, with only one nonzero digit */
/* i.e. 3, 6 or 9 times an exact power of ten */

/* Select a number of digits to use.  If we produce one billion numbers
   per second, then we'll finish all the 18-digit numbers in just 30
   years.  24 digits should suffice until next geological epoch, at least. */
#define numlen 25               /* 24 decimal digits plus newline */

#define STR_(x) #x
#define STR(x) STR_(x)
#define chunk_str STR(chunk)

#define unlikely(e) __builtin_expect((e), 0)

char format[chunk * numlen];
char *nl[chunk+1];

int main()
{
    /* Create the format string. */
    /* We do this twice, as the numbers written first time round are
       too short for the addition. */
    for (int j = 0, n = 1;  j &lt; 2;  ++j)
    {
        nl[0] = format;
        char *p = format;
        for (int i = 0;  i &lt;= chunk;  ++i, ++n) {
            if ((n % 15) == 0) {
                p += sprintf(p, &quot;FizzBuzz\n&quot;);
            } else if ((n % 5) == 0) {
                p += sprintf(p, &quot;Buzz\n&quot;);
            } else if ((n % 3) == 0) {
                p += sprintf(p, &quot;Fizz\n&quot;);
            } else {
                p += sprintf(p, &quot;%d\n&quot;, n);
            }
            nl[i] = p;
        }
        write(1, format, nl[chunk] - format);
    }

    atomic_int shuffle = 0;
    for (;;) {
#pragma omp parallel for schedule(static)
        for (int i = 0;  i &lt; chunk;  ++i) {
            if (nl[i+1][-2] == 'z') {
                /* fizz and/or buzz - not a number */
                continue;
            }
            /* else add 'chunk' to the number */
            static const int units_offset = sizeof chunk_str;
            static const int digit = chunk_str[0] - '0';
            char *p = nl[i+1] - units_offset;
            *p += digit;
            while (*p &gt; '9') {
                *p-- -= 10;
                ++*p;
            }
            if (unlikely(p &lt; nl[i])) {
                /* digit rollover */
                ++shuffle;
            }
        }
        if (unlikely(shuffle)) {
            /* add a leading one to each overflowing number */
            char **nlp = nl + chunk;
            char *p = *nlp;
            char *dest = p + shuffle;
            while (p &lt; dest) {
                if (*p == '\n') {
                    *nlp-- = dest + 1;
                } else if (*p == '\n'+1) {
                    --*p;
                    *dest-- = '1';
                    *nlp-- = dest + 1;
                }
                *dest-- = *p--;
            }
            shuffle = 0;
        }
        write(1, format, nl[chunk] - format);
    }
}
</code></pre>
</div>
<div id="pu39" class="pu"><p>Coded in rust- modern languages can be fast too. Build with <code>cargo build --release</code>* and run with <code>./target/release/fizz_buzz</code>. The count goes up by 15 every iteration of the loop. The itoap crate is used to quickly write integers to the buffer. Adds 15 line chunks to an array unless there isn't enough space left in the buffer for a max-sized chunk, and when that happens it flushes the buffer to stdout.</p>
<p>main.rs:</p>
<pre class="lang-rust prettyprint-override"><code>use std::io::*;
use itoap::Integer;
const FIZZ:*const u8 = &quot;Fizz\n&quot;.as_ptr();
const BUZZ:*const u8 = &quot;Buzz\n&quot;.as_ptr();
const FIZZBUZZ:*const u8 = &quot;FizzBuzz\n&quot;.as_ptr();
const BUF_SIZE:usize = 1024*256;
const BLOCK_SIZE:usize = 15 * i32::MAX_LEN;
/// buf.len() &gt; count
macro_rules! itoap_write{
  ($buf:ident,$count:ident,$num:ident)=&gt;{
    $count += itoap::write_to_ptr(
      $buf.get_unchecked_mut($count..).as_mut_ptr(),
      $num
    );
    $buf.as_mut_ptr().add($count).write(b'\n');
    $count += 1;
  }
}
///ptr must be valid, buf.len() &gt; count, ptr.add(len) must not overflow buffer
macro_rules! str_write{
  ($buf:ident,$count:ident,$ptr:ident,$len:literal)=&gt;{
    let ptr = $buf.get_unchecked_mut($count..).as_mut_ptr();
    ptr.copy_from_nonoverlapping($ptr,$len);
    $count += $len;
  }
}

fn main() -&gt; Result&lt;()&gt;{
  let mut write = stdout();
  let mut count:usize = 0;
  let mut buf = [0u8;BUF_SIZE];
  let mut i:i32 = -1;
  loop{
    if &amp;count + &amp;BLOCK_SIZE &gt; BUF_SIZE{
      unsafe{
        write.write_all(
          buf.get_unchecked(..count)
        )?;
      }
      count = 0;
    } 
    i += 2;
    unsafe{
      itoap_write!(buf,count,i);     
      i += 1;
      itoap_write!(buf,count,i);
      str_write!(buf,count,FIZZ,5);
      i += 2;
      itoap_write!(buf,count,i);
      str_write!(buf,count,BUZZ,5);
      str_write!(buf,count,FIZZ,5);
      i += 3;
      itoap_write!(buf,count,i);
      i += 1;
      itoap_write!(buf,count,i);
      str_write!(buf,count,FIZZ,5);
      str_write!(buf,count,BUZZ,5);
      i += 3;
      itoap_write!(buf,count,i);
      str_write!(buf,count,FIZZ,5);
      i += 2;
      itoap_write!(buf,count,i);
      i += 1;
      itoap_write!(buf,count,i);
      str_write!(buf,count,FIZZBUZZ,9);
    }
  }
}

</code></pre>
<p>Cargo.toml:</p>
<pre><code>[package]
name = &quot;fizz_buzz&quot;
version = &quot;0.1.0&quot;
authors = [&quot;aiden4&quot;]
edition = &quot;2018&quot;

[dependencies]
itoap = &quot;0.1&quot;
[[bin]]
name = &quot;fizz_buzz&quot;
path = &quot;main.rs&quot;

[profile.release]
lto = &quot;fat&quot;
</code></pre>
<p>*requires cargo to be able to connect to the internet</p>
</div>
<div id="pu40" class="pu"><p>I was struggling to get more than 2.75GB/s on my rig but then I realised I wasn't compiling with <code>-O3</code> which bumped me up to 6.75GB/s.</p>
<pre class="lang-c prettyprint-override"><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
char buf[416];
char out[65536 + 4096] = &quot;1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\n&quot;;
int main(int argc, char **argv) {
  const int o[16] = { 4, 7, 2, 11, 2, 7, 12, 2, 12, 7, 2, 11, 2, 7, 12, 2 };
  char *t = out + 30;
  unsigned long long i = 1, j = 1;
  for (int l = 1; l &lt; 20; l++) {
    int n = sprintf(buf, &quot;Buzz\n%llu1\nFizz\n%llu3\n%llu4\nFizzBuzz\n%llu6\n%llu7\nFizz\n%llu9\nBuzz\nFizz\n%llu2\n%llu3\nFizz\nBuzz\n%llu6\nFizz\n%llu8\n%llu9\nFizzBuzz\n%llu1\n%llu2\nFizz\n%llu4\nBuzz\nFizz\n%llu7\n%llu8\nFizz\n&quot;, i, i, i, i, i, i, i + 1, i + 1, i + 1, i + 1, i + 1, i + 2, i + 2, i + 2, i + 2, i + 2);
    i *= 10;
    while (j &lt; i) {
      memcpy(t, buf, n);
      t += n;
      if (t &gt;= &amp;out[65536]) {
        char *u = out;
        do {
          int w = write(1, u, &amp;out[65536] - u);
          if (w &gt; 0) u += w;
        } while (u &lt; &amp;out[65536]);
        memcpy(out, out + 65536, t - &amp;out[65536]);
        t -= 65536;
      }
      char *q = buf;
      for (int k = 0; k &lt; 16; k++) {
        char *p = q += o[k] + l;
        if (*p &lt; '7') *p += 3;
        else {
          *p-- -= 7;
          while (*p == '9') *p-- = '0';
          ++*p;
        }
      }
      j += 3;
    }
  }
}
</code></pre>
</div>
<div id="pu41" class="pu"><p>My code works on Windows 10. It outputs 8-9 GiB/s when the CPU is cool enough.</p>
<p>I used the following ideas in my code:</p>
<ul>
<li>Filling a buffer 256 KiB and sending it to output; for smaller buffer size the performance suffers; bigger buffer sometimes improves performance, but never by much.</li>
<li>For numbers which have the same number of digits, it works in chunks of 15 output lines. These chunks have identical length. While the size of the output buffer is big enough, it copies the previous chunk and adds 15 to the ASCII representation of all the numbers in it.</li>
<li>Near the end of the buffer and for first chunk, it calculates the output messages explicitly. Also, if numbers in the chunk have different length (e.g. 9999 and 10000).</li>
<li>It uses OpenMP to calculate 4 chunks simultaneously. I set <code>NUM_THREADS</code> to 4 (best on my computer, which has 8 logical cores); a larger setting might be better.</li>
</ul>
<p>When I want to verify the output, I set <code>check_file = 1</code> in code; if <code>check_file = 0</code>, it writes to <code>NUL</code>, which is the null output device on Windows.</p>
<pre class="lang-c prettyprint-override"><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include &lt;inttypes.h&gt;
#include &lt;assert.h&gt;
#include &quot;windows.h&quot;
#include &quot;fileapi.h&quot;
#include &quot;process.h&quot;

int size_15(int num_digits) // size of 15 messages, where numbers have a given number of digits
{
    return 8 * num_digits + 47;
}

int num_of_digits(int64_t counter) // number of digits
{
    int result = 1;
    if (counter &gt;= 100000000)
    {
        counter /= 100000000;
        result += 8;
    }
    if (counter &gt;= 10000)
    {
        counter /= 10000;
        result += 4;
    }
    if (counter &gt;= 100)
    {
        counter /= 100;
        result += 2;
    }
    if (counter &gt;= 10)
        return result + 1;
    else
        return result;
}

void print_num(char* buf, int64_t counter, int num_digits)
{
    for (int i = 0; i &lt; num_digits; ++i)
    {
        buf[num_digits - 1 - i] = counter % 10 + '0';
        counter /= 10;
    }
}

void add_15_to_decimal_num(char* p, int num_digits)
{
    char digit = p[num_digits - 1] + 5;
    int c = (digit &gt; '9');
    p[num_digits - 1] = (char)(digit - c * 10);
    c += 1;
    for (int i = 1; i &lt; num_digits; ++i)
    {
        if (c == 0)
            break;
        digit = (char)(p[num_digits - 1 - i] + c);
        c = digit &gt; '9';
        p[num_digits - 1 - i] = (char)(digit - c * 10);
    }
}

uint64_t fill_general(char* buf, int size, uint64_t counter, int* excess)
{
    char* p = buf;
    while (p &lt; buf + size)
    {
        int fizz = counter % 3 == 0;
        int buzz = counter % 5 == 0;
        if (fizz &amp;&amp; buzz)
        {
            memcpy(p, &quot;FizzBuzz\n&quot;, 9);
            p += 9;
        }
        else if (fizz)
        {
            memcpy(p, &quot;Fizz\n&quot;, 5);
            p += 5;
        }
        else if (buzz)
        {
            memcpy(p, &quot;Buzz\n&quot;, 5);
            p += 5;
        }
        else
        {
            int num_digits = num_of_digits(counter);
            print_num(p, counter, num_digits);
            p[num_digits] = '\n';
            p += num_digits + 1;
        }
        ++counter;
    }
    *excess = (int)(p - (buf + size));
    return counter;
}

void fill15(char* buf, int64_t counter, int num_digits, int num_ofs[8])
{
    char* p = buf;
    int m15 = counter % 15;
    for (int i = m15; i &lt; m15 + 15; ++i)
    {
        if (i % 15 == 0)
        {
            memcpy(p, &quot;FizzBuzz\n&quot;, 9);
            p += 9;
        }
        else if (i % 3 == 0)
        {
            memcpy(p, &quot;Fizz\n&quot;, 5);
            p += 5;
        }
        else if (i % 5 == 0)
        {
            memcpy(p, &quot;Buzz\n&quot;, 5);
            p += 5;
        }
        else
        {
            *num_ofs++ = (int)(p - buf);
            print_num(p, counter + i - m15, num_digits);
            p += num_digits;
            *p++ = '\n';
        }
    }
}

// memcpy replacement; works only for sizes equal to 47 + 8 * n, for small n
void copy_47_8n(char* src, unsigned size)
{
    char* dst = src + size;

    memcpy(dst, src, 47);
    size -= 47;
    dst += 47;
    src += 47;

    if (size &gt;= 128)
        exit(1);
    if (size &gt;= 96)
        memcpy(dst + 64, src + 64, 32);
    if (size &gt;= 64)
        memcpy(dst + 32, src + 32, 32);
    if (size &gt;= 32)
        memcpy(dst + 0, src + 0, 32);
    dst += size / 32 * 32;
    src += size / 32 * 32;
    size %= 32;
    if (size &gt;= 24)
        memcpy(dst + 16, src + 16, 8);
    if (size &gt;= 16)
        memcpy(dst + 8, src + 8, 8);
    if (size &gt;= 8)
        memcpy(dst + 0, src + 0, 8);
}

#define NUM_THREADS 4

uint64_t fill_fast(char* buf, int size, uint64_t counter, int* excess)
{
    const int num_digits = num_of_digits(counter);
    const int chunk_size = 8 * num_digits + 47;
    const int num_iter = size / chunk_size;
    int thread;
#pragma omp parallel for
    for (thread = 0; thread &lt; NUM_THREADS; ++thread)
    {
        const int begin_iter = num_iter * thread / NUM_THREADS;
        const int thread_num_iter = num_iter * (thread + 1) / NUM_THREADS - begin_iter;
        char* output = buf + begin_iter * chunk_size;
        int num_ofs[8];
        fill15(output, counter + begin_iter, num_digits, num_ofs);
        for (int iter = 1; iter &lt; thread_num_iter; ++iter)
        {
            copy_47_8n(output, chunk_size);
            for (int i = 0; i &lt; 8; ++i)
                add_15_to_decimal_num(output + chunk_size + num_ofs[i], num_digits);
            output += chunk_size;
        }
    }

    buf += num_iter * chunk_size;
    size -= num_iter * chunk_size;
    counter += num_iter * 15;

    return fill_general(buf, size, counter, excess);
}

uint64_t fill(char* buf, int size, uint64_t counter, int* excess)
{
    int num_digits = num_of_digits(counter);
    int64_t max_next_counter = counter + size / (8 * num_digits + 47) * 15 + 15;
    int max_next_num_digits = num_of_digits(max_next_counter);
    if (num_digits == max_next_num_digits)
        return fill_fast(buf, size, counter, excess);
    else
        return fill_general(buf, size, counter, excess);
}

void file_io(void)
{
    int check_file = 0;
    HANDLE f = CreateFileA(check_file ? &quot;my.txt&quot; : &quot;NUL&quot;, GENERIC_WRITE, FILE_SHARE_READ, 0, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, 0);
    DWORD e = GetLastError();
    LARGE_INTEGER frequency;
    QueryPerformanceFrequency(&amp;frequency);

    DWORD read;
    int bufsize = 1 &lt;&lt; 18;
    long long statsize = 1ll &lt;&lt; 34;
    char* buf = malloc(bufsize);
    uint64_t counter = 1;
    int excess = 0;
    while (counter &lt; 9999999900000000)
    {
        LARGE_INTEGER start, stop;
        QueryPerformanceCounter(&amp;start);
        for (int i = 0; i &lt; statsize / bufsize; ++i)
        {
            memcpy(buf, buf + bufsize, excess);
            counter = fill(buf + excess, bufsize - excess, counter, &amp;excess);
            e = WriteFile(f, buf, bufsize, &amp;read, 0);
            if (check_file)
                FlushFileBuffers(f);
            if (e == 0 || (int)read != bufsize)
            {
                e = GetLastError();
                exit(1);
            }
        }
        QueryPerformanceCounter(&amp;stop);
        double time = (double)(stop.QuadPart - start.QuadPart) / frequency.QuadPart;
        printf(&quot;Throughput (GB/s): %f\n&quot;, statsize / (1 &lt;&lt; 30) / time);
    }

    CloseHandle(f);
    exit(0);
}

int main()
{
    file_io();
}
</code></pre>
</div>
<div id="pu42" class="pu"><p>After much trial and error, with the goal of not resorting to Assembly while achieving the best single-threaded performance, this is my entry:</p>
<pre class="lang-c prettyprint-override"><code>#include &lt;unistd.h&gt;

#define unlikely(e)      __builtin_expect((e), 0)
#define mcpy(d, s, n)    __builtin_memcpy((d), (s), (n))

#define CACHELINE 64
#define PGSIZE 4096
#define ALIGNED_BUF 65536
#define FIZZ &quot;Fizz&quot;
#define BUZZ &quot;Buzz&quot;
#define DELIM &quot;\n&quot;

typedef struct {
    unsigned char offset;
    char data[CACHELINE - sizeof(unsigned char)];
} counters_t;

static inline void os_write(int out, void *buf, unsigned int n)
{
    while (n)
    {
        ssize_t written = write(out, buf, n);

        if (written &gt;= 0)
        {
            buf += written;
            n -= written;
        }
    }
}

int main(void)
{
    const int out = 1;

    __attribute__((aligned(CACHELINE))) static counters_t counter = {
        sizeof(counter.data) - 1, &quot;00000000000000000000000000000000000000000000000000000000000000&quot;
    };
    __attribute__((aligned(PGSIZE))) static char buf[ALIGNED_BUF + (sizeof(counter.data) * 15 * 3)] = { 0 };
    char *off = buf;

    for (;;)
    {
        // Write chunks of 30 counters until we reach `ALIGNED_BUF`
        while (off - buf &lt; ALIGNED_BUF)
        {
            #define NN (sizeof(counter.data) - 2)

            // Hand-rolled counter copy, because with non-constant sizes the compiler
            // just calls memcpy, which is too much overhead.
            #define CTRCPY(i) do { \
                const char *src = end; \
                char *dst = off; \
                unsigned _n = n; \
                switch (_n &amp; 3) { \
                case 3: *dst++ = *src++; \
                case 2: \
                    mcpy(dst, src, 2); \
                    dst += 2; src += 2; \
                    break; \
                case 1: *dst++ = *src++; \
                case 0: break; \
                } \
                for (_n &amp;= ~3; _n; _n -= 4, dst += 4, src += 4) { \
                    mcpy(dst, src, 4); \
                } \
                mcpy(off + n, i DELIM, sizeof(i DELIM) - 1); \
                off += n + sizeof(i DELIM) - 1; \
            } while (0)

            // Write the first 10 counters of the group (need to separate the
            // first 10 counters from the rest of the chunk due to possible decimal
            // order increase at the end of this block)
            {
                const char *const end = counter.data + counter.offset;
                const unsigned int n = sizeof(counter.data) - counter.offset - 1;

                CTRCPY(&quot;1&quot;); // 1
                CTRCPY(&quot;2&quot;); // 2

                mcpy(off, FIZZ DELIM, sizeof(FIZZ DELIM) - 1); // Fizz (3)
                off += sizeof(FIZZ DELIM) - 1;

                CTRCPY(&quot;4&quot;); // 4

                mcpy(off, BUZZ DELIM FIZZ DELIM, sizeof(BUZZ DELIM FIZZ DELIM) - 1); // Buzz (5) Fizz (6)
                off += sizeof(BUZZ DELIM FIZZ DELIM) - 1;

                CTRCPY(&quot;7&quot;); // 7
                CTRCPY(&quot;8&quot;); // 8

                mcpy(off, FIZZ DELIM BUZZ DELIM, sizeof(FIZZ DELIM BUZZ DELIM) - 1); // Fizz (9) Buzz (10)
                off += sizeof(FIZZ DELIM BUZZ DELIM) - 1;

                // Carry handling on MOD 10
                for (unsigned d = NN; ; --d)
                {
                    if (counter.data[d] != '9')
                    {
                        ++counter.data[d];
                        break;
                    }
                    counter.data[d] = '0';
                }

                // Decimal order increases only when `counter MOD 30 == 10`
                if (unlikely(counter.data[counter.offset - 1] != '0'))
                {
                    if (unlikely(counter.offset == 1))
                    {
                        goto end;
                    }

                    --counter.offset;
                }
            }

            // Write the chunk's remaining 20 counters
            {
                const char *const end = counter.data + counter.offset;
                const unsigned int n = sizeof(counter.data) - counter.offset - 1;

                CTRCPY(&quot;1&quot;); // 11

                mcpy(off, FIZZ DELIM, sizeof(FIZZ DELIM) - 1); // Fizz (12)
                off += sizeof(FIZZ DELIM) - 1;

                CTRCPY(&quot;3&quot;); // 13
                CTRCPY(&quot;4&quot;); // 14

                mcpy(off, FIZZ BUZZ DELIM, sizeof(FIZZ BUZZ DELIM) - 1); // FizzBuzz (15)
                off += sizeof(FIZZ BUZZ DELIM) - 1;

                CTRCPY(&quot;6&quot;); // 16
                CTRCPY(&quot;7&quot;); // 17

                mcpy(off, FIZZ DELIM, sizeof(FIZZ DELIM) - 1); // Fizz (18)
                off += sizeof(FIZZ DELIM) - 1;

                CTRCPY(&quot;9&quot;); // 19

                mcpy(off, BUZZ DELIM FIZZ DELIM, sizeof(BUZZ DELIM FIZZ DELIM) - 1); // Buzz (20) Fizz (21)
                off += sizeof(BUZZ DELIM FIZZ DELIM) - 1;

                // Carry handling on MOD 10
                for (unsigned d = NN; ; --d)
                {
                    if (counter.data[d] != '9')
                    {
                        ++counter.data[d];
                        break;
                    }
                    counter.data[d] = '0';
                }

                CTRCPY(&quot;2&quot;); // 22
                CTRCPY(&quot;3&quot;); // 23

                mcpy(off, FIZZ DELIM BUZZ DELIM, sizeof(FIZZ DELIM BUZZ DELIM) - 1); // Fizz (24) Buzz (25)
                off += sizeof(FIZZ DELIM BUZZ DELIM) - 1;

                CTRCPY(&quot;6&quot;); // 26

                mcpy(off, FIZZ DELIM, sizeof(FIZZ DELIM) - 1); // Fizz (27)
                off += sizeof(FIZZ DELIM) - 1;

                CTRCPY(&quot;8&quot;); // 28
                CTRCPY(&quot;9&quot;); // 29

                mcpy(off, FIZZ BUZZ DELIM, sizeof(FIZZ BUZZ DELIM) - 1); // FizzBuzz (30)
                off += sizeof(FIZZ BUZZ DELIM) - 1;

                // Carry handling on MOD 10
                for (unsigned d = NN; ; --d)
                {
                    if (counter.data[d] != '9')
                    {
                        ++counter.data[d];
                        break;
                    }
                    counter.data[d] = '0';
                }
            }
        }

        os_write(out, buf, ALIGNED_BUF);
        mcpy(buf, buf + ALIGNED_BUF, (off - buf) % ALIGNED_BUF);
        off -= ALIGNED_BUF;
    }

end:
    os_write(out, buf, off - buf);

    return 0;
}
</code></pre>
<p>Compiled as <code>clang -o fizz fizz.c -O3 -march=native</code> (with clang 11.0.0 on my Ubuntu 20.10 installation, running kernel version <code>5.8.0-26.27-generic 5.8.14</code> on an Intel Core i7-8750H mobile CPU while plugged into the wall), this produces ~3.8GiB/s when run as <code>./fizz | pv &gt; /dev/null</code> (not very steady due to write blocking every once in a while, but there's nothing I can do about that when single-threaded, I guess).</p>
<p><strong>EDIT</strong>: Optimised the carry handling a bit, and now I'm getting ~3.9GiB/s on my machine (same configuration as above).</p>
</div>

<table id="st">
<!-- Popups content will be added here -->
</table>

<table id="at">
<!-- Popups content will be added here -->
</table>

</div>





  <div class="footer">
      <b><a class="nonewtab" href="../">GOLFSCORE/</a><a href="https://codegolf.stackexchange.com/questions/215216/">215216</a></b>
  </div>
<div class="footer-space">&nbsp;</div>



<script src="../c.js"> </script>
</body>
</html>




